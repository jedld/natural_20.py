{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pyyaml in /home/jedld/.local/lib/python3.10/site-packages (6.0.1)\n",
      "Requirement already satisfied: dndice in /home/jedld/.local/lib/python3.10/site-packages (2.8.1)\n",
      "Requirement already satisfied: python-i18n in /home/jedld/.local/lib/python3.10/site-packages (0.3.9)\n",
      "Requirement already satisfied: gymnasium in /home/jedld/.local/lib/python3.10/site-packages (0.29.1)\n",
      "Requirement already satisfied: numpy>=1.21.0 in /home/jedld/.local/lib/python3.10/site-packages (from gymnasium) (1.26.4)\n",
      "Requirement already satisfied: cloudpickle>=1.2.0 in /home/jedld/.local/lib/python3.10/site-packages (from gymnasium) (2.2.1)\n",
      "Requirement already satisfied: typing-extensions>=4.3.0 in /home/jedld/.local/lib/python3.10/site-packages (from gymnasium) (4.9.0)\n",
      "Requirement already satisfied: farama-notifications>=0.0.1 in /home/jedld/.local/lib/python3.10/site-packages (from gymnasium) (0.0.4)\n",
      "Requirement already satisfied: inflect in /home/jedld/.local/lib/python3.10/site-packages (7.0.0)\n",
      "Requirement already satisfied: pydantic>=1.9.1 in /home/jedld/.local/lib/python3.10/site-packages (from inflect) (2.8.2)\n",
      "Requirement already satisfied: typing-extensions in /home/jedld/.local/lib/python3.10/site-packages (from inflect) (4.9.0)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /home/jedld/.local/lib/python3.10/site-packages (from pydantic>=1.9.1->inflect) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.20.1 in /home/jedld/.local/lib/python3.10/site-packages (from pydantic>=1.9.1->inflect) (2.20.1)\n",
      "Requirement already satisfied: collections-extended in /home/jedld/miniconda3/envs/ai322/lib/python3.10/site-packages (2.0.2)\n",
      "Requirement already satisfied: openai in /home/jedld/miniconda3/envs/ai322/lib/python3.10/site-packages (1.30.3)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /home/jedld/.local/lib/python3.10/site-packages (from openai) (3.7.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /home/jedld/miniconda3/envs/ai322/lib/python3.10/site-packages (from openai) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /home/jedld/.local/lib/python3.10/site-packages (from openai) (0.27.0)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in /home/jedld/.local/lib/python3.10/site-packages (from openai) (2.8.2)\n",
      "Requirement already satisfied: sniffio in /home/jedld/.local/lib/python3.10/site-packages (from openai) (1.3.0)\n",
      "Requirement already satisfied: tqdm>4 in /home/jedld/.local/lib/python3.10/site-packages (from openai) (4.65.0)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.7 in /home/jedld/.local/lib/python3.10/site-packages (from openai) (4.9.0)\n",
      "Requirement already satisfied: idna>=2.8 in /home/jedld/.local/lib/python3.10/site-packages (from anyio<5,>=3.5.0->openai) (2.10)\n",
      "Requirement already satisfied: exceptiongroup in /home/jedld/.local/lib/python3.10/site-packages (from anyio<5,>=3.5.0->openai) (1.1.1)\n",
      "Requirement already satisfied: certifi in /home/jedld/.local/lib/python3.10/site-packages (from httpx<1,>=0.23.0->openai) (2023.5.7)\n",
      "Requirement already satisfied: httpcore==1.* in /home/jedld/.local/lib/python3.10/site-packages (from httpx<1,>=0.23.0->openai) (1.0.5)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /home/jedld/.local/lib/python3.10/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /home/jedld/.local/lib/python3.10/site-packages (from pydantic<3,>=1.9.0->openai) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.20.1 in /home/jedld/.local/lib/python3.10/site-packages (from pydantic<3,>=1.9.0->openai) (2.20.1)\n",
      "Obtaining file:///home/jedld/workspace/natural_20.py\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: pyyaml in /home/jedld/.local/lib/python3.10/site-packages (from natural20.py==0.1) (6.0.1)\n",
      "Requirement already satisfied: dndice in /home/jedld/.local/lib/python3.10/site-packages (from natural20.py==0.1) (2.8.1)\n",
      "Requirement already satisfied: python-i18n in /home/jedld/.local/lib/python3.10/site-packages (from natural20.py==0.1) (0.3.9)\n",
      "Requirement already satisfied: fantasynames in /home/jedld/miniconda3/envs/ai322/lib/python3.10/site-packages (from natural20.py==0.1) (0.1.2)\n",
      "Requirement already satisfied: black<21.0,>=20.8b1 in /home/jedld/miniconda3/envs/ai322/lib/python3.10/site-packages (from fantasynames->natural20.py==0.1) (20.8b1)\n",
      "Requirement already satisfied: flake8<4.0.0,>=3.9.0 in /home/jedld/miniconda3/envs/ai322/lib/python3.10/site-packages (from fantasynames->natural20.py==0.1) (3.9.2)\n",
      "Requirement already satisfied: mypy<0.813,>=0.812 in /home/jedld/miniconda3/envs/ai322/lib/python3.10/site-packages (from fantasynames->natural20.py==0.1) (0.812)\n",
      "Requirement already satisfied: pytest<7.0.0,>=6.2.3 in /home/jedld/miniconda3/envs/ai322/lib/python3.10/site-packages (from fantasynames->natural20.py==0.1) (6.2.5)\n",
      "Requirement already satisfied: click>=7.1.2 in /home/jedld/.local/lib/python3.10/site-packages (from black<21.0,>=20.8b1->fantasynames->natural20.py==0.1) (8.1.7)\n",
      "Requirement already satisfied: appdirs in /home/jedld/miniconda3/envs/ai322/lib/python3.10/site-packages (from black<21.0,>=20.8b1->fantasynames->natural20.py==0.1) (1.4.4)\n",
      "Requirement already satisfied: toml>=0.10.1 in /home/jedld/miniconda3/envs/ai322/lib/python3.10/site-packages (from black<21.0,>=20.8b1->fantasynames->natural20.py==0.1) (0.10.2)\n",
      "Requirement already satisfied: typed-ast>=1.4.0 in /home/jedld/miniconda3/envs/ai322/lib/python3.10/site-packages (from black<21.0,>=20.8b1->fantasynames->natural20.py==0.1) (1.4.3)\n",
      "Requirement already satisfied: regex>=2020.1.8 in /home/jedld/.local/lib/python3.10/site-packages (from black<21.0,>=20.8b1->fantasynames->natural20.py==0.1) (2023.12.25)\n",
      "Requirement already satisfied: pathspec<1,>=0.6 in /home/jedld/miniconda3/envs/ai322/lib/python3.10/site-packages (from black<21.0,>=20.8b1->fantasynames->natural20.py==0.1) (0.12.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4 in /home/jedld/.local/lib/python3.10/site-packages (from black<21.0,>=20.8b1->fantasynames->natural20.py==0.1) (4.9.0)\n",
      "Requirement already satisfied: mypy-extensions>=0.4.3 in /home/jedld/miniconda3/envs/ai322/lib/python3.10/site-packages (from black<21.0,>=20.8b1->fantasynames->natural20.py==0.1) (0.4.4)\n",
      "Requirement already satisfied: pyflakes<2.4.0,>=2.3.0 in /home/jedld/miniconda3/envs/ai322/lib/python3.10/site-packages (from flake8<4.0.0,>=3.9.0->fantasynames->natural20.py==0.1) (2.3.1)\n",
      "Requirement already satisfied: pycodestyle<2.8.0,>=2.7.0 in /home/jedld/miniconda3/envs/ai322/lib/python3.10/site-packages (from flake8<4.0.0,>=3.9.0->fantasynames->natural20.py==0.1) (2.7.0)\n",
      "Requirement already satisfied: mccabe<0.7.0,>=0.6.0 in /home/jedld/miniconda3/envs/ai322/lib/python3.10/site-packages (from flake8<4.0.0,>=3.9.0->fantasynames->natural20.py==0.1) (0.6.1)\n",
      "Requirement already satisfied: attrs>=19.2.0 in /home/jedld/miniconda3/envs/ai322/lib/python3.10/site-packages (from pytest<7.0.0,>=6.2.3->fantasynames->natural20.py==0.1) (23.2.0)\n",
      "Requirement already satisfied: iniconfig in /home/jedld/miniconda3/envs/ai322/lib/python3.10/site-packages (from pytest<7.0.0,>=6.2.3->fantasynames->natural20.py==0.1) (2.0.0)\n",
      "Requirement already satisfied: packaging in /home/jedld/.local/lib/python3.10/site-packages (from pytest<7.0.0,>=6.2.3->fantasynames->natural20.py==0.1) (23.2)\n",
      "Requirement already satisfied: pluggy<2.0,>=0.12 in /home/jedld/.local/lib/python3.10/site-packages (from pytest<7.0.0,>=6.2.3->fantasynames->natural20.py==0.1) (1.5.0)\n",
      "Requirement already satisfied: py>=1.8.2 in /home/jedld/miniconda3/envs/ai322/lib/python3.10/site-packages (from pytest<7.0.0,>=6.2.3->fantasynames->natural20.py==0.1) (1.11.0)\n",
      "Installing collected packages: natural20.py\n",
      "  Attempting uninstall: natural20.py\n",
      "    Found existing installation: natural20.py 0.1\n",
      "    Uninstalling natural20.py-0.1:\n",
      "      Successfully uninstalled natural20.py-0.1\n",
      "  Running setup.py develop for natural20.py\n",
      "Successfully installed natural20.py\n",
      "Requirement already satisfied: ipywidgets in /home/jedld/miniconda3/envs/ai322/lib/python3.10/site-packages (8.1.3)\n",
      "Requirement already satisfied: comm>=0.1.3 in /home/jedld/miniconda3/envs/ai322/lib/python3.10/site-packages (from ipywidgets) (0.2.2)\n",
      "Requirement already satisfied: ipython>=6.1.0 in /home/jedld/miniconda3/envs/ai322/lib/python3.10/site-packages (from ipywidgets) (8.22.2)\n",
      "Requirement already satisfied: traitlets>=4.3.1 in /home/jedld/miniconda3/envs/ai322/lib/python3.10/site-packages (from ipywidgets) (5.14.3)\n",
      "Requirement already satisfied: widgetsnbextension~=4.0.11 in /home/jedld/miniconda3/envs/ai322/lib/python3.10/site-packages (from ipywidgets) (4.0.11)\n",
      "Requirement already satisfied: jupyterlab-widgets~=3.0.11 in /home/jedld/miniconda3/envs/ai322/lib/python3.10/site-packages (from ipywidgets) (3.0.11)\n",
      "Requirement already satisfied: decorator in /home/jedld/miniconda3/envs/ai322/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (5.1.1)\n",
      "Requirement already satisfied: jedi>=0.16 in /home/jedld/miniconda3/envs/ai322/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (0.19.1)\n",
      "Requirement already satisfied: matplotlib-inline in /home/jedld/miniconda3/envs/ai322/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (0.1.7)\n",
      "Requirement already satisfied: prompt-toolkit<3.1.0,>=3.0.41 in /home/jedld/miniconda3/envs/ai322/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (3.0.42)\n",
      "Requirement already satisfied: pygments>=2.4.0 in /home/jedld/miniconda3/envs/ai322/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (2.18.0)\n",
      "Requirement already satisfied: stack-data in /home/jedld/miniconda3/envs/ai322/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (0.6.2)\n",
      "Requirement already satisfied: exceptiongroup in /home/jedld/.local/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (1.1.1)\n",
      "Requirement already satisfied: pexpect>4.3 in /home/jedld/miniconda3/envs/ai322/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (4.9.0)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.3 in /home/jedld/miniconda3/envs/ai322/lib/python3.10/site-packages (from jedi>=0.16->ipython>=6.1.0->ipywidgets) (0.8.4)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in /home/jedld/miniconda3/envs/ai322/lib/python3.10/site-packages (from pexpect>4.3->ipython>=6.1.0->ipywidgets) (0.7.0)\n",
      "Requirement already satisfied: wcwidth in /home/jedld/miniconda3/envs/ai322/lib/python3.10/site-packages (from prompt-toolkit<3.1.0,>=3.0.41->ipython>=6.1.0->ipywidgets) (0.2.13)\n",
      "Requirement already satisfied: executing>=1.2.0 in /home/jedld/miniconda3/envs/ai322/lib/python3.10/site-packages (from stack-data->ipython>=6.1.0->ipywidgets) (2.0.1)\n",
      "Requirement already satisfied: asttokens>=2.1.0 in /home/jedld/miniconda3/envs/ai322/lib/python3.10/site-packages (from stack-data->ipython>=6.1.0->ipywidgets) (2.4.1)\n",
      "Requirement already satisfied: pure-eval in /home/jedld/miniconda3/envs/ai322/lib/python3.10/site-packages (from stack-data->ipython>=6.1.0->ipywidgets) (0.2.2)\n",
      "Requirement already satisfied: six>=1.12.0 in /home/jedld/miniconda3/envs/ai322/lib/python3.10/site-packages (from asttokens>=2.1.0->stack-data->ipython>=6.1.0->ipywidgets) (1.16.0)\n",
      "Requirement already satisfied: iprogress in /home/jedld/miniconda3/envs/ai322/lib/python3.10/site-packages (0.4)\n",
      "Requirement already satisfied: six in /home/jedld/miniconda3/envs/ai322/lib/python3.10/site-packages (from iprogress) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install pyyaml\n",
    "!pip install dndice\n",
    "!pip install python-i18n\n",
    "!pip install gymnasium\n",
    "!pip install inflect\n",
    "!pip install collections-extended\n",
    "!pip install openai\n",
    "!pip install -e ..\n",
    "!pip install ipywidgets\n",
    "!pip install iprogress\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gymnasium import make\n",
    "from model import QNetwork\n",
    "from natural20.gym.dndenv import dndenv\n",
    "import torch\n",
    "import tqdm as tqdm\n",
    "import tqdm.notebook as tqdm\n",
    "import random\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "import gc\n",
    "import numpy as np\n",
    "import sys\n",
    "import collections\n",
    "from natural20.session import Session\n",
    "from natural20.event_manager import EventManager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.backends.mps.is_available():\n",
    "  device = torch.device(\"mps\")\n",
    "else:\n",
    "  device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "env_config = \"map_with_obstacles\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "session = Session(env_config, event_manager=EventManager())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Show info about the environment and a render of the tabletop map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading map from map_with_obstacles/maps/game_map.yml\n",
      "Creating new event manager\n",
      "==== Player Character ====\n",
      "name: gomerin\n",
      "level: 1\n",
      "character class: {'rogue': 1}\n",
      "hp: 18\n",
      "max hp: 18\n",
      "ac: 16\n",
      "speed: 25\n",
      "no spells\n",
      "\n",
      "\n",
      "\n",
      "==== Player Character ====\n",
      "name: rumblebelly\n",
      "level: 1\n",
      "character class: {'rogue': 1}\n",
      "hp: 18\n",
      "max hp: 18\n",
      "ac: 16\n",
      "speed: 25\n",
      "no spells\n",
      "\n",
      "\n",
      "\n",
      "____________\n",
      "____________\n",
      "____________\n",
      "_____...... \n",
      "_____....   \n",
      "_____...#  .\n",
      "_____.P~E~..\n",
      "_____~~~....\n",
      "_____~~.....\n",
      "____________\n",
      "____________\n",
      "____________\n",
      "Dict('ability_info': Box(0, 1, (8,), int64), 'enemy_reactions': Box(0, 1, (1,), int64), 'health_enemy': Box(0.0, 1.0, (1,), float64), 'health_pct': Box(0.0, 1.0, (1,), float64), 'map': Box(-1, 255, (12, 12, 4), int64), 'movement': Discrete(255), 'turn_info': Box(0, 1, (3,), int64))\n",
      "<bound method Tuple.sample of Tuple(Box(-1, 255, (1,), int64), Box(-1, 255, (2,), int64), Box(-6, 6, (2,), int64), Discrete(255), Discrete(255))>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jedld/.local/lib/python3.10/site-packages/gymnasium/utils/passive_env_checker.py:318: UserWarning: \u001b[33mWARN: No render modes was declared in the environment (env.metadata['render_modes'] is None or not defined), you may have trouble when calling `.render()`.\u001b[0m\n",
      "  logger.warn(\n"
     ]
    }
   ],
   "source": [
    "env = make(\"dndenv-v0\", root_path=\"map_with_obstacles\", show_logs=True,\n",
    "           custom_session=session,\n",
    "           damaged_based_reward=True,\n",
    "           render_mode=\"ansi\")\n",
    "env.reset()\n",
    "print(env.render())\n",
    "print(env.observation_space)\n",
    "print(env.action_space.sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DQN Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAJECTORY_POLICY = \"e-greedy\"\n",
    "NUM_UPDATES = 2\n",
    "TEMP_DECAY = 0.999\n",
    "BUFFER_CAPACITY = 3000\n",
    "FRAMES_TO_STORE = 2\n",
    "MAX_STEPS = 10000\n",
    "BATCH_SIZE = 64\n",
    "TARGET_UPDATE_FREQ = 1\n",
    "T_HORIZON = 2048\n",
    "EPSILON_START = 1.0\n",
    "EPSILON_FINAL = 0.01\n",
    "EPSILON_DECAY_FRAMES = 10**3\n",
    "EVAL_STEPS = 25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading map from map_with_obstacles/maps/game_map.yml\n",
      "Creating new event manager\n",
      "==== Player Character ====\n",
      "name: gomerin\n",
      "level: 1\n",
      "character class: {'rogue': 1}\n",
      "hp: 18\n",
      "max hp: 18\n",
      "ac: 16\n",
      "speed: 25\n",
      "no spells\n",
      "\n",
      "\n",
      "\n",
      "==== Player Character ====\n",
      "name: rumblebelly\n",
      "level: 1\n",
      "character class: {'rogue': 1}\n",
      "hp: 18\n",
      "max hp: 18\n",
      "ac: 16\n",
      "speed: 25\n",
      "no spells\n",
      "\n",
      "\n",
      "\n",
      "tensor([[-0.1478]], device='cuda:0', grad_fn=<AddmmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "model = QNetwork(device=device)\n",
    "model.to(device)\n",
    "state, info = env.reset()\n",
    "moves = info[\"available_moves\"]\n",
    "model.eval()\n",
    "print(model(state, moves[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def act_with_policy(state, info, model, policy='e-greedy', temperature=5.0, epsilon=0.1):\n",
    "    available_moves = info[\"available_moves\"]\n",
    "    with torch.no_grad():\n",
    "        if policy == 'boltzmann':\n",
    "            values = torch.stack([model(state, move).squeeze() for move in available_moves])\n",
    "            if len(values) > 1:\n",
    "                if temperature != 0:\n",
    "                    values = values / temperature\n",
    "                else:\n",
    "                    raise ValueError(\"Temperature is zero, which can lead to division by zero.\")\n",
    "\n",
    "                # Stabilizing the exponential calculation\n",
    "                values = values - torch.max(values)  # Subtract the max value for numerical stability\n",
    "                values = torch.exp(values)\n",
    "                sum_values = torch.sum(values)\n",
    "\n",
    "                if sum_values > 0:\n",
    "                    values = values / sum_values\n",
    "                    chosen_index = torch.multinomial(values, 1).item()\n",
    "                else:\n",
    "                    print(\"Sum of exponentiated values is zero. Adjust the model or input.\")\n",
    "                    chosen_index = torch.randint(len(available_moves), (1,)).item()\n",
    "            else:\n",
    "                chosen_index = 0\n",
    "        elif policy == 'e-greedy':\n",
    "            if random.random() < epsilon:\n",
    "                # place available moves in buckets according to their type\n",
    "                # this is so that movements are not chosen more often than other types of moves\n",
    "                move_types = collections.defaultdict(list)\n",
    "                for orig_index, move in enumerate(available_moves):\n",
    "                    move_types[move[0]].append(orig_index)\n",
    "                chosen_move_type = random.choice(list(move_types.keys()))\n",
    "                chosen_index = random.choice(move_types[chosen_move_type])\n",
    "            else:\n",
    "                values = torch.stack([model(state, move) for move in available_moves])\n",
    "                chosen_index = torch.argmax(values).item()\n",
    "        elif policy == 'greedy':\n",
    "                values = torch.stack([model(state, move) for move in available_moves])\n",
    "                chosen_index = torch.argmax(values).item()\n",
    "        else:\n",
    "            raise ValueError(f\"Unknown policy: {policy}\")\n",
    "    \n",
    "    return available_moves[chosen_index]\n",
    "\n",
    "def generate_trajectory(env, model, policy='e-greedy', temperature=5.0, epsilon=0.1, horizon=2048, quick_exit=False):\n",
    "    state, info = env.reset()\n",
    "    done = False\n",
    "    truncated = False\n",
    "    states = []\n",
    "    actions = []\n",
    "    rewards = []\n",
    "    dones = []\n",
    "    truncateds = []\n",
    "    infos = []\n",
    "    truncated = False\n",
    "    for _ in range(horizon):\n",
    "        # instead of sampling  (e.g. env.action_space.sample()) we can ask help from the enivronment to obtain valid moves\n",
    "        # as there are sparse valid moves in the environment\n",
    "        action = act_with_policy(state, info, model, policy, temperature, epsilon)\n",
    "        next_state, reward, done, truncated, next_info = env.step(action)       \n",
    "        \n",
    "        states.append(state)\n",
    "        actions.append(action)\n",
    "        rewards.append(reward)\n",
    "        dones.append(done)\n",
    "        truncateds.append(truncated)\n",
    "        infos.append(info)\n",
    "\n",
    "        if done:\n",
    "            break    \n",
    "        if truncated:\n",
    "            truncated = True\n",
    "            break\n",
    "        state = next_state\n",
    "        info = next_info\n",
    "        \n",
    "    states.append(next_state)\n",
    "    infos.append(next_info)\n",
    "    actions.append((-1, (0,0), (0,0), 0, 0))\n",
    "    return states, actions, rewards, dones, truncateds, infos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading map from map_with_obstacles/maps/game_map.yml\n",
      "Creating new event manager\n",
      "==== Player Character ====\n",
      "name: gomerin\n",
      "level: 1\n",
      "character class: {'rogue': 1}\n",
      "hp: 18\n",
      "max hp: 18\n",
      "ac: 16\n",
      "speed: 25\n",
      "no spells\n",
      "\n",
      "\n",
      "\n",
      "==== Player Character ====\n",
      "name: rumblebelly\n",
      "level: 1\n",
      "character class: {'rogue': 1}\n",
      "hp: 18\n",
      "max hp: 18\n",
      "ac: 16\n",
      "speed: 25\n",
      "no spells\n",
      "\n",
      "\n",
      "\n",
      "==== end turn ===\n",
      "gomerin 18/18\n",
      "no spells\n",
      "rumblebelly 18/18\n",
      "no spells\n",
      "==== current turn rumblebelly 18/18 AC 16===\n",
      "no spells\n",
      "no move for rumblebelly\n",
      "==== current turn gomerin 10/18 AC 16===\n",
      "no spells\n",
      "Result: False\n",
      "==== end turn ===\n",
      "gomerin 10/18\n",
      "no spells\n",
      "rumblebelly 18/18\n",
      "no spells\n",
      "==== current turn rumblebelly 18/18 AC 16===\n",
      "no spells\n",
      "no move for rumblebelly\n",
      "==== current turn gomerin 10/18 AC 16===\n",
      "no spells\n",
      "Result: False\n",
      "==== end turn ===\n",
      "gomerin 3/18\n",
      "no spells\n",
      "rumblebelly 18/18\n",
      "no spells\n",
      "==== current turn rumblebelly 18/18 AC 16===\n",
      "no spells\n",
      "no move for rumblebelly\n",
      "==== current turn gomerin 3/18 AC 16===\n",
      "no spells\n",
      "Result: False\n",
      "==== end turn ===\n",
      "gomerin 3/18\n",
      "no spells\n",
      "rumblebelly 18/18\n",
      "no spells\n",
      "==== current turn rumblebelly 18/18 AC 16===\n",
      "no spells\n",
      "Result: tpk\n",
      "([{'map': array([[[ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0]],\n",
      "\n",
      "       [[ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0]],\n",
      "\n",
      "       [[ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0]],\n",
      "\n",
      "       [[ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [  0,   0,   0,   0],\n",
      "        [  0,   0,   0,   0],\n",
      "        [  0,   0,   0,   0],\n",
      "        [  0,   0,   0,   0],\n",
      "        [255, 255, 255, 255],\n",
      "        [255, 255, 255, 255],\n",
      "        [255, 255, 255, 255],\n",
      "        [ -1,  -1,   0,   0]],\n",
      "\n",
      "       [[ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [  0,   0,   0,   0],\n",
      "        [  2,   0, 254,   0],\n",
      "        [  0,   0,   0,   0],\n",
      "        [255, 255, 255, 255],\n",
      "        [255, 255, 255, 255],\n",
      "        [255, 255, 255, 255],\n",
      "        [255, 255, 255, 255],\n",
      "        [ -1,  -1,   0,   0]],\n",
      "\n",
      "       [[ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [  0,   0,   0,   0],\n",
      "        [  0,   0,   0,   0],\n",
      "        [  0,   0,   0,   0],\n",
      "        [  0,   1,   0,   0],\n",
      "        [255, 255, 255, 255],\n",
      "        [  0,   0,   0,   0],\n",
      "        [  0,   0,   0,   0],\n",
      "        [ -1,  -1,   0,   0]],\n",
      "\n",
      "       [[ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [  0,   0,   0,   0],\n",
      "        [  0,   2,   0,   0],\n",
      "        [  1,   2, 254,   0],\n",
      "        [  0,   2,   0,   0],\n",
      "        [  0,   2,   0,   0],\n",
      "        [  0,   0,   0,   0],\n",
      "        [  0,   0,   0,   0],\n",
      "        [ -1,  -1,   0,   0]],\n",
      "\n",
      "       [[ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [  0,   2,   0,   0],\n",
      "        [  0,   2,   0,   0],\n",
      "        [  0,   2,   0,   0],\n",
      "        [  0,   0,   0,   0],\n",
      "        [  0,   0,   0,   0],\n",
      "        [  0,   0,   0,   0],\n",
      "        [  0,   0,   0,   0],\n",
      "        [ -1,  -1,   0,   0]],\n",
      "\n",
      "       [[ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [  0,   2,   0,   0],\n",
      "        [  0,   2,   0,   0],\n",
      "        [  0,   0,   0,   0],\n",
      "        [  0,   0,   0,   0],\n",
      "        [  0,   0,   0,   0],\n",
      "        [  0,   0,   0,   0],\n",
      "        [  0,   0,   0,   0],\n",
      "        [ -1,  -1,   0,   0]],\n",
      "\n",
      "       [[ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0]],\n",
      "\n",
      "       [[ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0]],\n",
      "\n",
      "       [[ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0]]]), 'turn_info': array([1, 1, 1]), 'health_pct': array([1.]), 'health_enemy': array([1.]), 'enemy_reactions': array([0]), 'ability_info': array([0, 0, 0, 0, 0, 0, 0, 0]), 'movement': 25}, {'map': array([[[ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0]],\n",
      "\n",
      "       [[ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0]],\n",
      "\n",
      "       [[ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0]],\n",
      "\n",
      "       [[ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0]],\n",
      "\n",
      "       [[ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [  0,   0,   0,   0],\n",
      "        [  0,   0,   0,   0],\n",
      "        [  0,   0,   0,   0],\n",
      "        [  0,   0,   0,   0],\n",
      "        [  0,   0,   0,   0],\n",
      "        [  0,   0,   0,   0],\n",
      "        [  0,   0,   0,   0]],\n",
      "\n",
      "       [[ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [  0,   0,   0,   0],\n",
      "        [  2,   0, 254,   0],\n",
      "        [  0,   0,   0,   0],\n",
      "        [  0,   0,   0,   0],\n",
      "        [  0,   0,   0,   0],\n",
      "        [  0,   0,   0,   0],\n",
      "        [255, 255, 255, 255]],\n",
      "\n",
      "       [[ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [  0,   0,   0,   0],\n",
      "        [  1,   0, 254,   0],\n",
      "        [  0,   0,   0,   0],\n",
      "        [  0,   1,   0,   0],\n",
      "        [255, 255, 255, 255],\n",
      "        [255, 255, 255, 255],\n",
      "        [255, 255, 255, 255]],\n",
      "\n",
      "       [[ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [  0,   0,   0,   0],\n",
      "        [  0,   2,   0,   0],\n",
      "        [  0,   2,   0,   0],\n",
      "        [  0,   2,   0,   0],\n",
      "        [  0,   2,   0,   0],\n",
      "        [  0,   0,   0,   0],\n",
      "        [255, 255, 255, 255]],\n",
      "\n",
      "       [[ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [  0,   2,   0,   0],\n",
      "        [  0,   2,   0,   0],\n",
      "        [  0,   2,   0,   0],\n",
      "        [  0,   0,   0,   0],\n",
      "        [  0,   0,   0,   0],\n",
      "        [  0,   0,   0,   0],\n",
      "        [  0,   0,   0,   0]],\n",
      "\n",
      "       [[ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [  0,   2,   0,   0],\n",
      "        [  0,   2,   0,   0],\n",
      "        [  0,   0,   0,   0],\n",
      "        [  0,   0,   0,   0],\n",
      "        [  0,   0,   0,   0],\n",
      "        [  0,   0,   0,   0],\n",
      "        [  0,   0,   0,   0]],\n",
      "\n",
      "       [[ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0]],\n",
      "\n",
      "       [[ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0]]]), 'turn_info': array([1, 1, 1]), 'health_pct': array([1.]), 'health_enemy': array([1.]), 'enemy_reactions': array([0]), 'ability_info': array([0, 0, 0, 0, 0, 0, 0, 0]), 'movement': 20}, {'map': array([[[ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0]],\n",
      "\n",
      "       [[ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0]],\n",
      "\n",
      "       [[ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0]],\n",
      "\n",
      "       [[ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0]],\n",
      "\n",
      "       [[ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [  0,   0,   0,   0],\n",
      "        [  0,   0,   0,   0],\n",
      "        [  0,   0,   0,   0],\n",
      "        [  0,   0,   0,   0],\n",
      "        [  0,   0,   0,   0],\n",
      "        [  0,   0,   0,   0],\n",
      "        [  0,   0,   0,   0]],\n",
      "\n",
      "       [[ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [  0,   0,   0,   0],\n",
      "        [  0,   0,   0,   0],\n",
      "        [  0,   0,   0,   0],\n",
      "        [  0,   0,   0,   0],\n",
      "        [  0,   0,   0,   0],\n",
      "        [  0,   0,   0,   0],\n",
      "        [255, 255, 255, 255]],\n",
      "\n",
      "       [[ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [  2,   0, 254,   0],\n",
      "        [  1,   0, 141,   0],\n",
      "        [  0,   0,   0,   0],\n",
      "        [  0,   1,   0,   0],\n",
      "        [255, 255, 255, 255],\n",
      "        [255, 255, 255, 255],\n",
      "        [255, 255, 255, 255]],\n",
      "\n",
      "       [[ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [  0,   0,   0,   0],\n",
      "        [  0,   2,   0,   0],\n",
      "        [  0,   2,   0,   0],\n",
      "        [  0,   2,   0,   0],\n",
      "        [  0,   2,   0,   0],\n",
      "        [  0,   0,   0,   0],\n",
      "        [255, 255, 255, 255]],\n",
      "\n",
      "       [[ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [  0,   2,   0,   0],\n",
      "        [  0,   2,   0,   0],\n",
      "        [  0,   2,   0,   0],\n",
      "        [  0,   0,   0,   0],\n",
      "        [  0,   0,   0,   0],\n",
      "        [  0,   0,   0,   0],\n",
      "        [  0,   0,   0,   0]],\n",
      "\n",
      "       [[ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [  0,   2,   0,   0],\n",
      "        [  0,   2,   0,   0],\n",
      "        [  0,   0,   0,   0],\n",
      "        [  0,   0,   0,   0],\n",
      "        [  0,   0,   0,   0],\n",
      "        [  0,   0,   0,   0],\n",
      "        [  0,   0,   0,   0]],\n",
      "\n",
      "       [[ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0]],\n",
      "\n",
      "       [[ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0]]]), 'turn_info': array([1, 1, 1]), 'health_pct': array([0.55555556]), 'health_enemy': array([1.]), 'enemy_reactions': array([1]), 'ability_info': array([0, 0, 0, 0, 0, 0, 0, 0]), 'movement': 25}, {'map': array([[[ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0]],\n",
      "\n",
      "       [[ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0]],\n",
      "\n",
      "       [[ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0]],\n",
      "\n",
      "       [[ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0]],\n",
      "\n",
      "       [[ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [  0,   0,   0,   0],\n",
      "        [  0,   0,   0,   0],\n",
      "        [  0,   0,   0,   0],\n",
      "        [  0,   0,   0,   0],\n",
      "        [  0,   0,   0,   0],\n",
      "        [  0,   0,   0,   0],\n",
      "        [  0,   0,   0,   0]],\n",
      "\n",
      "       [[ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [  0,   0,   0,   0],\n",
      "        [  0,   0,   0,   0],\n",
      "        [  0,   0,   0,   0],\n",
      "        [  0,   0,   0,   0],\n",
      "        [  0,   0,   0,   0],\n",
      "        [  0,   0,   0,   0],\n",
      "        [255, 255, 255, 255]],\n",
      "\n",
      "       [[ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [  2,   0, 254,   0],\n",
      "        [  1,   0, 141,   0],\n",
      "        [  0,   0,   0,   0],\n",
      "        [  0,   1,   0,   0],\n",
      "        [255, 255, 255, 255],\n",
      "        [255, 255, 255, 255],\n",
      "        [255, 255, 255, 255]],\n",
      "\n",
      "       [[ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [  0,   0,   0,   0],\n",
      "        [  0,   2,   0,   0],\n",
      "        [  0,   2,   0,   0],\n",
      "        [  0,   2,   0,   0],\n",
      "        [  0,   2,   0,   0],\n",
      "        [  0,   0,   0,   0],\n",
      "        [255, 255, 255, 255]],\n",
      "\n",
      "       [[ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [  0,   2,   0,   0],\n",
      "        [  0,   2,   0,   0],\n",
      "        [  0,   2,   0,   0],\n",
      "        [  0,   0,   0,   0],\n",
      "        [  0,   0,   0,   0],\n",
      "        [  0,   0,   0,   0],\n",
      "        [  0,   0,   0,   0]],\n",
      "\n",
      "       [[ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [  0,   2,   0,   0],\n",
      "        [  0,   2,   0,   0],\n",
      "        [  0,   0,   0,   0],\n",
      "        [  0,   0,   0,   0],\n",
      "        [  0,   0,   0,   0],\n",
      "        [  0,   0,   0,   0],\n",
      "        [  0,   0,   0,   0]],\n",
      "\n",
      "       [[ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0]],\n",
      "\n",
      "       [[ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0]]]), 'turn_info': array([1, 1, 1]), 'health_pct': array([0.55555556]), 'health_enemy': array([1.]), 'enemy_reactions': array([1]), 'ability_info': array([0, 0, 0, 0, 0, 0, 0, 0]), 'movement': 25}, {'map': array([[[ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0]],\n",
      "\n",
      "       [[ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0]],\n",
      "\n",
      "       [[ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0]],\n",
      "\n",
      "       [[ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0]],\n",
      "\n",
      "       [[ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [  0,   0,   0,   0],\n",
      "        [  0,   0,   0,   0],\n",
      "        [  0,   0,   0,   0],\n",
      "        [  0,   0,   0,   0],\n",
      "        [  0,   0,   0,   0],\n",
      "        [  0,   0,   0,   0],\n",
      "        [  0,   0,   0,   0]],\n",
      "\n",
      "       [[ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [  0,   0,   0,   0],\n",
      "        [  0,   0,   0,   0],\n",
      "        [  0,   0,   0,   0],\n",
      "        [  0,   0,   0,   0],\n",
      "        [  0,   0,   0,   0],\n",
      "        [  0,   0,   0,   0],\n",
      "        [255, 255, 255, 255]],\n",
      "\n",
      "       [[ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [  2,   0, 254,   0],\n",
      "        [  1,   0, 141,   1],\n",
      "        [  0,   0,   0,   0],\n",
      "        [  0,   1,   0,   0],\n",
      "        [255, 255, 255, 255],\n",
      "        [255, 255, 255, 255],\n",
      "        [255, 255, 255, 255]],\n",
      "\n",
      "       [[ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [  0,   0,   0,   0],\n",
      "        [  0,   2,   0,   0],\n",
      "        [  0,   2,   0,   0],\n",
      "        [  0,   2,   0,   0],\n",
      "        [  0,   2,   0,   0],\n",
      "        [  0,   0,   0,   0],\n",
      "        [255, 255, 255, 255]],\n",
      "\n",
      "       [[ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [  0,   2,   0,   0],\n",
      "        [  0,   2,   0,   0],\n",
      "        [  0,   2,   0,   0],\n",
      "        [  0,   0,   0,   0],\n",
      "        [  0,   0,   0,   0],\n",
      "        [  0,   0,   0,   0],\n",
      "        [  0,   0,   0,   0]],\n",
      "\n",
      "       [[ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [  0,   2,   0,   0],\n",
      "        [  0,   2,   0,   0],\n",
      "        [  0,   0,   0,   0],\n",
      "        [  0,   0,   0,   0],\n",
      "        [  0,   0,   0,   0],\n",
      "        [  0,   0,   0,   0],\n",
      "        [  0,   0,   0,   0]],\n",
      "\n",
      "       [[ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0]],\n",
      "\n",
      "       [[ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0]]]), 'turn_info': array([1, 1, 1]), 'health_pct': array([0.55555556]), 'health_enemy': array([1.]), 'enemy_reactions': array([1]), 'ability_info': array([0, 0, 0, 0, 0, 0, 0, 0]), 'movement': 25}, {'map': array([[[ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0]],\n",
      "\n",
      "       [[ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0]],\n",
      "\n",
      "       [[ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0]],\n",
      "\n",
      "       [[ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0]],\n",
      "\n",
      "       [[ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [  0,   0,   0,   0],\n",
      "        [  0,   0,   0,   0],\n",
      "        [  0,   0,   0,   0],\n",
      "        [  0,   0,   0,   0],\n",
      "        [  0,   0,   0,   0],\n",
      "        [  0,   0,   0,   0],\n",
      "        [  0,   0,   0,   0]],\n",
      "\n",
      "       [[ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [  0,   0,   0,   0],\n",
      "        [  0,   0,   0,   0],\n",
      "        [  0,   0,   0,   0],\n",
      "        [  0,   0,   0,   0],\n",
      "        [  0,   0,   0,   0],\n",
      "        [  0,   0,   0,   0],\n",
      "        [255, 255, 255, 255]],\n",
      "\n",
      "       [[ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [  2,   0, 254,   0],\n",
      "        [  1,   0, 141,   0],\n",
      "        [  0,   0,   0,   0],\n",
      "        [  0,   1,   0,   0],\n",
      "        [255, 255, 255, 255],\n",
      "        [255, 255, 255, 255],\n",
      "        [255, 255, 255, 255]],\n",
      "\n",
      "       [[ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [  0,   0,   0,   0],\n",
      "        [  0,   2,   0,   0],\n",
      "        [  0,   2,   0,   0],\n",
      "        [  0,   2,   0,   0],\n",
      "        [  0,   2,   0,   0],\n",
      "        [  0,   0,   0,   0],\n",
      "        [255, 255, 255, 255]],\n",
      "\n",
      "       [[ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [  0,   2,   0,   0],\n",
      "        [  0,   2,   0,   0],\n",
      "        [  0,   2,   0,   0],\n",
      "        [  0,   0,   0,   0],\n",
      "        [  0,   0,   0,   0],\n",
      "        [  0,   0,   0,   0],\n",
      "        [  0,   0,   0,   0]],\n",
      "\n",
      "       [[ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [  0,   2,   0,   0],\n",
      "        [  0,   2,   0,   0],\n",
      "        [  0,   0,   0,   0],\n",
      "        [  0,   0,   0,   0],\n",
      "        [  0,   0,   0,   0],\n",
      "        [  0,   0,   0,   0],\n",
      "        [  0,   0,   0,   0]],\n",
      "\n",
      "       [[ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0]],\n",
      "\n",
      "       [[ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0]]]), 'turn_info': array([1, 1, 1]), 'health_pct': array([0.55555556]), 'health_enemy': array([1.]), 'enemy_reactions': array([1]), 'ability_info': array([0, 0, 0, 0, 0, 0, 0, 0]), 'movement': 13}, {'map': array([[[ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0]],\n",
      "\n",
      "       [[ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0]],\n",
      "\n",
      "       [[ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0]],\n",
      "\n",
      "       [[ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [  0,   0,   0,   0],\n",
      "        [  0,   0,   0,   0],\n",
      "        [  0,   0,   0,   0],\n",
      "        [  0,   0,   0,   0],\n",
      "        [255, 255, 255, 255],\n",
      "        [255, 255, 255, 255],\n",
      "        [255, 255, 255, 255],\n",
      "        [ -1,  -1,   0,   0]],\n",
      "\n",
      "       [[ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [  0,   0,   0,   0],\n",
      "        [  0,   0,   0,   0],\n",
      "        [  0,   0,   0,   0],\n",
      "        [255, 255, 255, 255],\n",
      "        [255, 255, 255, 255],\n",
      "        [255, 255, 255, 255],\n",
      "        [255, 255, 255, 255],\n",
      "        [ -1,  -1,   0,   0]],\n",
      "\n",
      "       [[ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [  2,   0, 254,   0],\n",
      "        [  0,   0,   0,   0],\n",
      "        [  0,   0,   0,   0],\n",
      "        [  0,   1,   0,   0],\n",
      "        [255, 255, 255, 255],\n",
      "        [  0,   0,   0,   0],\n",
      "        [  0,   0,   0,   0],\n",
      "        [ -1,  -1,   0,   0]],\n",
      "\n",
      "       [[ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [  0,   0,   0,   0],\n",
      "        [  0,   2,   0,   0],\n",
      "        [  1,   2,  42,   0],\n",
      "        [  0,   2,   0,   0],\n",
      "        [  0,   2,   0,   0],\n",
      "        [  0,   0,   0,   0],\n",
      "        [  0,   0,   0,   0],\n",
      "        [ -1,  -1,   0,   0]],\n",
      "\n",
      "       [[ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [  0,   2,   0,   0],\n",
      "        [  0,   2,   0,   0],\n",
      "        [  0,   2,   0,   0],\n",
      "        [  0,   0,   0,   0],\n",
      "        [  0,   0,   0,   0],\n",
      "        [  0,   0,   0,   0],\n",
      "        [  0,   0,   0,   0],\n",
      "        [ -1,  -1,   0,   0]],\n",
      "\n",
      "       [[ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [  0,   2,   0,   0],\n",
      "        [  0,   2,   0,   0],\n",
      "        [  0,   0,   0,   0],\n",
      "        [  0,   0,   0,   0],\n",
      "        [  0,   0,   0,   0],\n",
      "        [  0,   0,   0,   0],\n",
      "        [  0,   0,   0,   0],\n",
      "        [ -1,  -1,   0,   0]],\n",
      "\n",
      "       [[ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0]],\n",
      "\n",
      "       [[ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0]],\n",
      "\n",
      "       [[ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0]]]), 'turn_info': array([1, 1, 1]), 'health_pct': array([0.16666667]), 'health_enemy': array([1.]), 'enemy_reactions': array([0]), 'ability_info': array([0, 0, 0, 0, 0, 0, 0, 0]), 'movement': 8}, {'map': array([[[ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0]],\n",
      "\n",
      "       [[ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0]],\n",
      "\n",
      "       [[ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0]],\n",
      "\n",
      "       [[ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [  0,   0,   0,   0],\n",
      "        [  0,   0,   0,   0],\n",
      "        [  0,   0,   0,   0],\n",
      "        [  0,   0,   0,   0],\n",
      "        [255, 255, 255, 255],\n",
      "        [255, 255, 255, 255],\n",
      "        [255, 255, 255, 255],\n",
      "        [ -1,  -1,   0,   0]],\n",
      "\n",
      "       [[ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [  0,   0,   0,   0],\n",
      "        [  0,   0,   0,   0],\n",
      "        [  0,   0,   0,   0],\n",
      "        [255, 255, 255, 255],\n",
      "        [255, 255, 255, 255],\n",
      "        [255, 255, 255, 255],\n",
      "        [255, 255, 255, 255],\n",
      "        [ -1,  -1,   0,   0]],\n",
      "\n",
      "       [[ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [  2,   0, 254,   0],\n",
      "        [  0,   0,   0,   0],\n",
      "        [  0,   0,   0,   0],\n",
      "        [  0,   1,   0,   0],\n",
      "        [255, 255, 255, 255],\n",
      "        [  0,   0,   0,   0],\n",
      "        [  0,   0,   0,   0],\n",
      "        [ -1,  -1,   0,   0]],\n",
      "\n",
      "       [[ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [  0,   0,   0,   0],\n",
      "        [  0,   2,   0,   0],\n",
      "        [  1,   2,  42,   0],\n",
      "        [  0,   2,   0,   0],\n",
      "        [  0,   2,   0,   0],\n",
      "        [  0,   0,   0,   0],\n",
      "        [  0,   0,   0,   0],\n",
      "        [ -1,  -1,   0,   0]],\n",
      "\n",
      "       [[ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [  0,   2,   0,   0],\n",
      "        [  0,   2,   0,   0],\n",
      "        [  0,   2,   0,   0],\n",
      "        [  0,   0,   0,   0],\n",
      "        [  0,   0,   0,   0],\n",
      "        [  0,   0,   0,   0],\n",
      "        [  0,   0,   0,   0],\n",
      "        [ -1,  -1,   0,   0]],\n",
      "\n",
      "       [[ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [  0,   2,   0,   0],\n",
      "        [  0,   2,   0,   0],\n",
      "        [  0,   0,   0,   0],\n",
      "        [  0,   0,   0,   0],\n",
      "        [  0,   0,   0,   0],\n",
      "        [  0,   0,   0,   0],\n",
      "        [  0,   0,   0,   0],\n",
      "        [ -1,  -1,   0,   0]],\n",
      "\n",
      "       [[ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0]],\n",
      "\n",
      "       [[ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0]],\n",
      "\n",
      "       [[ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0]]]), 'turn_info': array([0, 1, 1]), 'health_pct': array([0.16666667]), 'health_enemy': array([1.]), 'enemy_reactions': array([0]), 'ability_info': array([0, 0, 0, 0, 0, 0, 0, 0]), 'movement': 8}, {'map': array([[[ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0]],\n",
      "\n",
      "       [[ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0]],\n",
      "\n",
      "       [[ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0]],\n",
      "\n",
      "       [[ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [  0,   0,   0,   0],\n",
      "        [  0,   0,   0,   0],\n",
      "        [  0,   0,   0,   0],\n",
      "        [  0,   0,   0,   0],\n",
      "        [255, 255, 255, 255],\n",
      "        [255, 255, 255, 255],\n",
      "        [255, 255, 255, 255],\n",
      "        [ -1,  -1,   0,   0]],\n",
      "\n",
      "       [[ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [  0,   0,   0,   0],\n",
      "        [  0,   0,   0,   0],\n",
      "        [  0,   0,   0,   0],\n",
      "        [255, 255, 255, 255],\n",
      "        [255, 255, 255, 255],\n",
      "        [255, 255, 255, 255],\n",
      "        [255, 255, 255, 255],\n",
      "        [ -1,  -1,   0,   0]],\n",
      "\n",
      "       [[ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [  0,   0,   0,   0],\n",
      "        [  0,   0,   0,   0],\n",
      "        [  0,   0,   0,   0],\n",
      "        [  0,   1,   0,   0],\n",
      "        [255, 255, 255, 255],\n",
      "        [  0,   0,   0,   0],\n",
      "        [  0,   0,   0,   0],\n",
      "        [ -1,  -1,   0,   0]],\n",
      "\n",
      "       [[ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [  0,   0,   0,   0],\n",
      "        [  2,   2, 254,   0],\n",
      "        [  1,   2,  42,   0],\n",
      "        [  0,   2,   0,   0],\n",
      "        [  0,   2,   0,   0],\n",
      "        [  0,   0,   0,   0],\n",
      "        [  0,   0,   0,   0],\n",
      "        [ -1,  -1,   0,   0]],\n",
      "\n",
      "       [[ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [  0,   2,   0,   0],\n",
      "        [  0,   2,   0,   0],\n",
      "        [  0,   2,   0,   0],\n",
      "        [  0,   0,   0,   0],\n",
      "        [  0,   0,   0,   0],\n",
      "        [  0,   0,   0,   0],\n",
      "        [  0,   0,   0,   0],\n",
      "        [ -1,  -1,   0,   0]],\n",
      "\n",
      "       [[ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [  0,   2,   0,   0],\n",
      "        [  0,   2,   0,   0],\n",
      "        [  0,   0,   0,   0],\n",
      "        [  0,   0,   0,   0],\n",
      "        [  0,   0,   0,   0],\n",
      "        [  0,   0,   0,   0],\n",
      "        [  0,   0,   0,   0],\n",
      "        [ -1,  -1,   0,   0]],\n",
      "\n",
      "       [[ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0]],\n",
      "\n",
      "       [[ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0]],\n",
      "\n",
      "       [[ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0]]]), 'turn_info': array([1, 1, 1]), 'health_pct': array([0.16666667]), 'health_enemy': array([1.]), 'enemy_reactions': array([1]), 'ability_info': array([0, 0, 0, 0, 0, 0, 0, 0]), 'movement': 25}, {'map': array([[[ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0]],\n",
      "\n",
      "       [[ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0]],\n",
      "\n",
      "       [[ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0]],\n",
      "\n",
      "       [[ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [  0,   0,   0,   0],\n",
      "        [  0,   0,   0,   0],\n",
      "        [  0,   0,   0,   0],\n",
      "        [  0,   0,   0,   0],\n",
      "        [255, 255, 255, 255],\n",
      "        [255, 255, 255, 255],\n",
      "        [255, 255, 255, 255],\n",
      "        [ -1,  -1,   0,   0]],\n",
      "\n",
      "       [[ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [  0,   0,   0,   0],\n",
      "        [  0,   0,   0,   0],\n",
      "        [  0,   0,   0,   0],\n",
      "        [255, 255, 255, 255],\n",
      "        [255, 255, 255, 255],\n",
      "        [255, 255, 255, 255],\n",
      "        [255, 255, 255, 255],\n",
      "        [ -1,  -1,   0,   0]],\n",
      "\n",
      "       [[ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [  0,   0,   0,   0],\n",
      "        [  0,   0,   0,   0],\n",
      "        [  0,   0,   0,   0],\n",
      "        [  0,   1,   0,   0],\n",
      "        [255, 255, 255, 255],\n",
      "        [  0,   0,   0,   0],\n",
      "        [  0,   0,   0,   0],\n",
      "        [ -1,  -1,   0,   0]],\n",
      "\n",
      "       [[ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [  0,   0,   0,   0],\n",
      "        [  2,   2, 254,   0],\n",
      "        [  1,   2,  42,   0],\n",
      "        [  0,   2,   0,   0],\n",
      "        [  0,   2,   0,   0],\n",
      "        [  0,   0,   0,   0],\n",
      "        [  0,   0,   0,   0],\n",
      "        [ -1,  -1,   0,   0]],\n",
      "\n",
      "       [[ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [  0,   2,   0,   0],\n",
      "        [  0,   2,   0,   0],\n",
      "        [  0,   2,   0,   0],\n",
      "        [  0,   0,   0,   0],\n",
      "        [  0,   0,   0,   0],\n",
      "        [  0,   0,   0,   0],\n",
      "        [  0,   0,   0,   0],\n",
      "        [ -1,  -1,   0,   0]],\n",
      "\n",
      "       [[ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [  0,   2,   0,   0],\n",
      "        [  0,   2,   0,   0],\n",
      "        [  0,   0,   0,   0],\n",
      "        [  0,   0,   0,   0],\n",
      "        [  0,   0,   0,   0],\n",
      "        [  0,   0,   0,   0],\n",
      "        [  0,   0,   0,   0],\n",
      "        [ -1,  -1,   0,   0]],\n",
      "\n",
      "       [[ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0]],\n",
      "\n",
      "       [[ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0]],\n",
      "\n",
      "       [[ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0]]]), 'turn_info': array([0, 1, 1]), 'health_pct': array([0.16666667]), 'health_enemy': array([1.]), 'enemy_reactions': array([1]), 'ability_info': array([0, 0, 0, 0, 0, 0, 0, 0]), 'movement': 25}, {'map': array([[[ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0]],\n",
      "\n",
      "       [[ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0]],\n",
      "\n",
      "       [[ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0]],\n",
      "\n",
      "       [[ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [  0,   0,   0,   0],\n",
      "        [  0,   0,   0,   0],\n",
      "        [  0,   0,   0,   0],\n",
      "        [  0,   0,   0,   0],\n",
      "        [  0,   0,   0,   0],\n",
      "        [  0,   0,   0,   0],\n",
      "        [255, 255, 255, 255]],\n",
      "\n",
      "       [[ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [  0,   0,   0,   0],\n",
      "        [  0,   0,   0,   0],\n",
      "        [  0,   0,   0,   0],\n",
      "        [  0,   0,   0,   0],\n",
      "        [255, 255, 255, 255],\n",
      "        [255, 255, 255, 255],\n",
      "        [255, 255, 255, 255]],\n",
      "\n",
      "       [[ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [  0,   0,   0,   0],\n",
      "        [  0,   0,   0,   0],\n",
      "        [  0,   0,   0,   0],\n",
      "        [  0,   1,   0,   0],\n",
      "        [255, 255, 255, 255],\n",
      "        [255, 255, 255, 255],\n",
      "        [  0,   0,   0,   0]],\n",
      "\n",
      "       [[ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [  0,   0,   0,   0],\n",
      "        [  1,   2, 254,   0],\n",
      "        [  2,   2,   0,  17],\n",
      "        [  0,   2,   0,   0],\n",
      "        [  0,   2,   0,   0],\n",
      "        [  0,   0,   0,   0],\n",
      "        [  0,   0,   0,   0]],\n",
      "\n",
      "       [[ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [  0,   2,   0,   0],\n",
      "        [  0,   2,   0,   0],\n",
      "        [  0,   2,   0,   0],\n",
      "        [  0,   0,   0,   0],\n",
      "        [  0,   0,   0,   0],\n",
      "        [  0,   0,   0,   0],\n",
      "        [  0,   0,   0,   0]],\n",
      "\n",
      "       [[ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [  0,   2,   0,   0],\n",
      "        [  0,   2,   0,   0],\n",
      "        [  0,   0,   0,   0],\n",
      "        [  0,   0,   0,   0],\n",
      "        [  0,   0,   0,   0],\n",
      "        [  0,   0,   0,   0],\n",
      "        [  0,   0,   0,   0]],\n",
      "\n",
      "       [[ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0]],\n",
      "\n",
      "       [[ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0]],\n",
      "\n",
      "       [[ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0],\n",
      "        [ -1,  -1,   0,   0]]]), 'turn_info': array([0, 1, 1]), 'health_pct': array([0.]), 'health_enemy': array([1.]), 'enemy_reactions': array([1]), 'ability_info': array([0, 0, 0, 0, 0, 0, 0, 0]), 'movement': 25}], [(1, (-1, -1), (0, 0), 0, 0), (-1, (0, 0), (0, 0), 0, 0), (-1, (0, 0), (0, 0), 0, 0), (10, (-1, -1), (0, 0), 0, 0), (6, (-1, -1), (0, 0), 0, 0), (1, (1, 1), (0, 0), 0, 0), (2, (-1, -1), (0, 0), 0, 0), (-1, (0, 0), (0, 0), 0, 0), (2, (-1, -1), (0, 0), 0, 0), (-1, (0, 0), (0, 0), 0, 0), (-1, (0, 0), (0, 0), 0, 0)], [0, 0, 0, 0, 0, 0, 0, 0, 0, -10], [False, False, False, False, False, False, False, False, False, True], [False, False, False, False, False, False, False, False, False, False], [{'available_moves': [(0, (0, 0), (-1, -2), 1, 1), (4, (-1, -1), (0, 0), 0, 0), (2, (-1, -1), (0, 0), 0, 0), (3, (-1, -1), (0, 0), 0, 0), (1, (-1, -1), (0, 0), 0, 0), (1, (-1, 0), (0, 0), 0, 0), (1, (-1, 1), (0, 0), 0, 0), (1, (0, -1), (0, 0), 0, 0), (1, (0, 1), (0, 0), 0, 0), (1, (1, 0), (0, 0), 0, 0), (1, (1, 1), (0, 0), 0, 0), (10, (-1, -1), (0, 0), 0, 0), (-1, (0, 0), (0, 0), 0, 0)], 'current_index': 0, 'group': 'a', 'round': 0, 'weapon_mappings': {'battleaxe': 0, 'dagger': 1, 'quarterstaff': 2, 'sling': 3, 'dart': 4, 'greatclub': 5, 'hand_crossbow': 6, 'handaxe': 7, 'javelin': 8, 'light_crossbow': 9, 'light_hammer': 10, 'longbow': 11, 'longsword': 12, 'rapier': 13, 'scimitar': 14, 'shortsword': 15, 'shortbow': 16, 'spear': 17, 'torch': 18, 'unarmed_attack': 19, 'vicious_rapier': 20, 'warhammer': 21}, 'spell_mappings': {'chill_touch': 100, 'expeditious_retreat': 101, 'find_familiar': 102, 'firebolt': 103, 'mage_armor': 104, 'magic_missile': 105, 'ray_of_frost': 106, 'shield': 107, 'shocking_grasp': 108, 'true_strike': 109}}, {'available_moves': [(0, (0, 0), (0, -1), 1, 0), (0, (0, 0), (0, -1), 1, 1), (0, (0, 0), (0, -1), 18, 0), (0, (0, 0), (0, -1), 19, 0), (4, (-1, -1), (0, 0), 0, 0), (2, (-1, -1), (0, 0), 0, 0), (3, (-1, -1), (0, 0), 0, 0), (1, (-1, -1), (0, 0), 0, 0), (1, (-1, 0), (0, 0), 0, 0), (1, (-1, 1), (0, 0), 0, 0), (1, (0, 1), (0, 0), 0, 0), (1, (1, -1), (0, 0), 0, 0), (1, (1, 0), (0, 0), 0, 0), (1, (1, 1), (0, 0), 0, 0), (10, (-1, -1), (0, 0), 0, 0), (-1, (0, 0), (0, 0), 0, 0)], 'current_index': 0, 'group': 'a', 'round': 1, 'weapon_mappings': {'battleaxe': 0, 'dagger': 1, 'quarterstaff': 2, 'sling': 3, 'dart': 4, 'greatclub': 5, 'hand_crossbow': 6, 'handaxe': 7, 'javelin': 8, 'light_crossbow': 9, 'light_hammer': 10, 'longbow': 11, 'longsword': 12, 'rapier': 13, 'scimitar': 14, 'shortsword': 15, 'shortbow': 16, 'spear': 17, 'torch': 18, 'unarmed_attack': 19, 'vicious_rapier': 20, 'warhammer': 21}, 'spell_mappings': {'chill_touch': 100, 'expeditious_retreat': 101, 'find_familiar': 102, 'firebolt': 103, 'mage_armor': 104, 'magic_missile': 105, 'ray_of_frost': 106, 'shield': 107, 'shocking_grasp': 108, 'true_strike': 109}}, {'available_moves': [(0, (0, 0), (-1, 0), 1, 0), (0, (0, 0), (-1, 0), 1, 1), (0, (0, 0), (-1, 0), 18, 0), (0, (0, 0), (-1, 0), 19, 0), (4, (-1, -1), (0, 0), 0, 0), (2, (-1, -1), (0, 0), 0, 0), (3, (-1, -1), (0, 0), 0, 0), (1, (-1, -1), (0, 0), 0, 0), (1, (-1, 1), (0, 0), 0, 0), (1, (0, -1), (0, 0), 0, 0), (1, (0, 1), (0, 0), 0, 0), (1, (1, -1), (0, 0), 0, 0), (1, (1, 0), (0, 0), 0, 0), (1, (1, 1), (0, 0), 0, 0), (10, (-1, -1), (0, 0), 0, 0), (-1, (0, 0), (0, 0), 0, 0)], 'current_index': 0, 'group': 'a', 'round': 2, 'weapon_mappings': {'battleaxe': 0, 'dagger': 1, 'quarterstaff': 2, 'sling': 3, 'dart': 4, 'greatclub': 5, 'hand_crossbow': 6, 'handaxe': 7, 'javelin': 8, 'light_crossbow': 9, 'light_hammer': 10, 'longbow': 11, 'longsword': 12, 'rapier': 13, 'scimitar': 14, 'shortsword': 15, 'shortbow': 16, 'spear': 17, 'torch': 18, 'unarmed_attack': 19, 'vicious_rapier': 20, 'warhammer': 21}, 'spell_mappings': {'chill_touch': 100, 'expeditious_retreat': 101, 'find_familiar': 102, 'firebolt': 103, 'mage_armor': 104, 'magic_missile': 105, 'ray_of_frost': 106, 'shield': 107, 'shocking_grasp': 108, 'true_strike': 109}}, {'available_moves': [(0, (0, 0), (-1, 0), 1, 0), (0, (0, 0), (-1, 0), 1, 1), (0, (0, 0), (-1, 0), 18, 0), (0, (0, 0), (-1, 0), 19, 0), (4, (-1, -1), (0, 0), 0, 0), (2, (-1, -1), (0, 0), 0, 0), (3, (-1, -1), (0, 0), 0, 0), (1, (-1, -1), (0, 0), 0, 0), (1, (-1, 1), (0, 0), 0, 0), (1, (0, -1), (0, 0), 0, 0), (1, (0, 1), (0, 0), 0, 0), (1, (1, -1), (0, 0), 0, 0), (1, (1, 0), (0, 0), 0, 0), (1, (1, 1), (0, 0), 0, 0), (10, (-1, -1), (0, 0), 0, 0), (-1, (0, 0), (0, 0), 0, 0)], 'current_index': 0, 'group': 'a', 'round': 3, 'weapon_mappings': {'battleaxe': 0, 'dagger': 1, 'quarterstaff': 2, 'sling': 3, 'dart': 4, 'greatclub': 5, 'hand_crossbow': 6, 'handaxe': 7, 'javelin': 8, 'light_crossbow': 9, 'light_hammer': 10, 'longbow': 11, 'longsword': 12, 'rapier': 13, 'scimitar': 14, 'shortsword': 15, 'shortbow': 16, 'spear': 17, 'torch': 18, 'unarmed_attack': 19, 'vicious_rapier': 20, 'warhammer': 21}, 'spell_mappings': {'chill_touch': 100, 'expeditious_retreat': 101, 'find_familiar': 102, 'firebolt': 103, 'mage_armor': 104, 'magic_missile': 105, 'ray_of_frost': 106, 'shield': 107, 'shocking_grasp': 108, 'true_strike': 109}}, {'available_moves': [(0, (0, 0), (-1, 0), 1, 0), (0, (0, 0), (-1, 0), 1, 1), (0, (0, 0), (-1, 0), 18, 0), (0, (0, 0), (-1, 0), 19, 0), (4, (-1, -1), (0, 0), 0, 0), (2, (-1, -1), (0, 0), 0, 0), (3, (-1, -1), (0, 0), 0, 0), (1, (-1, -1), (0, 0), 0, 0), (1, (-1, 1), (0, 0), 0, 0), (1, (0, -1), (0, 0), 0, 0), (1, (0, 1), (0, 0), 0, 0), (1, (1, -1), (0, 0), 0, 0), (1, (1, 0), (0, 0), 0, 0), (1, (1, 1), (0, 0), 0, 0), (6, (-1, -1), (0, 0), 0, 0), (-1, (0, 0), (0, 0), 0, 0)], 'current_index': 0, 'group': 'a', 'round': 4, 'weapon_mappings': {'battleaxe': 0, 'dagger': 1, 'quarterstaff': 2, 'sling': 3, 'dart': 4, 'greatclub': 5, 'hand_crossbow': 6, 'handaxe': 7, 'javelin': 8, 'light_crossbow': 9, 'light_hammer': 10, 'longbow': 11, 'longsword': 12, 'rapier': 13, 'scimitar': 14, 'shortsword': 15, 'shortbow': 16, 'spear': 17, 'torch': 18, 'unarmed_attack': 19, 'vicious_rapier': 20, 'warhammer': 21}, 'spell_mappings': {'chill_touch': 100, 'expeditious_retreat': 101, 'find_familiar': 102, 'firebolt': 103, 'mage_armor': 104, 'magic_missile': 105, 'ray_of_frost': 106, 'shield': 107, 'shocking_grasp': 108, 'true_strike': 109}}, {'available_moves': [(0, (0, 0), (-1, 0), 1, 0), (0, (0, 0), (-1, 0), 1, 1), (0, (0, 0), (-1, 0), 18, 0), (0, (0, 0), (-1, 0), 19, 0), (4, (-1, -1), (0, 0), 0, 0), (2, (-1, -1), (0, 0), 0, 0), (3, (-1, -1), (0, 0), 0, 0), (1, (-1, -1), (0, 0), 0, 0), (1, (-1, 1), (0, 0), 0, 0), (1, (0, -1), (0, 0), 0, 0), (1, (0, 1), (0, 0), 0, 0), (1, (1, -1), (0, 0), 0, 0), (1, (1, 0), (0, 0), 0, 0), (1, (1, 1), (0, 0), 0, 0), (10, (-1, -1), (0, 0), 0, 0), (-1, (0, 0), (0, 0), 0, 0)], 'current_index': 0, 'group': 'a', 'round': 5, 'weapon_mappings': {'battleaxe': 0, 'dagger': 1, 'quarterstaff': 2, 'sling': 3, 'dart': 4, 'greatclub': 5, 'hand_crossbow': 6, 'handaxe': 7, 'javelin': 8, 'light_crossbow': 9, 'light_hammer': 10, 'longbow': 11, 'longsword': 12, 'rapier': 13, 'scimitar': 14, 'shortsword': 15, 'shortbow': 16, 'spear': 17, 'torch': 18, 'unarmed_attack': 19, 'vicious_rapier': 20, 'warhammer': 21}, 'spell_mappings': {'chill_touch': 100, 'expeditious_retreat': 101, 'find_familiar': 102, 'firebolt': 103, 'mage_armor': 104, 'magic_missile': 105, 'ray_of_frost': 106, 'shield': 107, 'shocking_grasp': 108, 'true_strike': 109}}, {'available_moves': [(0, (0, 0), (-2, -1), 1, 1), (4, (-1, -1), (0, 0), 0, 0), (2, (-1, -1), (0, 0), 0, 0), (3, (-1, -1), (0, 0), 0, 0), (10, (-1, -1), (0, 0), 0, 0), (-1, (0, 0), (0, 0), 0, 0)], 'current_index': 0, 'group': 'a', 'round': 6, 'weapon_mappings': {'battleaxe': 0, 'dagger': 1, 'quarterstaff': 2, 'sling': 3, 'dart': 4, 'greatclub': 5, 'hand_crossbow': 6, 'handaxe': 7, 'javelin': 8, 'light_crossbow': 9, 'light_hammer': 10, 'longbow': 11, 'longsword': 12, 'rapier': 13, 'scimitar': 14, 'shortsword': 15, 'shortbow': 16, 'spear': 17, 'torch': 18, 'unarmed_attack': 19, 'vicious_rapier': 20, 'warhammer': 21}, 'spell_mappings': {'chill_touch': 100, 'expeditious_retreat': 101, 'find_familiar': 102, 'firebolt': 103, 'mage_armor': 104, 'magic_missile': 105, 'ray_of_frost': 106, 'shield': 107, 'shocking_grasp': 108, 'true_strike': 109}}, {'available_moves': [(10, (-1, -1), (0, 0), 0, 0), (-1, (0, 0), (0, 0), 0, 0)], 'current_index': 0, 'group': 'a', 'round': 7, 'weapon_mappings': {'battleaxe': 0, 'dagger': 1, 'quarterstaff': 2, 'sling': 3, 'dart': 4, 'greatclub': 5, 'hand_crossbow': 6, 'handaxe': 7, 'javelin': 8, 'light_crossbow': 9, 'light_hammer': 10, 'longbow': 11, 'longsword': 12, 'rapier': 13, 'scimitar': 14, 'shortsword': 15, 'shortbow': 16, 'spear': 17, 'torch': 18, 'unarmed_attack': 19, 'vicious_rapier': 20, 'warhammer': 21}, 'spell_mappings': {'chill_touch': 100, 'expeditious_retreat': 101, 'find_familiar': 102, 'firebolt': 103, 'mage_armor': 104, 'magic_missile': 105, 'ray_of_frost': 106, 'shield': 107, 'shocking_grasp': 108, 'true_strike': 109}}, {'available_moves': [(0, (0, 0), (-1, 0), 1, 0), (0, (0, 0), (-1, 0), 1, 1), (0, (0, 0), (-1, 0), 18, 0), (0, (0, 0), (-1, 0), 19, 0), (4, (-1, -1), (0, 0), 0, 0), (2, (-1, -1), (0, 0), 0, 0), (3, (-1, -1), (0, 0), 0, 0), (1, (-1, -1), (0, 0), 0, 0), (1, (-1, 1), (0, 0), 0, 0), (1, (0, -1), (0, 0), 0, 0), (1, (0, 1), (0, 0), 0, 0), (1, (1, 0), (0, 0), 0, 0), (1, (1, 1), (0, 0), 0, 0), (10, (-1, -1), (0, 0), 0, 0), (-1, (0, 0), (0, 0), 0, 0)], 'current_index': 0, 'group': 'a', 'round': 8, 'weapon_mappings': {'battleaxe': 0, 'dagger': 1, 'quarterstaff': 2, 'sling': 3, 'dart': 4, 'greatclub': 5, 'hand_crossbow': 6, 'handaxe': 7, 'javelin': 8, 'light_crossbow': 9, 'light_hammer': 10, 'longbow': 11, 'longsword': 12, 'rapier': 13, 'scimitar': 14, 'shortsword': 15, 'shortbow': 16, 'spear': 17, 'torch': 18, 'unarmed_attack': 19, 'vicious_rapier': 20, 'warhammer': 21}, 'spell_mappings': {'chill_touch': 100, 'expeditious_retreat': 101, 'find_familiar': 102, 'firebolt': 103, 'mage_armor': 104, 'magic_missile': 105, 'ray_of_frost': 106, 'shield': 107, 'shocking_grasp': 108, 'true_strike': 109}}, {'available_moves': [(1, (-1, -1), (0, 0), 0, 0), (1, (-1, 1), (0, 0), 0, 0), (1, (0, -1), (0, 0), 0, 0), (1, (0, 1), (0, 0), 0, 0), (1, (1, 0), (0, 0), 0, 0), (1, (1, 1), (0, 0), 0, 0), (10, (-1, -1), (0, 0), 0, 0), (-1, (0, 0), (0, 0), 0, 0)], 'current_index': 0, 'group': 'a', 'round': 9, 'weapon_mappings': {'battleaxe': 0, 'dagger': 1, 'quarterstaff': 2, 'sling': 3, 'dart': 4, 'greatclub': 5, 'hand_crossbow': 6, 'handaxe': 7, 'javelin': 8, 'light_crossbow': 9, 'light_hammer': 10, 'longbow': 11, 'longsword': 12, 'rapier': 13, 'scimitar': 14, 'shortsword': 15, 'shortbow': 16, 'spear': 17, 'torch': 18, 'unarmed_attack': 19, 'vicious_rapier': 20, 'warhammer': 21}, 'spell_mappings': {'chill_touch': 100, 'expeditious_retreat': 101, 'find_familiar': 102, 'firebolt': 103, 'mage_armor': 104, 'magic_missile': 105, 'ray_of_frost': 106, 'shield': 107, 'shocking_grasp': 108, 'true_strike': 109}}, {'available_moves': [(1, (-1, -1), (0, 0), 0, 0), (1, (-1, 0), (0, 0), 0, 0), (1, (-1, 1), (0, 0), 0, 0), (1, (0, -1), (0, 0), 0, 0), (1, (0, 1), (0, 0), 0, 0), (1, (1, -1), (0, 0), 0, 0), (1, (1, 1), (0, 0), 0, 0), (10, (-1, -1), (0, 0), 0, 0), (-1, (0, 0), (0, 0), 0, 0)], 'current_index': 1, 'group': 'a', 'round': 10, 'weapon_mappings': {'battleaxe': 0, 'dagger': 1, 'quarterstaff': 2, 'sling': 3, 'dart': 4, 'greatclub': 5, 'hand_crossbow': 6, 'handaxe': 7, 'javelin': 8, 'light_crossbow': 9, 'light_hammer': 10, 'longbow': 11, 'longsword': 12, 'rapier': 13, 'scimitar': 14, 'shortsword': 15, 'shortbow': 16, 'spear': 17, 'torch': 18, 'unarmed_attack': 19, 'vicious_rapier': 20, 'warhammer': 21}, 'spell_mappings': {'chill_touch': 100, 'expeditious_retreat': 101, 'find_familiar': 102, 'firebolt': 103, 'mage_armor': 104, 'magic_missile': 105, 'ray_of_frost': 106, 'shield': 107, 'shocking_grasp': 108, 'true_strike': 109}}])\n"
     ]
    }
   ],
   "source": [
    "trajectory = generate_trajectory(env, model, epsilon=1.0)\n",
    "print(trajectory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "70c9eba611d447ba8a8c3b8726714e19",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading map from map_with_obstacles/maps/game_map.yml\n",
      "Creating new event manager\n",
      "==== Player Character ====\n",
      "name: gomerin\n",
      "level: 1\n",
      "character class: {'rogue': 1}\n",
      "hp: 18\n",
      "max hp: 18\n",
      "ac: 16\n",
      "speed: 25\n",
      "no spells\n",
      "\n",
      "\n",
      "\n",
      "==== Player Character ====\n",
      "name: rumblebelly\n",
      "level: 1\n",
      "character class: {'rogue': 1}\n",
      "hp: 18\n",
      "max hp: 18\n",
      "ac: 16\n",
      "speed: 25\n",
      "no spells\n",
      "\n",
      "\n",
      "\n",
      "==== end turn ===\n",
      "gomerin 18/18\n",
      "no spells\n",
      "rumblebelly 18/18\n",
      "no spells\n",
      "==== current turn rumblebelly 18/18 AC 16===\n",
      "no spells\n",
      "no move for rumblebelly\n",
      "==== current turn gomerin 4/18 AC 16===\n",
      "no spells\n",
      "Result: False\n",
      "==== end turn ===\n",
      "gomerin 4/18\n",
      "no spells\n",
      "rumblebelly 18/18\n",
      "no spells\n",
      "==== current turn rumblebelly 18/18 AC 16===\n",
      "no spells\n",
      "Result: tpk\n",
      "loading map from map_with_obstacles/maps/game_map.yml\n",
      "Creating new event manager\n",
      "==== Player Character ====\n",
      "name: gomerin\n",
      "level: 1\n",
      "character class: {'rogue': 1}\n",
      "hp: 18\n",
      "max hp: 18\n",
      "ac: 16\n",
      "speed: 25\n",
      "no spells\n",
      "\n",
      "\n",
      "\n",
      "==== Player Character ====\n",
      "name: rumblebelly\n",
      "level: 1\n",
      "character class: {'rogue': 1}\n",
      "hp: 18\n",
      "max hp: 18\n",
      "ac: 16\n",
      "speed: 25\n",
      "no spells\n",
      "\n",
      "\n",
      "\n",
      "no move for rumblebelly\n",
      "==== current turn gomerin 9/18 AC 16===\n",
      "no spells\n",
      "loading map from map_with_obstacles/maps/game_map.yml\n",
      "Creating new event manager\n",
      "==== Player Character ====\n",
      "name: gomerin\n",
      "level: 1\n",
      "character class: {'rogue': 1}\n",
      "hp: 18\n",
      "max hp: 18\n",
      "ac: 16\n",
      "speed: 25\n",
      "no spells\n",
      "\n",
      "\n",
      "\n",
      "==== Player Character ====\n",
      "name: rumblebelly\n",
      "level: 1\n",
      "character class: {'rogue': 1}\n",
      "hp: 18\n",
      "max hp: 18\n",
      "ac: 16\n",
      "speed: 25\n",
      "no spells\n",
      "\n",
      "\n",
      "\n",
      "==== end turn ===\n",
      "gomerin 18/18\n",
      "no spells\n",
      "rumblebelly 18/18\n",
      "no spells\n",
      "==== current turn rumblebelly 18/18 AC 16===\n",
      "no spells\n",
      "no move for rumblebelly\n",
      "==== current turn gomerin 18/18 AC 16===\n",
      "no spells\n",
      "Result: False\n",
      "==== end turn ===\n",
      "gomerin 18/18\n",
      "no spells\n",
      "rumblebelly 18/18\n",
      "no spells\n",
      "==== current turn rumblebelly 18/18 AC 16===\n",
      "no spells\n",
      "no move for rumblebelly\n",
      "==== current turn gomerin 18/18 AC 16===\n",
      "no spells\n",
      "Result: False\n",
      "==== end turn ===\n",
      "gomerin 18/18\n",
      "no spells\n",
      "rumblebelly 18/18\n",
      "no spells\n",
      "==== current turn rumblebelly 18/18 AC 16===\n",
      "no spells\n",
      "no move for rumblebelly\n",
      "==== current turn gomerin 9/18 AC 16===\n",
      "no spells\n",
      "Result: False\n",
      "==== end turn ===\n",
      "gomerin 9/18\n",
      "no spells\n",
      "rumblebelly 18/18\n",
      "no spells\n",
      "==== current turn rumblebelly 18/18 AC 16===\n",
      "no spells\n",
      "Result: tpk\n",
      "loading map from map_with_obstacles/maps/game_map.yml\n",
      "Creating new event manager\n",
      "==== Player Character ====\n",
      "name: gomerin\n",
      "level: 1\n",
      "character class: {'rogue': 1}\n",
      "hp: 18\n",
      "max hp: 18\n",
      "ac: 16\n",
      "speed: 25\n",
      "no spells\n",
      "\n",
      "\n",
      "\n",
      "==== Player Character ====\n",
      "name: rumblebelly\n",
      "level: 1\n",
      "character class: {'rogue': 1}\n",
      "hp: 18\n",
      "max hp: 18\n",
      "ac: 16\n",
      "speed: 25\n",
      "no spells\n",
      "\n",
      "\n",
      "\n",
      "no move for rumblebelly\n",
      "==== current turn gomerin 18/18 AC 16===\n",
      "no spells\n",
      "==== end turn ===\n",
      "gomerin 18/18\n",
      "no spells\n",
      "rumblebelly 18/18\n",
      "no spells\n",
      "==== current turn rumblebelly 18/18 AC 16===\n",
      "no spells\n",
      "no move for rumblebelly\n",
      "==== current turn gomerin 18/18 AC 16===\n",
      "no spells\n",
      "Result: False\n",
      "==== end turn ===\n",
      "gomerin 18/18\n",
      "no spells\n",
      "rumblebelly 18/18\n",
      "no spells\n",
      "==== current turn rumblebelly 18/18 AC 16===\n",
      "no spells\n",
      "no move for rumblebelly\n",
      "==== current turn gomerin 18/18 AC 16===\n",
      "no spells\n",
      "Result: False\n",
      "==== end turn ===\n",
      "gomerin 18/18\n",
      "no spells\n",
      "rumblebelly 18/18\n",
      "no spells\n",
      "==== current turn rumblebelly 18/18 AC 16===\n",
      "no spells\n",
      "no move for rumblebelly\n",
      "==== current turn gomerin 18/18 AC 16===\n",
      "no spells\n",
      "Result: False\n",
      "==== end turn ===\n",
      "gomerin 18/18\n",
      "no spells\n",
      "rumblebelly 18/18\n",
      "no spells\n",
      "==== current turn rumblebelly 18/18 AC 16===\n",
      "no spells\n",
      "no move for rumblebelly\n",
      "==== current turn gomerin 18/18 AC 16===\n",
      "no spells\n",
      "Result: False\n",
      "==== end turn ===\n",
      "gomerin 18/18\n",
      "no spells\n",
      "rumblebelly 18/18\n",
      "no spells\n",
      "==== current turn rumblebelly 18/18 AC 16===\n",
      "no spells\n",
      "no move for rumblebelly\n",
      "==== current turn gomerin 18/18 AC 16===\n",
      "no spells\n",
      "Result: False\n",
      "==== end turn ===\n",
      "gomerin 18/18\n",
      "no spells\n",
      "rumblebelly 18/18\n",
      "no spells\n",
      "==== current turn rumblebelly 18/18 AC 16===\n",
      "no spells\n",
      "no move for rumblebelly\n",
      "==== current turn gomerin 18/18 AC 16===\n",
      "no spells\n",
      "Result: False\n",
      "==== end turn ===\n",
      "gomerin 18/18\n",
      "no spells\n",
      "rumblebelly 18/18\n",
      "no spells\n",
      "==== current turn rumblebelly 18/18 AC 16===\n",
      "no spells\n",
      "no move for rumblebelly\n",
      "==== current turn gomerin 18/18 AC 16===\n",
      "no spells\n",
      "Result: False\n",
      "==== end turn ===\n",
      "gomerin 18/18\n",
      "no spells\n",
      "rumblebelly 18/18\n",
      "no spells\n",
      "==== current turn rumblebelly 18/18 AC 16===\n",
      "no spells\n",
      "no move for rumblebelly\n",
      "==== current turn gomerin 18/18 AC 16===\n",
      "no spells\n",
      "Result: False\n",
      "==== end turn ===\n",
      "gomerin 18/18\n",
      "no spells\n",
      "rumblebelly 18/18\n",
      "no spells\n",
      "==== current turn rumblebelly 18/18 AC 16===\n",
      "no spells\n",
      "no move for rumblebelly\n",
      "==== current turn gomerin 18/18 AC 16===\n",
      "no spells\n",
      "Result: False\n",
      "==== end turn ===\n",
      "gomerin 18/18\n",
      "no spells\n",
      "rumblebelly 18/18\n",
      "no spells\n",
      "==== current turn rumblebelly 18/18 AC 16===\n",
      "no spells\n",
      "no move for rumblebelly\n",
      "==== current turn gomerin 18/18 AC 16===\n",
      "no spells\n",
      "Result: False\n",
      "==== end turn ===\n",
      "gomerin 18/18\n",
      "no spells\n",
      "rumblebelly 18/18\n",
      "no spells\n",
      "==== current turn rumblebelly 18/18 AC 16===\n",
      "no spells\n",
      "no move for rumblebelly\n",
      "==== current turn gomerin 1/18 AC 16===\n",
      "no spells\n",
      "Result: False\n",
      "==== end turn ===\n",
      "gomerin 1/18\n",
      "no spells\n",
      "rumblebelly 18/18\n",
      "no spells\n",
      "==== current turn rumblebelly 18/18 AC 16===\n",
      "no spells\n",
      "no move for rumblebelly\n",
      "==== current turn gomerin 1/18 AC 16===\n",
      "no spells\n",
      "Result: False\n",
      "==== end turn ===\n",
      "gomerin 1/18\n",
      "no spells\n",
      "rumblebelly 18/18\n",
      "no spells\n",
      "==== current turn rumblebelly 18/18 AC 16===\n",
      "no spells\n",
      "no move for rumblebelly\n",
      "==== current turn gomerin 1/18 AC 16===\n",
      "no spells\n",
      "Result: False\n",
      "==== end turn ===\n",
      "gomerin 1/18\n",
      "no spells\n",
      "rumblebelly 18/18\n",
      "no spells\n",
      "==== current turn rumblebelly 18/18 AC 16===\n",
      "no spells\n",
      "Result: tpk\n",
      "loading map from map_with_obstacles/maps/game_map.yml\n",
      "Creating new event manager\n",
      "==== Player Character ====\n",
      "name: gomerin\n",
      "level: 1\n",
      "character class: {'rogue': 1}\n",
      "hp: 18\n",
      "max hp: 18\n",
      "ac: 16\n",
      "speed: 25\n",
      "no spells\n",
      "\n",
      "\n",
      "\n",
      "==== Player Character ====\n",
      "name: rumblebelly\n",
      "level: 1\n",
      "character class: {'rogue': 1}\n",
      "hp: 18\n",
      "max hp: 18\n",
      "ac: 16\n",
      "speed: 25\n",
      "no spells\n",
      "\n",
      "\n",
      "\n",
      "==== end turn ===\n",
      "gomerin 18/18\n",
      "no spells\n",
      "rumblebelly 18/18\n",
      "no spells\n",
      "==== current turn rumblebelly 18/18 AC 16===\n",
      "no spells\n",
      "no move for rumblebelly\n",
      "==== current turn gomerin 18/18 AC 16===\n",
      "no spells\n",
      "Result: False\n",
      "==== end turn ===\n",
      "gomerin 18/18\n",
      "no spells\n",
      "rumblebelly 18/18\n",
      "no spells\n",
      "==== current turn rumblebelly 18/18 AC 16===\n",
      "no spells\n",
      "no move for rumblebelly\n",
      "==== current turn gomerin 18/18 AC 16===\n",
      "no spells\n",
      "Result: False\n",
      "==== end turn ===\n",
      "gomerin 8/18\n",
      "no spells\n",
      "rumblebelly 18/18\n",
      "no spells\n",
      "==== current turn rumblebelly 18/18 AC 16===\n",
      "no spells\n",
      "Result: tpk\n",
      "loading map from map_with_obstacles/maps/game_map.yml\n",
      "Creating new event manager\n",
      "==== Player Character ====\n",
      "name: gomerin\n",
      "level: 1\n",
      "character class: {'rogue': 1}\n",
      "hp: 18\n",
      "max hp: 18\n",
      "ac: 16\n",
      "speed: 25\n",
      "no spells\n",
      "\n",
      "\n",
      "\n",
      "==== Player Character ====\n",
      "name: rumblebelly\n",
      "level: 1\n",
      "character class: {'rogue': 1}\n",
      "hp: 18\n",
      "max hp: 18\n",
      "ac: 16\n",
      "speed: 25\n",
      "no spells\n",
      "\n",
      "\n",
      "\n",
      "==== end turn ===\n",
      "gomerin 18/18\n",
      "no spells\n",
      "rumblebelly 18/18\n",
      "no spells\n",
      "==== current turn rumblebelly 18/18 AC 16===\n",
      "no spells\n",
      "no move for rumblebelly\n",
      "==== current turn gomerin 8/18 AC 16===\n",
      "no spells\n",
      "Result: False\n",
      "==== end turn ===\n",
      "gomerin 8/18\n",
      "no spells\n",
      "rumblebelly 18/18\n",
      "no spells\n",
      "==== current turn rumblebelly 18/18 AC 16===\n",
      "no spells\n",
      "no move for rumblebelly\n",
      "==== current turn gomerin 8/18 AC 16===\n",
      "no spells\n",
      "Result: False\n",
      "==== end turn ===\n",
      "gomerin 8/18\n",
      "no spells\n",
      "rumblebelly 18/18\n",
      "no spells\n",
      "==== current turn rumblebelly 18/18 AC 16===\n",
      "no spells\n",
      "Result: tpk\n",
      "loading map from map_with_obstacles/maps/game_map.yml\n",
      "Creating new event manager\n",
      "==== Player Character ====\n",
      "name: gomerin\n",
      "level: 1\n",
      "character class: {'rogue': 1}\n",
      "hp: 18\n",
      "max hp: 18\n",
      "ac: 16\n",
      "speed: 25\n",
      "no spells\n",
      "\n",
      "\n",
      "\n",
      "==== Player Character ====\n",
      "name: rumblebelly\n",
      "level: 1\n",
      "character class: {'rogue': 1}\n",
      "hp: 18\n",
      "max hp: 18\n",
      "ac: 16\n",
      "speed: 25\n",
      "no spells\n",
      "\n",
      "\n",
      "\n",
      "==== end turn ===\n",
      "gomerin 18/18\n",
      "no spells\n",
      "rumblebelly 12/18\n",
      "no spells\n",
      "==== current turn rumblebelly 12/18 AC 16===\n",
      "no spells\n",
      "no move for rumblebelly\n",
      "==== current turn gomerin 12/18 AC 16===\n",
      "no spells\n",
      "Result: False\n",
      "==== end turn ===\n",
      "gomerin 12/18\n",
      "no spells\n",
      "rumblebelly 12/18\n",
      "no spells\n",
      "==== current turn rumblebelly 12/18 AC 16===\n",
      "no spells\n",
      "no move for rumblebelly\n",
      "==== current turn gomerin 12/18 AC 16===\n",
      "no spells\n",
      "Result: False\n",
      "loading map from map_with_obstacles/maps/game_map.yml\n",
      "Creating new event manager\n",
      "==== Player Character ====\n",
      "name: gomerin\n",
      "level: 1\n",
      "character class: {'rogue': 1}\n",
      "hp: 18\n",
      "max hp: 18\n",
      "ac: 16\n",
      "speed: 25\n",
      "no spells\n",
      "\n",
      "\n",
      "\n",
      "==== Player Character ====\n",
      "name: rumblebelly\n",
      "level: 1\n",
      "character class: {'rogue': 1}\n",
      "hp: 18\n",
      "max hp: 18\n",
      "ac: 16\n",
      "speed: 25\n",
      "no spells\n",
      "\n",
      "\n",
      "\n",
      "no move for rumblebelly\n",
      "==== current turn gomerin 10/18 AC 16===\n",
      "no spells\n",
      "==== end turn ===\n",
      "gomerin 10/18\n",
      "no spells\n",
      "rumblebelly 18/18\n",
      "no spells\n",
      "==== current turn rumblebelly 18/18 AC 16===\n",
      "no spells\n",
      "no move for rumblebelly\n",
      "==== current turn gomerin 1/18 AC 16===\n",
      "no spells\n",
      "Result: False\n",
      "==== end turn ===\n",
      "gomerin 1/18\n",
      "no spells\n",
      "rumblebelly 18/18\n",
      "no spells\n",
      "==== current turn rumblebelly 18/18 AC 16===\n",
      "no spells\n",
      "Result: tpk\n",
      "loading map from map_with_obstacles/maps/game_map.yml\n",
      "Creating new event manager\n",
      "==== Player Character ====\n",
      "name: gomerin\n",
      "level: 1\n",
      "character class: {'rogue': 1}\n",
      "hp: 18\n",
      "max hp: 18\n",
      "ac: 16\n",
      "speed: 25\n",
      "no spells\n",
      "\n",
      "\n",
      "\n",
      "==== Player Character ====\n",
      "name: rumblebelly\n",
      "level: 1\n",
      "character class: {'rogue': 1}\n",
      "hp: 18\n",
      "max hp: 18\n",
      "ac: 16\n",
      "speed: 25\n",
      "no spells\n",
      "\n",
      "\n",
      "\n",
      "no move for rumblebelly\n",
      "==== current turn gomerin 7/18 AC 16===\n",
      "no spells\n",
      "==== end turn ===\n",
      "gomerin 7/18\n",
      "no spells\n",
      "rumblebelly 18/18\n",
      "no spells\n",
      "==== current turn rumblebelly 18/18 AC 16===\n",
      "no spells\n",
      "no move for rumblebelly\n",
      "==== current turn gomerin 7/18 AC 16===\n",
      "no spells\n",
      "Result: False\n",
      "==== end turn ===\n",
      "gomerin 7/18\n",
      "no spells\n",
      "rumblebelly 18/18\n",
      "no spells\n",
      "==== current turn rumblebelly 18/18 AC 16===\n",
      "no spells\n",
      "Result: tpk\n",
      "loading map from map_with_obstacles/maps/game_map.yml\n",
      "Creating new event manager\n",
      "==== Player Character ====\n",
      "name: gomerin\n",
      "level: 1\n",
      "character class: {'rogue': 1}\n",
      "hp: 18\n",
      "max hp: 18\n",
      "ac: 16\n",
      "speed: 25\n",
      "no spells\n",
      "\n",
      "\n",
      "\n",
      "==== Player Character ====\n",
      "name: rumblebelly\n",
      "level: 1\n",
      "character class: {'rogue': 1}\n",
      "hp: 18\n",
      "max hp: 18\n",
      "ac: 16\n",
      "speed: 25\n",
      "no spells\n",
      "\n",
      "\n",
      "\n",
      "==== end turn ===\n",
      "gomerin 18/18\n",
      "no spells\n",
      "rumblebelly 18/18\n",
      "no spells\n",
      "==== current turn rumblebelly 18/18 AC 16===\n",
      "no spells\n",
      "no move for rumblebelly\n",
      "==== current turn gomerin 11/18 AC 16===\n",
      "no spells\n",
      "Result: False\n",
      "==== end turn ===\n",
      "gomerin 11/18\n",
      "no spells\n",
      "rumblebelly 11/18\n",
      "no spells\n",
      "==== current turn rumblebelly 11/18 AC 16===\n",
      "no spells\n",
      "no move for rumblebelly\n",
      "==== current turn gomerin 4/18 AC 16===\n",
      "no spells\n",
      "Result: False\n",
      "==== end turn ===\n",
      "gomerin 4/18\n",
      "no spells\n",
      "rumblebelly 11/18\n",
      "no spells\n",
      "==== current turn rumblebelly 11/18 AC 16===\n",
      "no spells\n",
      "no move for rumblebelly\n",
      "==== current turn gomerin 4/18 AC 16===\n",
      "no spells\n",
      "Result: False\n",
      "==== end turn ===\n",
      "gomerin 4/18\n",
      "no spells\n",
      "rumblebelly 11/18\n",
      "no spells\n",
      "==== current turn rumblebelly 11/18 AC 16===\n",
      "no spells\n",
      "no move for rumblebelly\n",
      "==== current turn gomerin 4/18 AC 16===\n",
      "no spells\n",
      "Result: False\n",
      "==== end turn ===\n",
      "gomerin 4/18\n",
      "no spells\n",
      "rumblebelly 11/18\n",
      "no spells\n",
      "==== current turn rumblebelly 11/18 AC 16===\n",
      "no spells\n",
      "no move for rumblebelly\n",
      "==== current turn gomerin 4/18 AC 16===\n",
      "no spells\n",
      "Result: False\n",
      "==== end turn ===\n",
      "gomerin 4/18\n",
      "no spells\n",
      "rumblebelly 11/18\n",
      "no spells\n",
      "==== current turn rumblebelly 11/18 AC 16===\n",
      "no spells\n",
      "no move for rumblebelly\n",
      "==== current turn gomerin 4/18 AC 16===\n",
      "no spells\n",
      "Result: False\n",
      "==== end turn ===\n",
      "gomerin 4/18\n",
      "no spells\n",
      "rumblebelly 11/18\n",
      "no spells\n",
      "==== current turn rumblebelly 11/18 AC 16===\n",
      "no spells\n",
      "no move for rumblebelly\n",
      "==== current turn gomerin 3/18 AC 16===\n",
      "no spells\n",
      "Result: False\n",
      "==== end turn ===\n",
      "gomerin 3/18\n",
      "no spells\n",
      "rumblebelly 11/18\n",
      "no spells\n",
      "==== current turn rumblebelly 11/18 AC 16===\n",
      "no spells\n",
      "no move for rumblebelly\n",
      "==== current turn gomerin 3/18 AC 16===\n",
      "no spells\n",
      "Result: False\n",
      "==== end turn ===\n",
      "gomerin 3/18\n",
      "no spells\n",
      "rumblebelly 11/18\n",
      "no spells\n",
      "==== current turn rumblebelly 11/18 AC 16===\n",
      "no spells\n",
      "no move for rumblebelly\n",
      "==== current turn gomerin 2/18 AC 16===\n",
      "no spells\n",
      "Result: False\n",
      "==== end turn ===\n",
      "gomerin 2/18\n",
      "no spells\n",
      "rumblebelly 11/18\n",
      "no spells\n",
      "==== current turn rumblebelly 11/18 AC 16===\n",
      "no spells\n",
      "no move for rumblebelly\n",
      "==== current turn gomerin 2/18 AC 16===\n",
      "no spells\n",
      "Result: False\n",
      "==== end turn ===\n",
      "gomerin 2/18\n",
      "no spells\n",
      "rumblebelly 11/18\n",
      "no spells\n",
      "==== current turn rumblebelly 11/18 AC 16===\n",
      "no spells\n",
      "no move for rumblebelly\n",
      "==== current turn gomerin 1/18 AC 16===\n",
      "no spells\n",
      "Result: False\n",
      "Average reward: -10.0 Total Reward: -100\n"
     ]
    }
   ],
   "source": [
    "EPISODES = 10\n",
    "total_rewards = 0\n",
    "for i in tqdm.tqdm(range(EPISODES)):\n",
    "    states, actions, rewards, dones, truncateds, infos = generate_trajectory(env, model, epsilon=1.0)\n",
    "    total_rewards += sum(rewards)\n",
    "\n",
    "avg_reward = total_rewards/EPISODES\n",
    "print(f\"Average reward: {avg_reward} Total Reward: {total_rewards}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReplayBuffer:\n",
    "    def __init__(self, capacity):\n",
    "        self.buffer = collections.deque(maxlen=capacity)\n",
    "\n",
    "    def push(self, states, actions, rewards, infos, is_terminal):\n",
    "        self.buffer.append((states, actions, rewards, infos, is_terminal))\n",
    "\n",
    "    def sample(self, batch_size):\n",
    "        indices = np.random.choice(len(self.buffer), batch_size)\n",
    "        states, actions, rewards, infos, is_terminals = zip(*[self.buffer[idx] for idx in indices])\n",
    "        return states, actions, rewards, infos, is_terminals\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.buffer)\n",
    "    \n",
    "    # memory usage of the buffer in bytes\n",
    "    def memory_usage(self):\n",
    "        total_size = 0\n",
    "        for item in self.buffer:\n",
    "            states, actions, rewards, infos, is_terminals = item\n",
    "            for s in states:\n",
    "                total_size += sys.getsizeof(s)\n",
    "            total_size += sys.getsizeof(actions)\n",
    "            total_size += sys.getsizeof(rewards)\n",
    "            total_size += sys.getsizeof(infos)\n",
    "            total_size += sys.getsizeof(is_terminals)\n",
    "\n",
    "        return total_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate a batch of trajectories and store them in the replay buffer\n",
    "def generate_batch_trajectories(env, model, n_rollout, replay_buffer: ReplayBuffer, temperature=5.0, epsilon=0.1, horizon=30, policy='e-greedy'):\n",
    "    # print(f\"generating {n_rollout} rollouts\")\n",
    "    for _ in range(n_rollout):\n",
    "        state, action, reward, done, truncated, info = generate_trajectory(env, model, temperature=temperature,\n",
    "                                                                           epsilon=epsilon,\n",
    "                                                                           horizon=horizon,policy=policy)\n",
    "        replay_buffer.push(state, action, reward, info, done)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(env, gamma, learning_rate, max_steps=MAX_STEPS, use_td_target=True,\n",
    "          trajectory_policy='e-greedy',\n",
    "          label=\"dnd_egreedy\",\n",
    "          n_rollout=8,\n",
    "          seed=1337):\n",
    "  print(f\"training with gamma {gamma} and learning rate {learning_rate}\")\n",
    "  env.seed(seed)\n",
    "\n",
    "  replay_buffer = ReplayBuffer(BUFFER_CAPACITY)\n",
    "  # load model checkpoint if available\n",
    "  model = QNetwork(device).to(device)\n",
    "  target_model = QNetwork(device).to(device)\n",
    "\n",
    "  # intialize target network with the same weights as the model\n",
    "  target_model.load_state_dict(model.state_dict())\n",
    "\n",
    "  optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "  best_avg = -10\n",
    "  best_step = 0\n",
    "  temperature = 5.0\n",
    "  reward_per_episode = []\n",
    "  epsilon = EPSILON_START\n",
    "\n",
    "  for step in tqdm.tqdm(range(max_steps)):\n",
    "    generate_batch_trajectories(env, model, n_rollout, replay_buffer, temperature=temperature,\n",
    "                                epsilon=epsilon, policy=trajectory_policy, horizon=T_HORIZON)\n",
    "\n",
    "    states, actions, rewards, infos, is_terminals = replay_buffer.sample(BATCH_SIZE)\n",
    "    rewards_collected = 0\n",
    "    for _ in range(NUM_UPDATES):\n",
    "      rewards_collected = 0\n",
    "      total_loss = 0.0\n",
    "      \n",
    "      for i in range(len(states)):\n",
    "        s = states[i]\n",
    "        a = actions[i]\n",
    "        env_info = infos[i]\n",
    "        r = torch.tensor(rewards[i]).to(device).unsqueeze(1)\n",
    "        is_terminal = torch.tensor(is_terminals[i]).float().to(device).unsqueeze(1)\n",
    "        \n",
    "        if use_td_target:\n",
    "          with torch.no_grad():\n",
    "            s_next = s[1:]\n",
    "            a_next = a[1:]\n",
    "            q_targets = target_model(s_next, a_next).detach()\n",
    "        else: # Q-learning target == \"slow\"\n",
    "          with torch.no_grad():\n",
    "            s_next = s[1:]\n",
    "            s_info = env_info[1:]\n",
    "            q_targets = torch.zeros(len(s_next)).to(device)\n",
    "            \n",
    "            for index in range(len(s_info)):\n",
    "              info = s_info[index]\n",
    "              state = s_next[index]\n",
    "              \n",
    "              if len(state) == 0:\n",
    "                q_targets[index] = 0\n",
    "                continue\n",
    "              \n",
    "              total_available_moves = len(info[\"available_moves\"])\n",
    "              states_t = [state] * total_available_moves\n",
    "              avail_actions = info[\"available_moves\"]\n",
    "              assert len(states_t) > 0, \"No available states\"\n",
    "              assert len(avail_actions) > 0, \"No available moves\"\n",
    "              \n",
    "              q_values = target_model(states_t, avail_actions).detach().squeeze(1)\n",
    "              if len(q_values) == 0:\n",
    "                q_targets[index] = 0\n",
    "              else:\n",
    "                q_targets[index] = torch.max(q_values).item()\n",
    "\n",
    "            q_targets = q_targets.unsqueeze(1)\n",
    "            assert q_targets.shape == r.shape, f\"q_targets shape {q_targets.shape} != r shape {r.shape}\"\n",
    "\n",
    "        targets = r + gamma * q_targets * (1 - is_terminal)\n",
    "        \n",
    "        s_input = s[0:-1]\n",
    "        a_input = a[0:-1]\n",
    "        output = model(s_input, a_input)\n",
    "        q_sa = output\n",
    "\n",
    "        value_loss = nn.MSELoss()(q_sa, targets)\n",
    "        optimizer.zero_grad()\n",
    "        value_loss.backward()\n",
    "        total_loss += value_loss.item()\n",
    "        rewards_collected += r.sum().item()\n",
    "        optimizer.step()\n",
    "\n",
    "    # save model checkpoint\n",
    "\n",
    "    if step % 10 == 0:\n",
    "      # torch.save(model.state_dict(), f\"model_{step}.pt\")\n",
    "      eval_rewards = []\n",
    "      for _ in range(EVAL_STEPS):\n",
    "        _, _, rewards, _, _, _ = generate_trajectory(env, model, policy='greedy')\n",
    "        total_reward = sum(rewards)\n",
    "        eval_rewards.append(total_reward)\n",
    "        \n",
    "      avg_rewards = np.mean(eval_rewards)\n",
    "      std_rewards = np.std(eval_rewards)\n",
    "      # print(f\"eval rewards: {avg_rewards}\")\n",
    "      reward_per_episode.append(avg_rewards)\n",
    "\n",
    "      # print(f\"total reward: {total_reward}\")\n",
    "      if trajectory_policy == \"e-greedy\":\n",
    "        print(f\"{step}: avg rewards {avg_rewards} std: {std_rewards} best avg {best_avg}@{best_step} epsilon {epsilon}\")\n",
    "      elif trajectory_policy == \"boltzmann\":\n",
    "        print(f\"{step}: avg rewards {avg_rewards} std: {std_rewards} best avg {best_avg}@{best_step} temperature {temperature}\")\n",
    "      else:\n",
    "        print(f\"{step}: avg rewards {avg_rewards} std: {std_rewards} best avg {best_avg}@{best_step}\")\n",
    "\n",
    "      if avg_rewards > best_avg:\n",
    "        print(f\"best: {avg_rewards}\")\n",
    "        best_avg = avg_rewards\n",
    "        best_step = step\n",
    "        torch.save(model.state_dict(), f\"model_best_{label}.pt\")\n",
    "\n",
    "      # torch.save(model.state_dict(), f\"model_{label}_{gamma}_{learning_rate}.pt\")\n",
    "\n",
    "\n",
    "    # if step % 100 == 0:\n",
    "    #   torch.save(model.state_dict(), f\"model_{label}_{gamma}_{learning_rate}_{step}.pt\")\n",
    "\n",
    "\n",
    "    gc.collect()\n",
    "    \n",
    "    # decay temp\n",
    "    temperature = np.max([0.1, temperature * TEMP_DECAY])\n",
    "\n",
    "    # decay epsilon\n",
    "    epsilon = EPSILON_FINAL + (EPSILON_START - EPSILON_FINAL) * np.exp(-1.0 * step / EPSILON_DECAY_FRAMES)\n",
    "\n",
    "    if step % TARGET_UPDATE_FREQ == 0:\n",
    "      # calculate the avg change weights of the model with the target model\n",
    "      total_change = 0\n",
    "      for p, p_target in zip(model.parameters(), target_model.parameters()):\n",
    "        total_change += torch.abs(p - p_target).sum().item()\n",
    "      # print(f\"total change: {total_change}\")\n",
    "\n",
    "      target_model.load_state_dict(model.state_dict())\n",
    "\n",
    "  env.close()\n",
    "  return reward_per_episode\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Specify the location of the game configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "game_setup_path = \"map_with_obstacles\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create the env setup. Note that we use damaged based rewards to give a denser reward signalling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_env(root_path, render_mode=\"ansi\", show_logs=False):\n",
    "    return make(\"dndenv-v0\", root_path=root_path, show_logs=show_logs,\n",
    "                render_mode=render_mode,\n",
    "                damage_based_reward=False,\n",
    "                profiles=['high_elf_mage'],\n",
    "                enemies=['halfling_rogue'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = make_env(game_setup_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training with gamma 0.99 and learning rate 0.0001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jedld/.local/lib/python3.10/site-packages/gymnasium/core.py:311: UserWarning: \u001b[33mWARN: env.seed to get variables from other wrappers is deprecated and will be removed in v1.0, to get this variable you can do `env.unwrapped.seed` for environment variables or `env.get_wrapper_attr('seed')` that will search the reminding wrappers.\u001b[0m\n",
      "  logger.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8d8cc259372d4da4bc1e96cc059c070b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jedld/.local/lib/python3.10/site-packages/torch/autograd/graph.py:744: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0: avg rewards -1.2 std: 9.927738916792686 best avg -10@0 epsilon 1.0\n",
      "best: -1.2\n",
      "10: avg rewards -0.4 std: 9.991996797437437 best avg -1.2@0 epsilon 0.9911299749851548\n",
      "best: -0.4\n",
      "20: avg rewards -1.2 std: 9.927738916792686 best avg -0.4@10 epsilon 0.9813675686203779\n",
      "30: avg rewards -2.0 std: 9.797958971132712 best avg -0.4@10 epsilon 0.9717022998219388\n",
      "40: avg rewards -2.0 std: 9.797958971132712 best avg -0.4@10 epsilon 0.962133202054903\n",
      "50: avg rewards 2.8 std: 9.600000000000001 best avg -0.4@10 epsilon 0.9526593184015199\n",
      "best: 2.8\n",
      "60: avg rewards -2.0 std: 9.797958971132712 best avg 2.8@50 epsilon 0.9432797014655288\n",
      "70: avg rewards -0.4 std: 9.991996797437437 best avg 2.8@50 epsilon 0.9339934132774199\n",
      "80: avg rewards 0.4 std: 9.991996797437437 best avg 2.8@50 epsilon 0.9247995252006359\n",
      "90: avg rewards 2.0 std: 9.797958971132712 best avg 2.8@50 epsilon 0.9156971178387074\n",
      "100: avg rewards -2.8 std: 9.600000000000001 best avg 2.8@50 epsilon 0.906685280943313\n",
      "110: avg rewards -3.6 std: 9.329523031752482 best avg 2.8@50 epsilon 0.8977631133232531\n",
      "120: avg rewards -1.2 std: 9.927738916792686 best avg 2.8@50 epsilon 0.8889297227543306\n",
      "130: avg rewards -0.4 std: 9.991996797437437 best avg 2.8@50 epsilon 0.8801842258901273\n",
      "140: avg rewards -0.4 std: 9.991996797437437 best avg 2.8@50 epsilon 0.871525748173669\n",
      "150: avg rewards -2.0 std: 9.797958971132712 best avg 2.8@50 epsilon 0.8629534237499686\n",
      "160: avg rewards -3.6 std: 9.329523031752482 best avg 2.8@50 epsilon 0.8544663953794402\n",
      "170: avg rewards -3.6 std: 9.329523031752482 best avg 2.8@50 epsilon 0.846063814352174\n",
      "180: avg rewards -0.4 std: 9.991996797437437 best avg 2.8@50 epsilon 0.8377448404030652\n",
      "190: avg rewards -3.6 std: 9.329523031752482 best avg 2.8@50 epsilon 0.8295086416277863\n",
      "200: avg rewards -0.4 std: 9.991996797437437 best avg 2.8@50 epsilon 0.8213543943995963\n",
      "210: avg rewards -6.0 std: 8.0 best avg 2.8@50 epsilon 0.8132812832869774\n",
      "220: avg rewards -2.8 std: 9.600000000000001 best avg 2.8@50 epsilon 0.8052885009720903\n",
      "230: avg rewards -0.4 std: 9.991996797437437 best avg 2.8@50 epsilon 0.797375248170043\n",
      "240: avg rewards -2.8 std: 9.600000000000001 best avg 2.8@50 epsilon 0.7895407335489611\n",
      "250: avg rewards 0.4 std: 9.991996797437437 best avg 2.8@50 epsilon 0.7817841736508534\n",
      "260: avg rewards -2.0 std: 9.797958971132712 best avg 2.8@50 epsilon 0.7741047928132664\n",
      "270: avg rewards -5.2 std: 8.541662601625049 best avg 2.8@50 epsilon 0.766501823091717\n",
      "280: avg rewards 0.4 std: 9.991996797437437 best avg 2.8@50 epsilon 0.7589745041828969\n",
      "290: avg rewards -5.2 std: 8.541662601625049 best avg 2.8@50 epsilon 0.7515220833486427\n",
      "300: avg rewards -1.2 std: 9.927738916792686 best avg 2.8@50 epsilon 0.7441438153406604\n",
      "310: avg rewards 1.2 std: 9.927738916792686 best avg 2.8@50 epsilon 0.7368389623260008\n",
      "320: avg rewards -3.6 std: 9.329523031752482 best avg 2.8@50 epsilon 0.7296067938132749\n",
      "330: avg rewards -3.6 std: 9.329523031752482 best avg 2.8@50 epsilon 0.7224465865796047\n",
      "340: avg rewards -5.2 std: 8.541662601625049 best avg 2.8@50 epsilon 0.7153576245982999\n",
      "350: avg rewards 0.4 std: 9.991996797437437 best avg 2.8@50 epsilon 0.7083391989672548\n",
      "360: avg rewards -2.8 std: 9.600000000000001 best avg 2.8@50 epsilon 0.7013906078380578\n",
      "370: avg rewards -3.6 std: 9.329523031752482 best avg 2.8@50 epsilon 0.6945111563458054\n",
      "380: avg rewards -4.4 std: 8.97997772825746 best avg 2.8@50 epsilon 0.6877001565396155\n",
      "390: avg rewards 1.2 std: 9.927738916792686 best avg 2.8@50 epsilon 0.6809569273138314\n",
      "400: avg rewards -2.0 std: 9.797958971132712 best avg 2.8@50 epsilon 0.6742807943399114\n",
      "410: avg rewards -2.0 std: 9.797958971132712 best avg 2.8@50 epsilon 0.6676710899989946\n",
      "420: avg rewards -2.0 std: 9.797958971132712 best avg 2.8@50 epsilon 0.6611271533151388\n",
      "430: avg rewards -0.4 std: 9.991996797437437 best avg 2.8@50 epsilon 0.6546483298892222\n",
      "440: avg rewards -2.0 std: 9.797958971132712 best avg 2.8@50 epsilon 0.6482339718335033\n",
      "450: avg rewards -6.0 std: 8.0 best avg 2.8@50 epsilon 0.6418834377068311\n",
      "460: avg rewards -3.6 std: 9.329523031752482 best avg 2.8@50 epsilon 0.635596092450501\n",
      "470: avg rewards -2.8 std: 9.600000000000001 best avg 2.8@50 epsilon 0.6293713073247477\n",
      "480: avg rewards 0.4 std: 9.991996797437437 best avg 2.8@50 epsilon 0.6232084598458713\n",
      "490: avg rewards -4.4 std: 8.97997772825746 best avg 2.8@50 epsilon 0.6171069337239882\n",
      "500: avg rewards -1.2 std: 9.927738916792686 best avg 2.8@50 epsilon 0.6110661188014018\n",
      "510: avg rewards -4.4 std: 8.97997772825746 best avg 2.8@50 epsilon 0.6050854109915855\n",
      "520: avg rewards -3.6 std: 9.329523031752482 best avg 2.8@50 epsilon 0.5991642122187746\n",
      "530: avg rewards -3.6 std: 9.329523031752482 best avg 2.8@50 epsilon 0.5933019303581573\n",
      "540: avg rewards -3.6 std: 9.329523031752482 best avg 2.8@50 epsilon 0.5874979791766624\n",
      "550: avg rewards -3.6 std: 9.329523031752482 best avg 2.8@50 epsilon 0.5817517782743352\n",
      "560: avg rewards 2.0 std: 9.797958971132712 best avg 2.8@50 epsilon 0.5760627530262967\n",
      "570: avg rewards 1.6 std: 9.666436778875658 best avg 2.8@50 epsilon 0.5704303345252815\n",
      "580: avg rewards -0.8 std: 9.765244492586962 best avg 2.8@50 epsilon 0.5648539595247455\n",
      "590: avg rewards -0.4 std: 9.991996797437437 best avg 2.8@50 epsilon 0.559333070382542\n",
      "600: avg rewards 2.0 std: 9.797958971132712 best avg 2.8@50 epsilon 0.5538671150051557\n",
      "610: avg rewards -2.4 std: 9.499473669630335 best avg 2.8@50 epsilon 0.548455546792494\n",
      "620: avg rewards -2.0 std: 9.797958971132712 best avg 2.8@50 epsilon 0.5430978245832262\n",
      "630: avg rewards 2.0 std: 9.797958971132712 best avg 2.8@50 epsilon 0.5377934126006662\n",
      "640: avg rewards 0.4 std: 9.991996797437437 best avg 2.8@50 epsilon 0.5325417803991956\n",
      "650: avg rewards -1.6 std: 9.666436778875658 best avg 2.8@50 epsilon 0.5273424028112179\n",
      "660: avg rewards -2.8 std: 9.600000000000001 best avg 2.8@50 epsilon 0.5221947598946415\n",
      "670: avg rewards -4.4 std: 8.97997772825746 best avg 2.8@50 epsilon 0.5170983368808848\n",
      "680: avg rewards -0.4 std: 9.991996797437437 best avg 2.8@50 epsilon 0.5120526241233995\n",
      "690: avg rewards 0.8 std: 9.765244492586962 best avg 2.8@50 epsilon 0.5070571170467053\n",
      "700: avg rewards 1.2 std: 9.927738916792686 best avg 2.8@50 epsilon 0.5021113160959313\n",
      "710: avg rewards 0.4 std: 9.991996797437437 best avg 2.8@50 epsilon 0.4972147266868611\n",
      "720: avg rewards -2.8 std: 9.600000000000001 best avg 2.8@50 epsilon 0.4923668591564732\n",
      "730: avg rewards 0.8 std: 9.765244492586962 best avg 2.8@50 epsilon 0.4875672287139747\n",
      "740: avg rewards -1.2 std: 9.927738916792686 best avg 2.8@50 epsilon 0.48281535539232157\n",
      "750: avg rewards -0.8 std: 9.765244492586962 best avg 2.8@50 epsilon 0.47811076400022173\n",
      "760: avg rewards 2.4 std: 9.499473669630335 best avg 2.8@50 epsilon 0.47345298407461556\n",
      "770: avg rewards -0.8 std: 9.765244492586962 best avg 2.8@50 epsilon 0.46884154983362897\n",
      "780: avg rewards 3.2 std: 9.260669522232178 best avg 2.8@50 epsilon 0.464276000129995\n",
      "best: 3.2\n",
      "790: avg rewards -2.8 std: 9.600000000000001 best avg 3.2@780 epsilon 0.45975587840493853\n",
      "800: avg rewards -2.8 std: 9.600000000000001 best avg 3.2@780 epsilon 0.4552807326425205\n",
      "810: avg rewards -1.2 std: 9.927738916792686 best avg 3.2@780 epsilon 0.45085011532443514\n",
      "820: avg rewards 0.4 std: 9.991996797437437 best avg 3.2@780 epsilon 0.4464635833852586\n",
      "830: avg rewards 4.4 std: 8.97997772825746 best avg 3.2@780 epsilon 0.4421206981681414\n",
      "best: 4.4\n",
      "840: avg rewards 1.6 std: 9.666436778875658 best avg 4.4@830 epsilon 0.43782102538094286\n",
      "850: avg rewards 1.6 std: 9.666436778875658 best avg 4.4@830 epsilon 0.43356413505280106\n",
      "860: avg rewards -0.4 std: 9.991996797437437 best avg 4.4@830 epsilon 0.4293496014911359\n",
      "870: avg rewards -1.2 std: 9.927738916792686 best avg 4.4@830 epsilon 0.4251770032390789\n",
      "880: avg rewards 0.0 std: 9.797958971132712 best avg 4.4@830 epsilon 0.42104592303332794\n",
      "890: avg rewards -4.4 std: 8.979977728257458 best avg 4.4@830 epsilon 0.4169559477624196\n",
      "900: avg rewards -0.4 std: 9.991996797437437 best avg 4.4@830 epsilon 0.4129066684254187\n",
      "910: avg rewards -1.2 std: 9.927738916792686 best avg 4.4@830 epsilon 0.4088976800910169\n",
      "920: avg rewards -3.2 std: 9.26066952223218 best avg 4.4@830 epsilon 0.4049285818570401\n",
      "930: avg rewards 0.4 std: 9.991996797437437 best avg 4.4@830 epsilon 0.40099897681035723\n",
      "940: avg rewards -2.8 std: 9.600000000000001 best avg 4.4@830 epsilon 0.39710847198718907\n",
      "950: avg rewards -2.0 std: 9.797958971132712 best avg 4.4@830 epsilon 0.393256678333811\n",
      "960: avg rewards -2.0 std: 9.797958971132712 best avg 4.4@830 epsilon 0.389443210667648\n",
      "970: avg rewards 0.4 std: 9.991996797437437 best avg 4.4@830 epsilon 0.38566768763875536\n",
      "980: avg rewards -0.4 std: 9.991996797437437 best avg 4.4@830 epsilon 0.3819297316916842\n",
      "990: avg rewards -1.2 std: 9.927738916792686 best avg 4.4@830 epsilon 0.3782289690277246\n",
      "1000: avg rewards 3.2 std: 9.260669522232178 best avg 4.4@830 epsilon 0.3745650295675263\n",
      "1010: avg rewards -1.2 std: 9.927738916792686 best avg 4.4@830 epsilon 0.37093754691409003\n",
      "1020: avg rewards 1.2 std: 9.927738916792686 best avg 4.4@830 epsilon 0.3673461583161273\n",
      "1030: avg rewards 1.2 std: 9.927738916792686 best avg 4.4@830 epsilon 0.36379050463178575\n",
      "1040: avg rewards -2.8 std: 9.600000000000001 best avg 4.4@830 epsilon 0.3602702302927337\n",
      "1050: avg rewards 1.2 std: 9.927738916792686 best avg 4.4@830 epsilon 0.35678498326860386\n",
      "1060: avg rewards 1.2 std: 9.927738916792686 best avg 4.4@830 epsilon 0.35333441503178925\n",
      "1070: avg rewards -4.4 std: 8.979977728257458 best avg 4.4@830 epsilon 0.3499181805225908\n",
      "1080: avg rewards -1.2 std: 9.927738916792686 best avg 4.4@830 epsilon 0.34653593811471073\n",
      "1090: avg rewards -2.4 std: 9.499473669630335 best avg 4.4@830 epsilon 0.34318734958108965\n",
      "1100: avg rewards -1.6 std: 9.666436778875658 best avg 4.4@830 epsilon 0.33987208006008374\n",
      "1110: avg rewards 0.4 std: 9.991996797437437 best avg 4.4@830 epsilon 0.3365897980219782\n",
      "1120: avg rewards -1.2 std: 9.927738916792686 best avg 4.4@830 epsilon 0.33334017523583387\n",
      "1130: avg rewards 2.8 std: 9.600000000000001 best avg 4.4@830 epsilon 0.3301228867366642\n",
      "1140: avg rewards 0.0 std: 9.797958971132712 best avg 4.4@830 epsilon 0.32693761079293815\n",
      "1150: avg rewards -0.4 std: 9.991996797437437 best avg 4.4@830 epsilon 0.32378402887440694\n",
      "1160: avg rewards 2.8 std: 9.600000000000001 best avg 4.4@830 epsilon 0.3206618256202507\n",
      "1170: avg rewards -1.2 std: 9.927738916792686 best avg 4.4@830 epsilon 0.31757068880754225\n",
      "1180: avg rewards -2.8 std: 9.600000000000001 best avg 4.4@830 epsilon 0.31451030932002433\n",
      "1190: avg rewards 2.8 std: 9.600000000000001 best avg 4.4@830 epsilon 0.3114803811171978\n",
      "1200: avg rewards 2.0 std: 9.797958971132712 best avg 4.4@830 epsilon 0.3084806012037175\n",
      "1210: avg rewards 3.6 std: 9.329523031752482 best avg 4.4@830 epsilon 0.30551066959909223\n",
      "1220: avg rewards -2.8 std: 9.600000000000001 best avg 4.4@830 epsilon 0.30257028930768665\n",
      "1230: avg rewards -2.8 std: 9.600000000000001 best avg 4.4@830 epsilon 0.2996591662890211\n",
      "1240: avg rewards 1.2 std: 9.927738916792686 best avg 4.4@830 epsilon 0.296777009428368\n",
      "1250: avg rewards 0.4 std: 9.991996797437437 best avg 4.4@830 epsilon 0.2939235305076393\n",
      "1260: avg rewards 2.0 std: 9.797958971132712 best avg 4.4@830 epsilon 0.2910984441765652\n",
      "1270: avg rewards 2.4 std: 9.499473669630335 best avg 4.4@830 epsilon 0.2883014679241582\n",
      "1280: avg rewards 3.2 std: 9.26066952223218 best avg 4.4@830 epsilon 0.28553232205046225\n",
      "1290: avg rewards 1.2 std: 9.927738916792686 best avg 4.4@830 epsilon 0.28279072963858237\n",
      "1300: avg rewards 2.8 std: 9.600000000000001 best avg 4.4@830 epsilon 0.2800764165269927\n",
      "1310: avg rewards 1.2 std: 9.927738916792684 best avg 4.4@830 epsilon 0.27738911128212024\n",
      "1320: avg rewards 2.0 std: 9.797958971132712 best avg 4.4@830 epsilon 0.27472854517120093\n",
      "1330: avg rewards 0.4 std: 9.991996797437437 best avg 4.4@830 epsilon 0.2720944521354066\n",
      "1340: avg rewards -1.2 std: 9.927738916792686 best avg 4.4@830 epsilon 0.26948656876323857\n",
      "1350: avg rewards -0.4 std: 9.991996797437437 best avg 4.4@830 epsilon 0.26690463426418637\n",
      "1360: avg rewards -1.2 std: 9.927738916792686 best avg 4.4@830 epsilon 0.2643483904426486\n",
      "1370: avg rewards -1.2 std: 9.927738916792686 best avg 4.4@830 epsilon 0.2618175816721127\n",
      "1380: avg rewards -0.4 std: 9.991996797437437 best avg 4.4@830 epsilon 0.2593119548695927\n",
      "1390: avg rewards 2.0 std: 9.797958971132712 best avg 4.4@830 epsilon 0.25683125947032037\n",
      "1400: avg rewards -3.6 std: 9.329523031752482 best avg 4.4@830 epsilon 0.2543752474026884\n",
      "1410: avg rewards 2.0 std: 9.797958971132712 best avg 4.4@830 epsilon 0.25194367306344345\n",
      "1420: avg rewards 2.0 std: 9.797958971132712 best avg 4.4@830 epsilon 0.2495362932931253\n",
      "1430: avg rewards -0.4 std: 9.991996797437437 best avg 4.4@830 epsilon 0.24715286735175065\n",
      "1440: avg rewards -1.2 std: 9.927738916792686 best avg 4.4@830 epsilon 0.24479315689473924\n",
      "1450: avg rewards -3.2 std: 9.260669522232178 best avg 4.4@830 epsilon 0.24245692594907892\n",
      "1460: avg rewards -2.8 std: 9.600000000000001 best avg 4.4@830 epsilon 0.24014394088972824\n",
      "1470: avg rewards -0.4 std: 9.991996797437437 best avg 4.4@830 epsilon 0.2378539704162538\n",
      "1480: avg rewards -0.4 std: 9.991996797437437 best avg 4.4@830 epsilon 0.23558678552969994\n",
      "1490: avg rewards -2.0 std: 9.797958971132712 best avg 4.4@830 epsilon 0.23334215950968865\n",
      "1500: avg rewards 1.2 std: 9.927738916792686 best avg 4.4@830 epsilon 0.23111986789174743\n",
      "1510: avg rewards -1.2 std: 9.927738916792686 best avg 4.4@830 epsilon 0.2289196884448626\n",
      "1520: avg rewards 2.8 std: 9.600000000000001 best avg 4.4@830 epsilon 0.22674140114925587\n",
      "1530: avg rewards 2.0 std: 9.797958971132712 best avg 4.4@830 epsilon 0.22458478817438252\n",
      "1540: avg rewards 0.4 std: 9.991996797437437 best avg 4.4@830 epsilon 0.22244963385714783\n",
      "1550: avg rewards -3.6 std: 9.329523031752482 best avg 4.4@830 epsilon 0.22033572468034085\n",
      "1560: avg rewards 2.0 std: 9.797958971132712 best avg 4.4@830 epsilon 0.21824284925128223\n",
      "1570: avg rewards 0.4 std: 9.991996797437437 best avg 4.4@830 epsilon 0.21617079828068503\n",
      "1580: avg rewards 1.6 std: 9.666436778875658 best avg 4.4@830 epsilon 0.21411936456172548\n",
      "1590: avg rewards 0.4 std: 9.991996797437437 best avg 4.4@830 epsilon 0.21208834294932213\n",
      "1600: avg rewards 0.4 std: 9.991996797437437 best avg 4.4@830 epsilon 0.21007753033962123\n",
      "1610: avg rewards -2.0 std: 9.797958971132712 best avg 4.4@830 epsilon 0.20808672564968614\n",
      "1620: avg rewards -1.2 std: 9.927738916792686 best avg 4.4@830 epsilon 0.20611572979738882\n",
      "1630: avg rewards 1.6 std: 9.666436778875658 best avg 4.4@830 epsilon 0.20416434568150157\n",
      "1640: avg rewards 2.0 std: 9.797958971132712 best avg 4.4@830 epsilon 0.2022323781619866\n",
      "1650: avg rewards 1.2 std: 9.927738916792684 best avg 4.4@830 epsilon 0.20031963404048206\n",
      "1660: avg rewards -0.4 std: 9.991996797437437 best avg 4.4@830 epsilon 0.19842592204098175\n",
      "1670: avg rewards 3.6 std: 9.329523031752482 best avg 4.4@830 epsilon 0.1965510527907077\n",
      "1680: avg rewards 1.2 std: 9.927738916792686 best avg 4.4@830 epsilon 0.19469483880117242\n",
      "1690: avg rewards 0.4 std: 9.991996797437437 best avg 4.4@830 epsilon 0.19285709444943014\n",
      "1700: avg rewards -0.4 std: 9.991996797437437 best avg 4.4@830 epsilon 0.19103763595951423\n",
      "1710: avg rewards -1.2 std: 9.927738916792686 best avg 4.4@830 epsilon 0.18923628138405948\n",
      "1720: avg rewards 2.8 std: 9.600000000000001 best avg 4.4@830 epsilon 0.1874528505861072\n",
      "1730: avg rewards 2.0 std: 9.797958971132712 best avg 4.4@830 epsilon 0.18568716522109138\n",
      "1740: avg rewards 2.8 std: 9.600000000000001 best avg 4.4@830 epsilon 0.18393904871900413\n",
      "1750: avg rewards 2.0 std: 9.797958971132712 best avg 4.4@830 epsilon 0.18220832626673847\n",
      "1760: avg rewards 2.0 std: 9.797958971132712 best avg 4.4@830 epsilon 0.18049482479060697\n",
      "1770: avg rewards 3.6 std: 9.329523031752482 best avg 4.4@830 epsilon 0.17879837293903394\n",
      "1780: avg rewards -0.4 std: 9.991996797437437 best avg 4.4@830 epsilon 0.17711880106542063\n",
      "1790: avg rewards 4.8 std: 8.541662601625049 best avg 4.4@830 epsilon 0.17545594121118\n",
      "best: 4.8\n",
      "1800: avg rewards 2.8 std: 9.600000000000001 best avg 4.8@1790 epsilon 0.17380962708894088\n",
      "1810: avg rewards 1.2 std: 9.927738916792686 best avg 4.8@1790 epsilon 0.1721796940659191\n",
      "1820: avg rewards 2.8 std: 9.600000000000001 best avg 4.8@1790 epsilon 0.17056597914745417\n",
      "1830: avg rewards 3.2 std: 9.260669522232178 best avg 4.8@1790 epsilon 0.16896832096070938\n",
      "1840: avg rewards 0.4 std: 9.991996797437437 best avg 4.8@1790 epsilon 0.1673865597385347\n",
      "1850: avg rewards 1.2 std: 9.927738916792686 best avg 4.8@1790 epsilon 0.16582053730348978\n",
      "1860: avg rewards -2.8 std: 9.600000000000001 best avg 4.8@1790 epsilon 0.1642700970520261\n",
      "1870: avg rewards 2.8 std: 9.600000000000001 best avg 4.8@1790 epsilon 0.16273508393882644\n",
      "1880: avg rewards -1.2 std: 9.927738916792686 best avg 4.8@1790 epsilon 0.16121534446130037\n",
      "1890: avg rewards -2.0 std: 9.797958971132712 best avg 4.8@1790 epsilon 0.1597107266442336\n",
      "1900: avg rewards -0.4 std: 9.991996797437437 best avg 4.8@1790 epsilon 0.15822108002459062\n",
      "1910: avg rewards -2.0 std: 9.797958971132712 best avg 4.8@1790 epsilon 0.15674625563646807\n",
      "1920: avg rewards 4.4 std: 8.97997772825746 best avg 4.8@1790 epsilon 0.15528610599619813\n",
      "1930: avg rewards -1.2 std: 9.927738916792686 best avg 4.8@1790 epsilon 0.15384048508759998\n",
      "1940: avg rewards 1.2 std: 9.927738916792686 best avg 4.8@1790 epsilon 0.15240924834737804\n",
      "1950: avg rewards -0.4 std: 9.991996797437437 best avg 4.8@1790 epsilon 0.1509922526506656\n",
      "1960: avg rewards 0.4 std: 9.991996797437437 best avg 4.8@1790 epsilon 0.14958935629671216\n",
      "1970: avg rewards -1.2 std: 9.927738916792686 best avg 4.8@1790 epsilon 0.14820041899471328\n",
      "1980: avg rewards 1.2 std: 9.927738916792686 best avg 4.8@1790 epsilon 0.14682530184978126\n",
      "1990: avg rewards 1.2 std: 9.927738916792686 best avg 4.8@1790 epsilon 0.14546386734905567\n",
      "2000: avg rewards 2.0 std: 9.797958971132712 best avg 4.8@1790 epsilon 0.14411597934795192\n",
      "2010: avg rewards 2.0 std: 9.797958971132712 best avg 4.8@1790 epsilon 0.1427815030565467\n",
      "2020: avg rewards 5.2 std: 8.541662601625049 best avg 4.8@1790 epsilon 0.14146030502609866\n",
      "best: 5.2\n",
      "2030: avg rewards 1.2 std: 9.927738916792684 best avg 5.2@2020 epsilon 0.14015225313570392\n",
      "2040: avg rewards 1.2 std: 9.927738916792686 best avg 5.2@2020 epsilon 0.1388572165790833\n",
      "2050: avg rewards 2.0 std: 9.797958971132712 best avg 5.2@2020 epsilon 0.13757506585150198\n",
      "2060: avg rewards -1.2 std: 9.927738916792686 best avg 5.2@2020 epsilon 0.13630567273681865\n",
      "2070: avg rewards 0.4 std: 9.991996797437437 best avg 5.2@2020 epsilon 0.13504891029466418\n",
      "2080: avg rewards -0.4 std: 9.991996797437437 best avg 5.2@2020 epsilon 0.13380465284774684\n",
      "2090: avg rewards 0.4 std: 9.991996797437437 best avg 5.2@2020 epsilon 0.13257277596928527\n",
      "2100: avg rewards -0.4 std: 9.991996797437437 best avg 5.2@2020 epsilon 0.13135315647056486\n",
      "2110: avg rewards 1.2 std: 9.927738916792686 best avg 5.2@2020 epsilon 0.13014567238861954\n",
      "2120: avg rewards 2.8 std: 9.600000000000001 best avg 5.2@2020 epsilon 0.12895020297403476\n",
      "2130: avg rewards -2.0 std: 9.797958971132712 best avg 5.2@2020 epsilon 0.12776662867887295\n",
      "2140: avg rewards -0.4 std: 9.991996797437437 best avg 5.2@2020 epsilon 0.12659483114471817\n",
      "2150: avg rewards 2.8 std: 9.600000000000001 best avg 5.2@2020 epsilon 0.12543469319084055\n",
      "2160: avg rewards 1.2 std: 9.927738916792686 best avg 5.2@2020 epsilon 0.12428609880247792\n",
      "2170: avg rewards -0.4 std: 9.991996797437437 best avg 5.2@2020 epsilon 0.12314893311923422\n",
      "2180: avg rewards 0.4 std: 9.991996797437437 best avg 5.2@2020 epsilon 0.12202308242359361\n",
      "2190: avg rewards -2.8 std: 9.600000000000001 best avg 5.2@2020 epsilon 0.12090843412954817\n",
      "2200: avg rewards 2.8 std: 9.600000000000001 best avg 5.2@2020 epsilon 0.11980487677133975\n",
      "2210: avg rewards 4.8 std: 8.541662601625049 best avg 5.2@2020 epsilon 0.11871229999231277\n",
      "2220: avg rewards 2.8 std: 9.600000000000001 best avg 5.2@2020 epsilon 0.11763059453387897\n",
      "2230: avg rewards 2.0 std: 9.797958971132712 best avg 5.2@2020 epsilon 0.11655965222459096\n",
      "2240: avg rewards 0.4 std: 9.991996797437437 best avg 5.2@2020 epsilon 0.11549936596932547\n",
      "2250: avg rewards -0.4 std: 9.991996797437437 best avg 5.2@2020 epsilon 0.1144496297385733\n",
      "2260: avg rewards 2.0 std: 9.797958971132712 best avg 5.2@2020 epsilon 0.11341033855783668\n",
      "2270: avg rewards -0.4 std: 9.991996797437437 best avg 5.2@2020 epsilon 0.11238138849713136\n",
      "2280: avg rewards 0.4 std: 9.991996797437437 best avg 5.2@2020 epsilon 0.11136267666059392\n",
      "2290: avg rewards -2.0 std: 9.797958971132712 best avg 5.2@2020 epsilon 0.11035410117619167\n",
      "2300: avg rewards 0.4 std: 9.991996797437437 best avg 5.2@2020 epsilon 0.10935556118553577\n",
      "2310: avg rewards -1.2 std: 9.927738916792686 best avg 5.2@2020 epsilon 0.10836695683379496\n",
      "2320: avg rewards -0.4 std: 9.991996797437437 best avg 5.2@2020 epsilon 0.1073881892597103\n",
      "2330: avg rewards 0.4 std: 9.991996797437437 best avg 5.2@2020 epsilon 0.10641916058570867\n",
      "2340: avg rewards -0.4 std: 9.991996797437437 best avg 5.2@2020 epsilon 0.10545977390811523\n",
      "2350: avg rewards 2.0 std: 9.797958971132712 best avg 5.2@2020 epsilon 0.10450993328746264\n",
      "2360: avg rewards 2.0 std: 9.797958971132712 best avg 5.2@2020 epsilon 0.10356954373889737\n",
      "2370: avg rewards 0.4 std: 9.991996797437437 best avg 5.2@2020 epsilon 0.10263851122268082\n",
      "2380: avg rewards -6.0 std: 8.0 best avg 5.2@2020 epsilon 0.1017167426347856\n",
      "2390: avg rewards 3.6 std: 9.329523031752482 best avg 5.2@2020 epsilon 0.10080414579758475\n",
      "2400: avg rewards 0.0 std: 9.797958971132712 best avg 5.2@2020 epsilon 0.09990062945063397\n",
      "2410: avg rewards -0.4 std: 9.991996797437437 best avg 5.2@2020 epsilon 0.09900610324154574\n",
      "2420: avg rewards -1.2 std: 9.927738916792686 best avg 5.2@2020 epsilon 0.09812047771695363\n",
      "2430: avg rewards 6.8 std: 7.332121111929345 best avg 5.2@2020 epsilon 0.09724366431356722\n",
      "best: 6.8\n",
      "2440: avg rewards -2.8 std: 9.600000000000001 best avg 6.8@2430 epsilon 0.09637557534931544\n",
      "2450: avg rewards -1.2 std: 9.927738916792686 best avg 6.8@2430 epsilon 0.09551612401457851\n",
      "2460: avg rewards -2.0 std: 9.797958971132712 best avg 6.8@2430 epsilon 0.09466522436350666\n",
      "2470: avg rewards -2.0 std: 9.797958971132712 best avg 6.8@2430 epsilon 0.09382279130542581\n",
      "2480: avg rewards 2.0 std: 9.797958971132712 best avg 6.8@2430 epsilon 0.09298874059632802\n",
      "2490: avg rewards -0.4 std: 9.991996797437437 best avg 6.8@2430 epsilon 0.09216298883044739\n",
      "2500: avg rewards 4.4 std: 8.97997772825746 best avg 6.8@2430 epsilon 0.09134545343191919\n",
      "2510: avg rewards -0.4 std: 9.991996797437437 best avg 6.8@2430 epsilon 0.0905360526465223\n",
      "2520: avg rewards 2.0 std: 9.797958971132712 best avg 6.8@2430 epsilon 0.08973470553350363\n",
      "2530: avg rewards -2.0 std: 9.797958971132712 best avg 6.8@2430 epsilon 0.08894133195748416\n",
      "2540: avg rewards -0.4 std: 9.991996797437437 best avg 6.8@2430 epsilon 0.08815585258044506\n",
      "2550: avg rewards 2.8 std: 9.600000000000001 best avg 6.8@2430 epsilon 0.08737818885379413\n",
      "2560: avg rewards 2.0 std: 9.797958971132712 best avg 6.8@2430 epsilon 0.08660826301051058\n",
      "2570: avg rewards 0.4 std: 9.991996797437437 best avg 6.8@2430 epsilon 0.08584599805736856\n",
      "2580: avg rewards -0.4 std: 9.991996797437437 best avg 6.8@2430 epsilon 0.08509131776723745\n",
      "2590: avg rewards 0.4 std: 9.991996797437437 best avg 6.8@2430 epsilon 0.08434414667145941\n",
      "2600: avg rewards -0.4 std: 9.991996797437437 best avg 6.8@2430 epsilon 0.08360441005230212\n",
      "2610: avg rewards -0.4 std: 9.991996797437437 best avg 6.8@2430 epsilon 0.08287203393548732\n",
      "2620: avg rewards 1.2 std: 9.927738916792686 best avg 6.8@2430 epsilon 0.08214694508279297\n",
      "2630: avg rewards 0.4 std: 9.991996797437437 best avg 6.8@2430 epsilon 0.08142907098472954\n",
      "2640: avg rewards -1.2 std: 9.927738916792686 best avg 6.8@2430 epsilon 0.08071833985328901\n",
      "2650: avg rewards 2.0 std: 9.797958971132712 best avg 6.8@2430 epsilon 0.08001468061476594\n",
      "2660: avg rewards 0.4 std: 9.991996797437437 best avg 6.8@2430 epsilon 0.07931802290265014\n",
      "2670: avg rewards 0.0 std: 9.797958971132712 best avg 6.8@2430 epsilon 0.07862829705058977\n",
      "2680: avg rewards 2.0 std: 9.797958971132712 best avg 6.8@2430 epsilon 0.07794543408542494\n",
      "2690: avg rewards -4.4 std: 8.97997772825746 best avg 6.8@2430 epsilon 0.07726936572029\n",
      "2700: avg rewards -2.0 std: 9.797958971132712 best avg 6.8@2430 epsilon 0.07660002434778511\n",
      "2710: avg rewards 2.0 std: 9.797958971132712 best avg 6.8@2430 epsilon 0.07593734303321518\n",
      "2720: avg rewards 2.0 std: 9.797958971132712 best avg 6.8@2430 epsilon 0.07528125550789658\n",
      "2730: avg rewards -3.6 std: 9.329523031752482 best avg 6.8@2430 epsilon 0.07463169616252995\n",
      "2740: avg rewards 5.2 std: 8.541662601625049 best avg 6.8@2430 epsilon 0.07398860004063953\n",
      "2750: avg rewards 2.8 std: 9.600000000000001 best avg 6.8@2430 epsilon 0.07335190283207715\n",
      "2760: avg rewards 0.4 std: 9.991996797437437 best avg 6.8@2430 epsilon 0.07272154086659145\n",
      "2770: avg rewards 0.4 std: 9.991996797437437 best avg 6.8@2430 epsilon 0.0720974511074605\n",
      "2780: avg rewards 0.4 std: 9.991996797437437 best avg 6.8@2430 epsilon 0.07147957114518838\n",
      "2790: avg rewards 3.2 std: 9.260669522232178 best avg 6.8@2430 epsilon 0.07086783919126388\n",
      "2800: avg rewards 0.4 std: 9.991996797437437 best avg 6.8@2430 epsilon 0.07026219407198192\n",
      "2810: avg rewards 2.8 std: 9.600000000000001 best avg 6.8@2430 epsilon 0.06966257522232579\n",
      "2820: avg rewards -2.0 std: 9.797958971132712 best avg 6.8@2430 epsilon 0.0690689226799109\n",
      "2830: avg rewards 0.4 std: 9.991996797437437 best avg 6.8@2430 epsilon 0.06848117707898822\n",
      "2840: avg rewards -2.8 std: 9.600000000000001 best avg 6.8@2430 epsilon 0.06789927964450797\n",
      "2850: avg rewards 1.2 std: 9.927738916792686 best avg 6.8@2430 epsilon 0.06732317218624169\n",
      "2860: avg rewards 2.0 std: 9.797958971132712 best avg 6.8@2430 epsilon 0.06675279709296353\n",
      "2870: avg rewards 2.0 std: 9.797958971132712 best avg 6.8@2430 epsilon 0.0661880973266888\n",
      "2880: avg rewards 4.4 std: 8.97997772825746 best avg 6.8@2430 epsilon 0.06562901641697033\n",
      "2890: avg rewards -2.0 std: 9.797958971132712 best avg 6.8@2430 epsilon 0.06507549845525122\n",
      "2900: avg rewards 2.0 std: 9.797958971132712 best avg 6.8@2430 epsilon 0.06452748808927403\n",
      "2910: avg rewards 2.8 std: 9.600000000000001 best avg 6.8@2430 epsilon 0.0639849305175455\n",
      "2920: avg rewards 0.4 std: 9.991996797437437 best avg 6.8@2430 epsilon 0.0634477714838563\n",
      "2930: avg rewards 1.2 std: 9.927738916792686 best avg 6.8@2430 epsilon 0.06291595727185546\n",
      "2940: avg rewards -2.0 std: 9.797958971132712 best avg 6.8@2430 epsilon 0.06238943469967857\n",
      "2950: avg rewards -2.0 std: 9.797958971132712 best avg 6.8@2430 epsilon 0.061868151114629684\n",
      "2960: avg rewards 2.8 std: 9.600000000000001 best avg 6.8@2430 epsilon 0.06135205438791583\n",
      "2970: avg rewards 1.2 std: 9.927738916792686 best avg 6.8@2430 epsilon 0.06084109290943432\n",
      "2980: avg rewards -2.0 std: 9.797958971132712 best avg 6.8@2430 epsilon 0.06033521558261144\n",
      "2990: avg rewards -4.4 std: 8.97997772825746 best avg 6.8@2430 epsilon 0.059834371819293\n",
      "3000: avg rewards -1.2 std: 9.927738916792686 best avg 6.8@2430 epsilon 0.059338511534685244\n",
      "3010: avg rewards 1.2 std: 9.927738916792686 best avg 6.8@2430 epsilon 0.05884758514234655\n",
      "3020: avg rewards -0.4 std: 9.991996797437437 best avg 6.8@2430 epsilon 0.058361543549228526\n",
      "3030: avg rewards -0.4 std: 9.991996797437437 best avg 6.8@2430 epsilon 0.05788033815076686\n",
      "3040: avg rewards 1.2 std: 9.927738916792686 best avg 6.8@2430 epsilon 0.057403920826020666\n",
      "3050: avg rewards 2.0 std: 9.797958971132712 best avg 6.8@2430 epsilon 0.0569322439328605\n",
      "3060: avg rewards 2.0 std: 9.797958971132712 best avg 6.8@2430 epsilon 0.056465260303203924\n",
      "3070: avg rewards -4.4 std: 8.97997772825746 best avg 6.8@2430 epsilon 0.05600292323829888\n",
      "3080: avg rewards -2.8 std: 9.600000000000001 best avg 6.8@2430 epsilon 0.055545186504053524\n",
      "3090: avg rewards -0.4 std: 9.991996797437437 best avg 6.8@2430 epsilon 0.055092004326413056\n",
      "3100: avg rewards -1.2 std: 9.927738916792686 best avg 6.8@2430 epsilon 0.054643331386782\n",
      "3110: avg rewards 0.0 std: 9.797958971132712 best avg 6.8@2430 epsilon 0.05419912281749255\n",
      "3120: avg rewards 2.0 std: 9.797958971132712 best avg 6.8@2430 epsilon 0.05375933419731755\n",
      "3130: avg rewards 2.8 std: 9.600000000000001 best avg 6.8@2430 epsilon 0.05332392154702853\n",
      "3140: avg rewards -1.2 std: 9.927738916792686 best avg 6.8@2430 epsilon 0.05289284132499761\n",
      "3150: avg rewards -3.6 std: 9.329523031752482 best avg 6.8@2430 epsilon 0.052466050422843316\n",
      "3160: avg rewards -2.8 std: 9.600000000000001 best avg 6.8@2430 epsilon 0.05204350616111982\n",
      "3170: avg rewards -1.2 std: 9.927738916792686 best avg 6.8@2430 epsilon 0.05162516628504879\n",
      "3180: avg rewards 0.4 std: 9.991996797437437 best avg 6.8@2430 epsilon 0.05121098896029404\n",
      "3190: avg rewards 3.6 std: 9.329523031752482 best avg 6.8@2430 epsilon 0.0508009327687779\n",
      "3200: avg rewards -0.4 std: 9.991996797437437 best avg 6.8@2430 epsilon 0.05039495670453956\n",
      "3210: avg rewards 0.4 std: 9.991996797437437 best avg 6.8@2430 epsilon 0.04999302016963422\n",
      "3220: avg rewards -1.2 std: 9.927738916792686 best avg 6.8@2430 epsilon 0.0495950829700735\n",
      "3230: avg rewards 0.4 std: 9.991996797437437 best avg 6.8@2430 epsilon 0.04920110531180577\n",
      "3240: avg rewards 2.8 std: 9.600000000000001 best avg 6.8@2430 epsilon 0.04881104779673694\n",
      "3250: avg rewards -2.0 std: 9.797958971132712 best avg 6.8@2430 epsilon 0.04842487141879041\n",
      "3260: avg rewards 2.0 std: 9.797958971132712 best avg 6.8@2430 epsilon 0.048042537560006614\n",
      "3270: avg rewards -1.2 std: 9.927738916792686 best avg 6.8@2430 epsilon 0.04766400798668102\n",
      "3280: avg rewards -0.4 std: 9.991996797437437 best avg 6.8@2430 epsilon 0.047289244845540895\n",
      "3290: avg rewards -0.4 std: 9.991996797437437 best avg 6.8@2430 epsilon 0.046918210659959776\n",
      "3300: avg rewards -0.4 std: 9.991996797437437 best avg 6.8@2430 epsilon 0.04655086832620994\n",
      "3310: avg rewards 1.2 std: 9.927738916792686 best avg 6.8@2430 epsilon 0.04618718110975188\n",
      "3320: avg rewards -0.4 std: 9.991996797437437 best avg 6.8@2430 epsilon 0.04582711264156089\n",
      "3330: avg rewards 0.4 std: 9.991996797437437 best avg 6.8@2430 epsilon 0.045470626914490074\n",
      "3340: avg rewards 0.4 std: 9.991996797437437 best avg 6.8@2430 epsilon 0.045117688279669665\n",
      "3350: avg rewards 1.2 std: 9.927738916792686 best avg 6.8@2430 epsilon 0.044768261442942055\n",
      "3360: avg rewards 0.4 std: 9.991996797437437 best avg 6.8@2430 epsilon 0.044422311461332395\n",
      "3370: avg rewards -2.8 std: 9.600000000000001 best avg 6.8@2430 epsilon 0.04407980373955422\n",
      "3380: avg rewards 0.4 std: 9.991996797437437 best avg 6.8@2430 epsilon 0.043740704026549934\n",
      "3390: avg rewards 0.4 std: 9.991996797437437 best avg 6.8@2430 epsilon 0.043404978412065656\n",
      "3400: avg rewards -0.4 std: 9.991996797437437 best avg 6.8@2430 epsilon 0.04307259332326014\n",
      "3410: avg rewards 0.4 std: 9.991996797437437 best avg 6.8@2430 epsilon 0.04274351552134756\n",
      "3420: avg rewards 2.8 std: 9.600000000000001 best avg 6.8@2430 epsilon 0.04241771209827344\n",
      "3430: avg rewards -0.4 std: 9.991996797437437 best avg 6.8@2430 epsilon 0.04209515047342402\n",
      "3440: avg rewards -0.4 std: 9.991996797437437 best avg 6.8@2430 epsilon 0.04177579839036798\n",
      "3450: avg rewards -2.0 std: 9.797958971132712 best avg 6.8@2430 epsilon 0.0414596239136309\n",
      "3460: avg rewards -0.4 std: 9.991996797437437 best avg 6.8@2430 epsilon 0.04114659542550162\n",
      "3470: avg rewards -1.2 std: 9.927738916792686 best avg 6.8@2430 epsilon 0.040836681622870484\n",
      "3480: avg rewards -2.0 std: 9.797958971132712 best avg 6.8@2430 epsilon 0.04052985151409894\n",
      "3490: avg rewards -1.2 std: 9.927738916792686 best avg 6.8@2430 epsilon 0.04022607441592045\n",
      "3500: avg rewards -2.0 std: 9.797958971132712 best avg 6.8@2430 epsilon 0.03992531995037202\n",
      "3510: avg rewards -2.8 std: 9.600000000000001 best avg 6.8@2430 epsilon 0.03962755804175648\n",
      "3520: avg rewards -1.2 std: 9.927738916792686 best avg 6.8@2430 epsilon 0.03933275891363482\n",
      "3530: avg rewards -2.8 std: 9.600000000000001 best avg 6.8@2430 epsilon 0.03904089308584859\n",
      "3540: avg rewards -1.2 std: 9.927738916792686 best avg 6.8@2430 epsilon 0.038751931371571756\n",
      "3550: avg rewards 1.2 std: 9.927738916792686 best avg 6.8@2430 epsilon 0.03846584487439211\n",
      "3560: avg rewards 0.4 std: 9.991996797437437 best avg 6.8@2430 epsilon 0.03818260498542151\n",
      "3570: avg rewards 2.0 std: 9.797958971132712 best avg 6.8@2430 epsilon 0.03790218338043505\n",
      "3580: avg rewards -1.2 std: 9.927738916792686 best avg 6.8@2430 epsilon 0.037624552017038515\n",
      "3590: avg rewards -2.8 std: 9.600000000000001 best avg 6.8@2430 epsilon 0.03734968313186423\n",
      "3600: avg rewards 0.4 std: 9.991996797437437 best avg 6.8@2430 epsilon 0.037077549237794605\n",
      "3610: avg rewards 1.2 std: 9.927738916792686 best avg 6.8@2430 epsilon 0.03680812312121347\n",
      "3620: avg rewards -1.2 std: 9.927738916792686 best avg 6.8@2430 epsilon 0.036541377839284614\n",
      "3630: avg rewards -0.4 std: 9.991996797437437 best avg 6.8@2430 epsilon 0.03627728671725759\n",
      "3640: avg rewards 0.4 std: 9.991996797437437 best avg 6.8@2430 epsilon 0.036015823345800106\n",
      "3650: avg rewards -3.6 std: 9.329523031752482 best avg 6.8@2430 epsilon 0.035756961578357116\n",
      "3660: avg rewards 2.8 std: 9.600000000000001 best avg 6.8@2430 epsilon 0.03550067552853617\n",
      "3670: avg rewards -0.4 std: 9.991996797437437 best avg 6.8@2430 epsilon 0.03524693956751871\n",
      "3680: avg rewards -2.0 std: 9.797958971132712 best avg 6.8@2430 epsilon 0.034995728321497194\n",
      "3690: avg rewards 1.2 std: 9.927738916792686 best avg 6.8@2430 epsilon 0.03474701666913767\n",
      "3700: avg rewards -2.4 std: 9.499473669630335 best avg 6.8@2430 epsilon 0.03450077973906764\n",
      "3710: avg rewards 1.2 std: 9.927738916792686 best avg 6.8@2430 epsilon 0.0342569929073889\n",
      "3720: avg rewards 0.4 std: 9.991996797437437 best avg 6.8@2430 epsilon 0.034015631795215134\n",
      "3730: avg rewards 1.2 std: 9.927738916792686 best avg 6.8@2430 epsilon 0.03377667226623397\n",
      "3740: avg rewards 2.0 std: 9.797958971132712 best avg 6.8@2430 epsilon 0.0335400904242934\n",
      "3750: avg rewards 0.4 std: 9.991996797437437 best avg 6.8@2430 epsilon 0.03330586261101206\n",
      "3760: avg rewards 2.0 std: 9.797958971132712 best avg 6.8@2430 epsilon 0.033073965403413445\n",
      "3770: avg rewards -1.2 std: 9.927738916792686 best avg 6.8@2430 epsilon 0.032844375611583536\n",
      "3780: avg rewards 2.8 std: 9.600000000000001 best avg 6.8@2430 epsilon 0.03261707027635183\n",
      "3790: avg rewards -0.4 std: 9.991996797437437 best avg 6.8@2430 epsilon 0.03239202666699538\n",
      "3800: avg rewards 2.0 std: 9.797958971132712 best avg 6.8@2430 epsilon 0.032169222278965716\n",
      "3810: avg rewards -2.0 std: 9.797958971132712 best avg 6.8@2430 epsilon 0.03194863483163835\n",
      "3820: avg rewards 0.4 std: 9.991996797437437 best avg 6.8@2430 epsilon 0.03173024226608476\n",
      "3830: avg rewards -4.4 std: 8.97997772825746 best avg 6.8@2430 epsilon 0.031514022742866354\n",
      "3840: avg rewards 4.4 std: 8.97997772825746 best avg 6.8@2430 epsilon 0.031299954639850656\n",
      "3850: avg rewards 0.4 std: 9.991996797437437 best avg 6.8@2430 epsilon 0.03108801655004896\n",
      "3860: avg rewards 1.2 std: 9.927738916792686 best avg 6.8@2430 epsilon 0.03087818727947568\n",
      "3870: avg rewards -2.0 std: 9.797958971132712 best avg 6.8@2430 epsilon 0.03067044584502889\n",
      "3880: avg rewards -1.2 std: 9.927738916792686 best avg 6.8@2430 epsilon 0.030464771472392037\n",
      "3890: avg rewards -0.4 std: 9.991996797437437 best avg 6.8@2430 epsilon 0.030261143593956458\n",
      "3900: avg rewards 1.2 std: 9.927738916792686 best avg 6.8@2430 epsilon 0.030059541846764605\n",
      "3910: avg rewards -1.2 std: 9.927738916792686 best avg 6.8@2430 epsilon 0.029859946070473785\n",
      "3920: avg rewards 2.0 std: 9.797958971132712 best avg 6.8@2430 epsilon 0.029662336305340008\n",
      "3930: avg rewards -1.2 std: 9.927738916792686 best avg 6.8@2430 epsilon 0.029466692790222113\n",
      "3940: avg rewards -0.8 std: 9.765244492586962 best avg 6.8@2430 epsilon 0.029272995960605522\n",
      "3950: avg rewards 1.2 std: 9.927738916792686 best avg 6.8@2430 epsilon 0.02908122644664589\n",
      "3960: avg rewards -2.0 std: 9.797958971132712 best avg 6.8@2430 epsilon 0.028891365071231988\n",
      "3970: avg rewards 5.2 std: 8.541662601625049 best avg 6.8@2430 epsilon 0.028703392848068075\n",
      "3980: avg rewards -1.2 std: 9.927738916792686 best avg 6.8@2430 epsilon 0.02851729097977517\n",
      "3990: avg rewards 0.4 std: 9.991996797437437 best avg 6.8@2430 epsilon 0.028333040856011384\n",
      "4000: avg rewards 2.0 std: 9.797958971132712 best avg 6.8@2430 epsilon 0.02815062405161077\n",
      "4010: avg rewards -2.8 std: 9.600000000000001 best avg 6.8@2430 epsilon 0.02797002232474089\n",
      "4020: avg rewards 2.8 std: 9.600000000000001 best avg 6.8@2430 epsilon 0.027791217615078558\n",
      "4030: avg rewards 2.0 std: 9.797958971132712 best avg 6.8@2430 epsilon 0.0276141920420038\n",
      "4040: avg rewards -2.8 std: 9.600000000000001 best avg 6.8@2430 epsilon 0.027438927902811786\n",
      "4050: avg rewards 1.2 std: 9.927738916792686 best avg 6.8@2430 epsilon 0.02726540767094253\n",
      "4060: avg rewards 1.2 std: 9.927738916792686 best avg 6.8@2430 epsilon 0.027093613994228265\n",
      "4070: avg rewards 0.4 std: 9.991996797437437 best avg 6.8@2430 epsilon 0.026923529693158144\n",
      "4080: avg rewards -3.6 std: 9.329523031752482 best avg 6.8@2430 epsilon 0.026755137759160337\n",
      "4090: avg rewards 1.2 std: 9.927738916792686 best avg 6.8@2430 epsilon 0.026588421352901084\n",
      "4100: avg rewards 2.8 std: 9.600000000000001 best avg 6.8@2430 epsilon 0.026423363802600873\n",
      "4110: avg rewards -1.6 std: 9.666436778875658 best avg 6.8@2430 epsilon 0.026259948602367106\n",
      "4120: avg rewards -3.6 std: 9.329523031752482 best avg 6.8@2430 epsilon 0.026098159410543574\n",
      "4130: avg rewards -1.2 std: 9.927738916792686 best avg 6.8@2430 epsilon 0.02593798004807627\n",
      "4140: avg rewards -0.4 std: 9.991996797437437 best avg 6.8@2430 epsilon 0.02577939449689546\n",
      "4150: avg rewards -0.4 std: 9.991996797437437 best avg 6.8@2430 epsilon 0.02562238689831389\n",
      "4160: avg rewards 2.8 std: 9.600000000000001 best avg 6.8@2430 epsilon 0.02546694155144085\n",
      "4170: avg rewards 0.4 std: 9.991996797437437 best avg 6.8@2430 epsilon 0.02531304291161212\n",
      "4180: avg rewards -0.4 std: 9.991996797437437 best avg 6.8@2430 epsilon 0.025160675588835446\n",
      "4190: avg rewards -3.6 std: 9.329523031752482 best avg 6.8@2430 epsilon 0.025009824346251604\n",
      "4200: avg rewards 5.2 std: 8.541662601625049 best avg 6.8@2430 epsilon 0.02486047409861062\n",
      "4210: avg rewards -1.2 std: 9.927738916792686 best avg 6.8@2430 epsilon 0.024712609910763267\n",
      "4220: avg rewards 1.2 std: 9.927738916792686 best avg 6.8@2430 epsilon 0.024566216996167522\n",
      "4230: avg rewards -0.4 std: 9.991996797437437 best avg 6.8@2430 epsilon 0.024421280715409964\n",
      "4240: avg rewards -0.4 std: 9.991996797437437 best avg 6.8@2430 epsilon 0.024277786574741722\n",
      "4250: avg rewards 0.4 std: 9.991996797437437 best avg 6.8@2430 epsilon 0.024135720224629148\n",
      "4260: avg rewards 1.2 std: 9.927738916792686 best avg 6.8@2430 epsilon 0.02399506745831883\n",
      "4270: avg rewards -1.2 std: 9.927738916792686 best avg 6.8@2430 epsilon 0.023855814210416954\n",
      "4280: avg rewards -0.4 std: 9.991996797437437 best avg 6.8@2430 epsilon 0.02371794655548267\n",
      "4290: avg rewards 0.4 std: 9.991996797437437 best avg 6.8@2430 epsilon 0.023581450706635594\n",
      "4300: avg rewards -0.4 std: 9.991996797437437 best avg 6.8@2430 epsilon 0.02344631301417708\n",
      "4310: avg rewards -0.4 std: 9.991996797437437 best avg 6.8@2430 epsilon 0.023312519964225294\n",
      "4320: avg rewards 2.0 std: 9.797958971132712 best avg 6.8@2430 epsilon 0.023180058177363738\n",
      "4330: avg rewards -0.4 std: 9.991996797437437 best avg 6.8@2430 epsilon 0.023048914407303334\n",
      "4340: avg rewards 1.2 std: 9.927738916792686 best avg 6.8@2430 epsilon 0.02291907553955778\n",
      "4350: avg rewards -4.4 std: 8.97997772825746 best avg 6.8@2430 epsilon 0.022790528590132128\n",
      "4360: avg rewards 1.2 std: 9.927738916792686 best avg 6.8@2430 epsilon 0.022663260704224295\n",
      "4370: avg rewards -2.0 std: 9.797958971132712 best avg 6.8@2430 epsilon 0.022537259154939638\n",
      "4380: avg rewards 0.4 std: 9.991996797437437 best avg 6.8@2430 epsilon 0.02241251134201823\n",
      "4390: avg rewards -2.8 std: 9.600000000000001 best avg 6.8@2430 epsilon 0.0222890047905748\n",
      "4400: avg rewards -2.0 std: 9.797958971132712 best avg 6.8@2430 epsilon 0.022166727149851316\n",
      "4410: avg rewards 2.0 std: 9.797958971132712 best avg 6.8@2430 epsilon 0.022045666191981787\n",
      "4420: avg rewards -2.8 std: 9.600000000000001 best avg 6.8@2430 epsilon 0.021925809810769543\n",
      "4430: avg rewards 0.8 std: 9.765244492586962 best avg 6.8@2430 epsilon 0.021807146020476578\n",
      "4440: avg rewards 2.8 std: 9.600000000000001 best avg 6.8@2430 epsilon 0.02168966295462499\n",
      "4450: avg rewards -0.4 std: 9.991996797437437 best avg 6.8@2430 epsilon 0.021573348864810278\n",
      "4460: avg rewards -1.2 std: 9.927738916792684 best avg 6.8@2430 epsilon 0.021458192119526542\n",
      "4470: avg rewards -3.6 std: 9.329523031752482 best avg 6.8@2430 epsilon 0.021344181203003274\n",
      "4480: avg rewards -3.6 std: 9.329523031752482 best avg 6.8@2430 epsilon 0.02123130471405383\n",
      "4490: avg rewards 0.4 std: 9.991996797437437 best avg 6.8@2430 epsilon 0.021119551364935246\n",
      "4500: avg rewards 2.8 std: 9.600000000000001 best avg 6.8@2430 epsilon 0.021008909980219474\n",
      "4510: avg rewards 1.6 std: 9.666436778875658 best avg 6.8@2430 epsilon 0.02089936949567584\n",
      "4520: avg rewards 2.0 std: 9.797958971132712 best avg 6.8@2430 epsilon 0.020790918957164624\n",
      "4530: avg rewards 0.4 std: 9.991996797437437 best avg 6.8@2430 epsilon 0.020683547519541583\n",
      "4540: avg rewards -2.8 std: 9.600000000000001 best avg 6.8@2430 epsilon 0.020577244445573482\n",
      "4550: avg rewards -1.2 std: 9.927738916792686 best avg 6.8@2430 epsilon 0.02047199910486433\n",
      "4560: avg rewards -2.0 std: 9.797958971132712 best avg 6.8@2430 epsilon 0.020367800972792373\n",
      "4570: avg rewards -1.2 std: 9.927738916792686 best avg 6.8@2430 epsilon 0.02026463962945755\n",
      "4580: avg rewards -1.2 std: 9.927738916792686 best avg 6.8@2430 epsilon 0.020162504758639573\n",
      "4590: avg rewards 2.4 std: 9.499473669630335 best avg 6.8@2430 epsilon 0.02006138614676623\n",
      "4600: avg rewards 1.2 std: 9.927738916792684 best avg 6.8@2430 epsilon 0.019961273681892093\n",
      "4610: avg rewards -2.0 std: 9.797958971132712 best avg 6.8@2430 epsilon 0.019862157352687232\n",
      "4620: avg rewards 4.4 std: 8.97997772825746 best avg 6.8@2430 epsilon 0.01976402724743613\n",
      "4630: avg rewards -2.0 std: 9.797958971132712 best avg 6.8@2430 epsilon 0.019666873553046492\n",
      "4640: avg rewards 0.4 std: 9.991996797437437 best avg 6.8@2430 epsilon 0.0195706865540679\n",
      "4650: avg rewards 6.8 std: 7.332121111929345 best avg 6.8@2430 epsilon 0.019475456631720324\n",
      "4660: avg rewards 3.6 std: 9.329523031752482 best avg 6.8@2430 epsilon 0.019381174262932163\n",
      "4670: avg rewards 3.6 std: 9.329523031752482 best avg 6.8@2430 epsilon 0.019287830019387962\n",
      "4680: avg rewards -0.4 std: 9.991996797437437 best avg 6.8@2430 epsilon 0.019195414566585578\n",
      "4690: avg rewards -0.4 std: 9.991996797437437 best avg 6.8@2430 epsilon 0.01910391866290273\n",
      "4700: avg rewards 2.0 std: 9.797958971132712 best avg 6.8@2430 epsilon 0.0190133331586728\n",
      "4710: avg rewards 0.8 std: 9.765244492586962 best avg 6.8@2430 epsilon 0.01892364899526987\n",
      "4720: avg rewards -1.2 std: 9.927738916792686 best avg 6.8@2430 epsilon 0.01883485720420286\n",
      "4730: avg rewards -0.4 std: 9.991996797437437 best avg 6.8@2430 epsilon 0.018746948906218683\n",
      "4740: avg rewards -1.6 std: 9.666436778875658 best avg 6.8@2430 epsilon 0.018659915310414277\n",
      "4750: avg rewards -2.0 std: 9.797958971132712 best avg 6.8@2430 epsilon 0.018573747713357534\n",
      "4760: avg rewards 0.8 std: 9.765244492586962 best avg 6.8@2430 epsilon 0.01848843749821693\n",
      "4770: avg rewards 2.8 std: 9.600000000000001 best avg 6.8@2430 epsilon 0.018403976133899876\n",
      "4780: avg rewards 0.4 std: 9.991996797437437 best avg 6.8@2430 epsilon 0.01832035517419955\n",
      "4790: avg rewards 2.8 std: 9.600000000000001 best avg 6.8@2430 epsilon 0.018237566256950298\n",
      "4800: avg rewards -0.4 std: 9.991996797437437 best avg 6.8@2430 epsilon 0.018155601103191393\n",
      "4810: avg rewards 1.2 std: 9.927738916792686 best avg 6.8@2430 epsilon 0.01807445151633917\n",
      "4820: avg rewards -0.4 std: 9.991996797437437 best avg 6.8@2430 epsilon 0.017994109381367317\n",
      "4830: avg rewards -1.2 std: 9.927738916792686 best avg 6.8@2430 epsilon 0.01791456666399538\n",
      "4840: avg rewards -0.4 std: 9.991996797437437 best avg 6.8@2430 epsilon 0.017835815409885325\n",
      "4850: avg rewards 2.0 std: 9.797958971132712 best avg 6.8@2430 epsilon 0.017757847743846138\n",
      "4860: avg rewards 1.2 std: 9.927738916792686 best avg 6.8@2430 epsilon 0.017680655869046227\n",
      "4870: avg rewards 3.6 std: 9.329523031752482 best avg 6.8@2430 epsilon 0.017604232066233794\n",
      "4880: avg rewards 5.2 std: 8.541662601625049 best avg 6.8@2430 epsilon 0.01752856869296486\n",
      "4890: avg rewards 0.4 std: 9.991996797437437 best avg 6.8@2430 epsilon 0.017453658182839046\n",
      "4900: avg rewards -0.4 std: 9.991996797437437 best avg 6.8@2430 epsilon 0.017379493044742927\n",
      "4910: avg rewards 1.2 std: 9.927738916792686 best avg 6.8@2430 epsilon 0.01730606586210088\n",
      "4920: avg rewards 5.2 std: 8.541662601625049 best avg 6.8@2430 epsilon 0.017233369292133448\n",
      "4930: avg rewards -0.4 std: 9.991996797437437 best avg 6.8@2430 epsilon 0.01716139606512305\n",
      "4940: avg rewards 0.4 std: 9.991996797437437 best avg 6.8@2430 epsilon 0.017090138983687025\n",
      "4950: avg rewards -0.8 std: 9.765244492586962 best avg 6.8@2430 epsilon 0.017019590922057834\n",
      "4960: avg rewards -0.4 std: 9.991996797437437 best avg 6.8@2430 epsilon 0.01694974482537053\n",
      "4970: avg rewards 2.0 std: 9.797958971132712 best avg 6.8@2430 epsilon 0.016880593708957232\n",
      "4980: avg rewards -4.4 std: 8.97997772825746 best avg 6.8@2430 epsilon 0.01681213065764868\n",
      "4990: avg rewards -0.4 std: 9.991996797437437 best avg 6.8@2430 epsilon 0.01674434882508269\n",
      "5000: avg rewards -2.0 std: 9.797958971132712 best avg 6.8@2430 epsilon 0.01667724143301951\n",
      "5010: avg rewards -3.6 std: 9.329523031752482 best avg 6.8@2430 epsilon 0.01661080177066402\n",
      "5020: avg rewards -1.2 std: 9.927738916792686 best avg 6.8@2430 epsilon 0.01654502319399462\n",
      "5030: avg rewards -1.2 std: 9.927738916792686 best avg 6.8@2430 epsilon 0.016479899125098826\n",
      "5040: avg rewards 2.8 std: 9.600000000000001 best avg 6.8@2430 epsilon 0.016415423051515474\n",
      "5050: avg rewards 1.2 std: 9.927738916792686 best avg 6.8@2430 epsilon 0.01635158852558347\n",
      "5060: avg rewards -0.4 std: 9.991996797437437 best avg 6.8@2430 epsilon 0.01628838916379704\n",
      "5070: avg rewards 2.8 std: 9.600000000000001 best avg 6.8@2430 epsilon 0.01622581864616733\n",
      "5080: avg rewards -1.2 std: 9.927738916792686 best avg 6.8@2430 epsilon 0.016163870715590438\n",
      "5090: avg rewards 0.4 std: 9.991996797437437 best avg 6.8@2430 epsilon 0.016102539177221674\n",
      "5100: avg rewards 1.2 std: 9.927738916792686 best avg 6.8@2430 epsilon 0.016041817897856102\n",
      "5110: avg rewards -2.4 std: 9.499473669630335 best avg 6.8@2430 epsilon 0.015981700805315184\n",
      "5120: avg rewards 2.8 std: 9.600000000000001 best avg 6.8@2430 epsilon 0.015922181887839566\n",
      "5130: avg rewards 1.2 std: 9.927738916792686 best avg 6.8@2430 epsilon 0.015863255193487896\n",
      "5140: avg rewards 4.4 std: 8.97997772825746 best avg 6.8@2430 epsilon 0.015804914829541633\n",
      "5150: avg rewards 1.2 std: 9.927738916792686 best avg 6.8@2430 epsilon 0.015747154961915776\n",
      "5160: avg rewards -0.4 std: 9.991996797437437 best avg 6.8@2430 epsilon 0.015689969814575423\n",
      "5170: avg rewards 3.6 std: 9.329523031752482 best avg 6.8@2430 epsilon 0.015633353668958183\n",
      "5180: avg rewards -0.4 std: 9.991996797437437 best avg 6.8@2430 epsilon 0.01557730086340231\n",
      "5190: avg rewards 1.2 std: 9.927738916792686 best avg 6.8@2430 epsilon 0.01552180579258055\n",
      "5200: avg rewards -3.2 std: 9.260669522232178 best avg 6.8@2430 epsilon 0.015466862906939568\n",
      "5210: avg rewards 1.6 std: 9.666436778875658 best avg 6.8@2430 epsilon 0.015412466712145014\n",
      "5220: avg rewards -1.2 std: 9.927738916792686 best avg 6.8@2430 epsilon 0.015358611768532072\n",
      "5230: avg rewards -2.0 std: 9.797958971132712 best avg 6.8@2430 epsilon 0.015305292690561516\n",
      "5240: avg rewards -4.0 std: 8.94427190999916 best avg 6.8@2430 epsilon 0.015252504146281107\n",
      "5250: avg rewards -1.2 std: 9.927738916792686 best avg 6.8@2430 epsilon 0.015200240856792427\n",
      "5260: avg rewards 1.2 std: 9.927738916792686 best avg 6.8@2430 epsilon 0.01514849759572297\n",
      "5270: avg rewards 0.4 std: 9.991996797437437 best avg 6.8@2430 epsilon 0.015097269188703518\n",
      "5280: avg rewards 2.0 std: 9.38083151964686 best avg 6.8@2430 epsilon 0.015046550512850677\n",
      "5290: avg rewards -0.4 std: 9.991996797437437 best avg 6.8@2430 epsilon 0.014996336496254592\n",
      "5300: avg rewards 1.2 std: 9.927738916792684 best avg 6.8@2430 epsilon 0.014946622117471758\n",
      "5310: avg rewards -0.4 std: 9.991996797437437 best avg 6.8@2430 epsilon 0.014897402405022872\n",
      "5320: avg rewards 3.6 std: 9.329523031752482 best avg 6.8@2430 epsilon 0.01484867243689567\n",
      "5330: avg rewards 0.0 std: 9.797958971132712 best avg 6.8@2430 epsilon 0.014800427340052734\n",
      "5340: avg rewards 1.6 std: 9.666436778875658 best avg 6.8@2430 epsilon 0.014752662289944166\n",
      "5350: avg rewards -1.2 std: 9.927738916792686 best avg 6.8@2430 epsilon 0.014705372510025162\n",
      "5360: avg rewards 1.2 std: 9.927738916792686 best avg 6.8@2430 epsilon 0.014658553271278319\n",
      "5370: avg rewards 0.4 std: 9.991996797437437 best avg 6.8@2430 epsilon 0.014612199891740743\n",
      "5380: avg rewards 1.6 std: 9.666436778875658 best avg 6.8@2430 epsilon 0.014566307736035854\n",
      "5390: avg rewards 3.6 std: 9.329523031752482 best avg 6.8@2430 epsilon 0.014520872214909835\n",
      "5400: avg rewards -4.4 std: 8.97997772825746 best avg 6.8@2430 epsilon 0.014475888784772717\n",
      "5410: avg rewards 2.8 std: 9.600000000000001 best avg 6.8@2430 epsilon 0.014431352947243995\n",
      "5420: avg rewards 4.4 std: 8.97997772825746 best avg 6.8@2430 epsilon 0.014387260248702804\n",
      "5430: avg rewards -0.8 std: 9.765244492586962 best avg 6.8@2430 epsilon 0.014343606279842543\n",
      "5440: avg rewards 1.2 std: 9.927738916792686 best avg 6.8@2430 epsilon 0.014300386675229952\n",
      "5450: avg rewards 2.0 std: 9.797958971132712 best avg 6.8@2430 epsilon 0.014257597112868552\n",
      "5460: avg rewards -2.4 std: 9.499473669630335 best avg 6.8@2430 epsilon 0.014215233313766448\n",
      "5470: avg rewards -2.8 std: 9.600000000000001 best avg 6.8@2430 epsilon 0.014173291041508424\n",
      "5480: avg rewards -1.2 std: 9.927738916792686 best avg 6.8@2430 epsilon 0.01413176610183231\n",
      "5490: avg rewards 2.0 std: 9.797958971132712 best avg 6.8@2430 epsilon 0.014090654342209526\n",
      "5500: avg rewards -2.0 std: 9.797958971132712 best avg 6.8@2430 epsilon 0.014049951651429856\n",
      "5510: avg rewards 1.2 std: 9.927738916792686 best avg 6.8@2430 epsilon 0.014009653959190294\n",
      "5520: avg rewards -2.0 std: 9.797958971132712 best avg 6.8@2430 epsilon 0.013969757235688045\n",
      "5530: avg rewards 3.2 std: 9.26066952223218 best avg 6.8@2430 epsilon 0.013930257491217506\n",
      "5540: avg rewards 6.0 std: 8.0 best avg 6.8@2430 epsilon 0.013891150775771317\n",
      "5550: avg rewards 1.2 std: 9.927738916792686 best avg 6.8@2430 epsilon 0.013852433178645335\n",
      "5560: avg rewards 1.2 std: 9.516301802696256 best avg 6.8@2430 epsilon 0.013814100828047593\n",
      "5570: avg rewards -0.4 std: 9.991996797437437 best avg 6.8@2430 epsilon 0.013776149890711084\n",
      "5580: avg rewards 0.4 std: 9.991996797437437 best avg 6.8@2430 epsilon 0.013738576571510449\n",
      "5590: avg rewards 6.0 std: 8.0 best avg 6.8@2430 epsilon 0.013701377113082454\n",
      "5600: avg rewards 2.8 std: 9.600000000000001 best avg 6.8@2430 epsilon 0.013664547795450259\n",
      "5610: avg rewards -1.2 std: 9.927738916792686 best avg 6.8@2430 epsilon 0.01362808493565141\n",
      "5620: avg rewards -3.6 std: 9.329523031752482 best avg 6.8@2430 epsilon 0.01359198488736954\n",
      "5630: avg rewards 0.4 std: 9.991996797437437 best avg 6.8@2430 epsilon 0.013556244040569737\n",
      "5640: avg rewards -2.0 std: 9.797958971132712 best avg 6.8@2430 epsilon 0.013520858821137537\n",
      "5650: avg rewards 0.8 std: 9.765244492586962 best avg 6.8@2430 epsilon 0.013485825690521511\n",
      "5660: avg rewards -1.2 std: 9.927738916792686 best avg 6.8@2430 epsilon 0.013451141145379401\n",
      "5670: avg rewards -2.0 std: 9.797958971132712 best avg 6.8@2430 epsilon 0.01341680171722779\n",
      "5680: avg rewards 2.4 std: 9.499473669630335 best avg 6.8@2430 epsilon 0.013382803972095243\n",
      "5690: avg rewards -3.6 std: 9.329523031752482 best avg 6.8@2430 epsilon 0.013349144510178922\n",
      "5700: avg rewards -1.6 std: 9.666436778875658 best avg 6.8@2430 epsilon 0.01331581996550458\n",
      "5710: avg rewards -3.6 std: 9.329523031752482 best avg 6.8@2430 epsilon 0.013282827005589984\n",
      "5720: avg rewards 2.8 std: 9.600000000000001 best avg 6.8@2430 epsilon 0.013250162331111641\n",
      "5730: avg rewards 1.2 std: 9.516301802696255 best avg 6.8@2430 epsilon 0.013217822675574888\n",
      "5740: avg rewards 1.2 std: 9.927738916792686 best avg 6.8@2430 epsilon 0.013185804804987222\n",
      "5750: avg rewards 0.4 std: 9.991996797437437 best avg 6.8@2430 epsilon 0.0131541055175349\n",
      "5760: avg rewards -2.8 std: 9.173875952943774 best avg 6.8@2430 epsilon 0.01312272164326276\n",
      "5770: avg rewards 4.0 std: 8.94427190999916 best avg 6.8@2430 epsilon 0.013091650043757225\n",
      "5780: avg rewards 1.2 std: 9.516301802696255 best avg 6.8@2430 epsilon 0.01306088761183245\n",
      "5790: avg rewards -2.4 std: 9.499473669630335 best avg 6.8@2430 epsilon 0.013030431271219604\n",
      "5800: avg rewards 1.2 std: 9.516301802696255 best avg 6.8@2430 epsilon 0.013000277976259248\n",
      "5810: avg rewards 2.8 std: 9.600000000000001 best avg 6.8@2430 epsilon 0.01297042471159676\n",
      "5820: avg rewards 3.2 std: 9.26066952223218 best avg 6.8@2430 epsilon 0.012940868491880793\n",
      "5830: avg rewards 2.8 std: 9.600000000000001 best avg 6.8@2430 epsilon 0.012911606361464746\n",
      "5840: avg rewards 2.0 std: 9.38083151964686 best avg 6.8@2430 epsilon 0.01288263539411119\n",
      "5850: avg rewards -1.6 std: 9.666436778875658 best avg 6.8@2430 epsilon 0.012853952692699252\n",
      "5860: avg rewards 1.2 std: 9.927738916792686 best avg 6.8@2430 epsilon 0.012825555388934885\n",
      "5870: avg rewards 3.2 std: 9.260669522232178 best avg 6.8@2430 epsilon 0.01279744064306405\n",
      "5880: avg rewards 2.8 std: 9.600000000000001 best avg 6.8@2430 epsilon 0.012769605643588729\n",
      "5890: avg rewards -2.4 std: 9.499473669630335 best avg 6.8@2430 epsilon 0.012742047606985777\n",
      "5900: avg rewards 1.2 std: 9.927738916792686 best avg 6.8@2430 epsilon 0.012714763777428573\n",
      "5910: avg rewards 2.8 std: 9.600000000000001 best avg 6.8@2430 epsilon 0.012687751426511422\n",
      "5920: avg rewards 2.0 std: 9.797958971132712 best avg 6.8@2430 epsilon 0.012661007852976724\n",
      "5930: avg rewards -0.4 std: 9.991996797437437 best avg 6.8@2430 epsilon 0.012634530382444834\n",
      "5940: avg rewards -1.2 std: 9.927738916792686 best avg 6.8@2430 epsilon 0.01260831636714664\n",
      "5950: avg rewards -0.4 std: 9.58331884056875 best avg 6.8@2430 epsilon 0.012582363185658767\n",
      "5960: avg rewards -2.8 std: 9.600000000000001 best avg 6.8@2430 epsilon 0.012556668242641435\n",
      "5970: avg rewards -2.0 std: 9.797958971132712 best avg 6.8@2430 epsilon 0.012531228968578927\n",
      "5980: avg rewards 3.6 std: 9.329523031752482 best avg 6.8@2430 epsilon 0.012506042819522646\n",
      "5990: avg rewards 2.0 std: 9.797958971132712 best avg 6.8@2430 epsilon 0.012481107276836692\n",
      "6000: avg rewards 0.4 std: 9.991996797437437 best avg 6.8@2430 epsilon 0.01245641984694602\n",
      "6010: avg rewards -1.2 std: 9.927738916792686 best avg 6.8@2430 epsilon 0.012431978061087062\n",
      "6020: avg rewards -1.2 std: 9.927738916792686 best avg 6.8@2430 epsilon 0.01240777947506087\n",
      "6030: avg rewards 0.0 std: 9.797958971132712 best avg 6.8@2430 epsilon 0.012383821668988673\n",
      "6040: avg rewards 0.4 std: 9.991996797437437 best avg 6.8@2430 epsilon 0.0123601022470699\n",
      "6050: avg rewards 1.6 std: 9.666436778875658 best avg 6.8@2430 epsilon 0.012336618837342592\n",
      "6060: avg rewards -3.6 std: 9.329523031752482 best avg 6.8@2430 epsilon 0.01231336909144621\n",
      "6070: avg rewards -2.8 std: 9.600000000000001 best avg 6.8@2430 epsilon 0.012290350684386782\n",
      "6080: avg rewards 0.8 std: 9.765244492586962 best avg 6.8@2430 epsilon 0.01226756131430443\n",
      "6090: avg rewards -2.4 std: 9.499473669630335 best avg 6.8@2430 epsilon 0.012244998702243142\n",
      "6100: avg rewards -0.4 std: 9.991996797437437 best avg 6.8@2430 epsilon 0.012222660591922922\n",
      "6110: avg rewards 4.4 std: 8.97997772825746 best avg 6.8@2430 epsilon 0.012200544749514116\n",
      "6120: avg rewards 4.0 std: 8.94427190999916 best avg 6.8@2430 epsilon 0.012178648963414057\n",
      "6130: avg rewards 2.0 std: 9.797958971132712 best avg 6.8@2430 epsilon 0.012156971044025884\n",
      "6140: avg rewards -2.4 std: 9.499473669630335 best avg 6.8@2430 epsilon 0.012135508823539596\n",
      "6150: avg rewards -1.2 std: 9.927738916792686 best avg 6.8@2430 epsilon 0.012114260155715258\n",
      "6160: avg rewards -4.0 std: 8.94427190999916 best avg 6.8@2430 epsilon 0.012093222915668382\n",
      "6170: avg rewards -1.6 std: 9.666436778875658 best avg 6.8@2430 epsilon 0.01207239499965743\n",
      "6180: avg rewards 0.8 std: 9.765244492586962 best avg 6.8@2430 epsilon 0.012051774324873445\n",
      "6190: avg rewards 0.0 std: 9.797958971132712 best avg 6.8@2430 epsilon 0.012031358829231766\n",
      "6200: avg rewards 3.6 std: 9.329523031752482 best avg 6.8@2430 epsilon 0.012011146471165815\n",
      "6210: avg rewards 0.4 std: 9.991996797437437 best avg 6.8@2430 epsilon 0.011991135229422942\n",
      "6220: avg rewards -1.6 std: 9.666436778875658 best avg 6.8@2430 epsilon 0.011971323102862294\n",
      "6230: avg rewards 2.4 std: 9.499473669630335 best avg 6.8@2430 epsilon 0.011951708110254708\n",
      "6240: avg rewards 1.2 std: 9.927738916792686 best avg 6.8@2430 epsilon 0.011932288290084577\n",
      "6250: avg rewards -1.2 std: 9.927738916792686 best avg 6.8@2430 epsilon 0.011913061700353701\n",
      "6260: avg rewards -1.6 std: 9.666436778875658 best avg 6.8@2430 epsilon 0.01189402641838708\n",
      "6270: avg rewards -1.6 std: 9.666436778875658 best avg 6.8@2430 epsilon 0.011875180540640662\n",
      "6280: avg rewards -2.8 std: 9.600000000000001 best avg 6.8@2430 epsilon 0.011856522182510962\n",
      "6290: avg rewards 2.0 std: 9.797958971132712 best avg 6.8@2430 epsilon 0.011838049478146621\n",
      "6300: avg rewards 0.4 std: 9.58331884056875 best avg 6.8@2430 epsilon 0.011819760580261806\n",
      "6310: avg rewards 2.8 std: 9.173875952943773 best avg 6.8@2430 epsilon 0.011801653659951492\n",
      "6320: avg rewards -1.2 std: 9.927738916792686 best avg 6.8@2430 epsilon 0.011783726906508555\n",
      "6330: avg rewards 1.6 std: 9.666436778875658 best avg 6.8@2430 epsilon 0.011765978527242713\n",
      "6340: avg rewards -1.6 std: 9.666436778875658 best avg 6.8@2430 epsilon 0.011748406747301248\n",
      "6350: avg rewards 0.4 std: 9.991996797437437 best avg 6.8@2430 epsilon 0.011731009809491523\n",
      "6360: avg rewards 2.0 std: 9.797958971132712 best avg 6.8@2430 epsilon 0.011713785974105263\n",
      "6370: avg rewards 2.4 std: 9.499473669630335 best avg 6.8@2430 epsilon 0.011696733518744572\n",
      "6380: avg rewards 0.8 std: 9.765244492586962 best avg 6.8@2430 epsilon 0.011679850738149705\n",
      "6390: avg rewards 3.6 std: 9.329523031752482 best avg 6.8@2430 epsilon 0.01166313594402853\n",
      "6400: avg rewards 2.0 std: 8.94427190999916 best avg 6.8@2430 epsilon 0.011646587464887713\n",
      "6410: avg rewards 3.2 std: 9.260669522232178 best avg 6.8@2430 epsilon 0.011630203645865545\n",
      "6420: avg rewards -1.6 std: 9.666436778875658 best avg 6.8@2430 epsilon 0.01161398284856647\n",
      "6430: avg rewards -1.2 std: 9.927738916792686 best avg 6.8@2430 epsilon 0.011597923450897243\n",
      "6440: avg rewards -1.2 std: 9.927738916792686 best avg 6.8@2430 epsilon 0.011582023846904712\n",
      "6450: avg rewards 2.8 std: 9.173875952943774 best avg 6.8@2430 epsilon 0.01156628244661523\n",
      "6460: avg rewards 1.2 std: 9.927738916792686 best avg 6.8@2430 epsilon 0.01155069767587565\n",
      "6470: avg rewards 0.0 std: 9.797958971132712 best avg 6.8@2430 epsilon 0.011535267976195905\n",
      "6480: avg rewards -2.8 std: 9.600000000000001 best avg 6.8@2430 epsilon 0.011519991804593179\n",
      "6490: avg rewards 2.8 std: 9.600000000000001 best avg 6.8@2430 epsilon 0.011504867633437575\n",
      "6500: avg rewards 0.0 std: 9.797958971132712 best avg 6.8@2430 epsilon 0.011489893950299375\n",
      "6510: avg rewards 0.8 std: 9.765244492586962 best avg 6.8@2430 epsilon 0.011475069257797788\n",
      "6520: avg rewards 2.0 std: 9.38083151964686 best avg 6.8@2430 epsilon 0.011460392073451208\n",
      "6530: avg rewards 6.0 std: 8.0 best avg 6.8@2430 epsilon 0.011445860929528972\n",
      "6540: avg rewards 2.0 std: 9.797958971132712 best avg 6.8@2430 epsilon 0.011431474372904576\n",
      "6550: avg rewards 2.4 std: 9.499473669630335 best avg 6.8@2430 epsilon 0.011417230964910369\n",
      "6560: avg rewards 2.4 std: 9.499473669630335 best avg 6.8@2430 epsilon 0.011403129281193684\n",
      "6570: avg rewards 5.2 std: 8.541662601625049 best avg 6.8@2430 epsilon 0.011389167911574398\n",
      "6580: avg rewards -1.2 std: 9.927738916792686 best avg 6.8@2430 epsilon 0.011375345459903912\n",
      "6590: avg rewards 2.4 std: 9.499473669630335 best avg 6.8@2430 epsilon 0.01136166054392554\n",
      "6600: avg rewards 1.2 std: 9.927738916792686 best avg 6.8@2430 epsilon 0.011348111795136282\n",
      "6610: avg rewards 3.6 std: 9.329523031752482 best avg 6.8@2430 epsilon 0.011334697858649968\n",
      "6620: avg rewards 0.8 std: 9.765244492586962 best avg 6.8@2430 epsilon 0.011321417393061773\n",
      "6630: avg rewards 4.0 std: 8.94427190999916 best avg 6.8@2430 epsilon 0.011308269070314068\n",
      "6640: avg rewards 1.2 std: 9.927738916792686 best avg 6.8@2430 epsilon 0.01129525157556362\n",
      "6650: avg rewards -0.4 std: 9.991996797437437 best avg 6.8@2430 epsilon 0.01128236360705011\n",
      "6660: avg rewards 4.4 std: 8.97997772825746 best avg 6.8@2430 epsilon 0.011269603875965945\n",
      "6670: avg rewards 2.0 std: 9.797958971132712 best avg 6.8@2430 epsilon 0.011256971106327384\n",
      "6680: avg rewards 3.2 std: 9.26066952223218 best avg 6.8@2430 epsilon 0.011244464034846934\n",
      "6690: avg rewards 1.2 std: 9.927738916792686 best avg 6.8@2430 epsilon 0.011232081410807025\n",
      "6700: avg rewards 5.2 std: 8.541662601625049 best avg 6.8@2430 epsilon 0.011219821995934937\n",
      "6710: avg rewards -0.4 std: 9.58331884056875 best avg 6.8@2430 epsilon 0.011207684564278963\n",
      "6720: avg rewards 2.8 std: 9.600000000000001 best avg 6.8@2430 epsilon 0.011195667902085822\n",
      "6730: avg rewards 3.6 std: 8.890444308357148 best avg 6.8@2430 epsilon 0.011183770807679285\n",
      "6740: avg rewards 3.2 std: 9.260669522232178 best avg 6.8@2430 epsilon 0.011171992091339995\n",
      "6750: avg rewards 2.4 std: 9.499473669630335 best avg 6.8@2430 epsilon 0.011160330575186502\n",
      "6760: avg rewards 0.0 std: 9.797958971132712 best avg 6.8@2430 epsilon 0.011148785093057473\n",
      "6770: avg rewards 1.6 std: 9.666436778875658 best avg 6.8@2430 epsilon 0.011137354490395074\n",
      "6780: avg rewards -1.2 std: 9.927738916792686 best avg 6.8@2430 epsilon 0.011126037624129512\n",
      "6790: avg rewards 2.0 std: 9.797958971132712 best avg 6.8@2430 epsilon 0.011114833362564733\n",
      "6800: avg rewards 1.2 std: 9.927738916792686 best avg 6.8@2430 epsilon 0.011103740585265238\n",
      "6810: avg rewards 4.4 std: 8.97997772825746 best avg 6.8@2430 epsilon 0.011092758182944059\n",
      "6820: avg rewards 3.6 std: 9.329523031752482 best avg 6.8@2430 epsilon 0.011081885057351809\n",
      "6830: avg rewards 6.0 std: 8.0 best avg 6.8@2430 epsilon 0.011071120121166868\n",
      "6840: avg rewards 0.8 std: 9.765244492586962 best avg 6.8@2430 epsilon 0.011060462297886646\n",
      "6850: avg rewards 2.4 std: 9.499473669630335 best avg 6.8@2430 epsilon 0.011049910521719934\n",
      "6860: avg rewards 1.6 std: 9.666436778875658 best avg 6.8@2430 epsilon 0.011039463737480323\n",
      "6870: avg rewards 0.4 std: 9.991996797437437 best avg 6.8@2430 epsilon 0.011029120900480683\n",
      "6880: avg rewards 1.2 std: 9.927738916792686 best avg 6.8@2430 epsilon 0.011018880976428695\n",
      "6890: avg rewards 2.4 std: 9.499473669630335 best avg 6.8@2430 epsilon 0.011008742941323419\n",
      "6900: avg rewards 2.0 std: 9.797958971132712 best avg 6.8@2430 epsilon 0.010998705781352897\n",
      "6910: avg rewards 2.8 std: 9.600000000000001 best avg 6.8@2430 epsilon 0.01098876849279277\n",
      "6920: avg rewards 1.2 std: 9.927738916792684 best avg 6.8@2430 epsilon 0.010978930081905897\n",
      "6930: avg rewards 1.6 std: 9.243376006633074 best avg 6.8@2430 epsilon 0.010969189564842993\n",
      "6940: avg rewards -1.2 std: 9.927738916792686 best avg 6.8@2430 epsilon 0.010959545967544233\n",
      "6950: avg rewards 2.0 std: 9.797958971132712 best avg 6.8@2430 epsilon 0.010949998325641853\n",
      "6960: avg rewards 2.0 std: 9.797958971132712 best avg 6.8@2430 epsilon 0.010940545684363704\n",
      "6970: avg rewards 3.6 std: 9.329523031752482 best avg 6.8@2430 epsilon 0.010931187098437782\n",
      "6980: avg rewards 2.0 std: 9.797958971132712 best avg 6.8@2430 epsilon 0.010921921631997697\n",
      "6990: avg rewards 1.6 std: 9.666436778875658 best avg 6.8@2430 epsilon 0.010912748358489082\n",
      "7000: avg rewards 1.2 std: 9.927738916792686 best avg 6.8@2430 epsilon 0.010903666360576941\n",
      "7010: avg rewards -0.4 std: 9.991996797437437 best avg 6.8@2430 epsilon 0.010894674730053917\n",
      "7020: avg rewards -1.2 std: 9.927738916792686 best avg 6.8@2430 epsilon 0.010885772567749462\n",
      "7030: avg rewards 5.2 std: 8.541662601625049 best avg 6.8@2430 epsilon 0.01087695898343993\n",
      "7040: avg rewards 3.6 std: 9.329523031752482 best avg 6.8@2430 epsilon 0.01086823309575954\n",
      "7050: avg rewards 3.6 std: 9.329523031752482 best avg 6.8@2430 epsilon 0.010859594032112257\n",
      "7060: avg rewards 1.6 std: 9.666436778875658 best avg 6.8@2430 epsilon 0.010851040928584518\n",
      "7070: avg rewards 0.4 std: 9.991996797437437 best avg 6.8@2430 epsilon 0.010842572929858841\n",
      "7080: avg rewards 0.4 std: 9.991996797437437 best avg 6.8@2430 epsilon 0.010834189189128294\n",
      "7090: avg rewards 0.4 std: 9.991996797437437 best avg 6.8@2430 epsilon 0.010825888868011821\n",
      "7100: avg rewards 2.8 std: 9.600000000000001 best avg 6.8@2430 epsilon 0.010817671136470391\n",
      "7110: avg rewards 1.2 std: 9.927738916792686 best avg 6.8@2430 epsilon 0.010809535172724006\n",
      "7120: avg rewards 5.2 std: 8.541662601625049 best avg 6.8@2430 epsilon 0.010801480163169504\n",
      "7130: avg rewards 6.0 std: 8.0 best avg 6.8@2430 epsilon 0.010793505302299226\n",
      "7140: avg rewards 1.2 std: 9.927738916792684 best avg 6.8@2430 epsilon 0.010785609792620431\n",
      "7150: avg rewards 2.0 std: 9.797958971132712 best avg 6.8@2430 epsilon 0.010777792844575576\n",
      "7160: avg rewards 0.8 std: 9.765244492586962 best avg 6.8@2430 epsilon 0.010770053676463342\n",
      "7170: avg rewards 1.2 std: 9.927738916792686 best avg 6.8@2430 epsilon 0.010762391514360467\n",
      "7180: avg rewards 3.6 std: 9.329523031752482 best avg 6.8@2430 epsilon 0.010754805592044357\n",
      "7190: avg rewards -0.8 std: 9.765244492586962 best avg 6.8@2430 epsilon 0.010747295150916457\n",
      "7200: avg rewards 1.6 std: 9.666436778875658 best avg 6.8@2430 epsilon 0.010739859439926398\n",
      "7210: avg rewards 3.6 std: 9.329523031752482 best avg 6.8@2430 epsilon 0.010732497715496883\n",
      "7220: avg rewards 1.6 std: 9.666436778875658 best avg 6.8@2430 epsilon 0.010725209241449334\n",
      "7230: avg rewards 1.2 std: 9.927738916792686 best avg 6.8@2430 epsilon 0.010717993288930274\n",
      "7240: avg rewards 3.2 std: 9.260669522232178 best avg 6.8@2430 epsilon 0.010710849136338437\n",
      "7250: avg rewards 2.8 std: 9.600000000000001 best avg 6.8@2430 epsilon 0.010703776069252609\n",
      "7260: avg rewards 1.6 std: 9.666436778875658 best avg 6.8@2430 epsilon 0.010696773380360187\n",
      "7270: avg rewards 4.8 std: 8.059776671843954 best avg 6.8@2430 epsilon 0.01068984036938645\n",
      "7280: avg rewards -0.8 std: 9.765244492586962 best avg 6.8@2430 epsilon 0.010682976343024519\n",
      "7290: avg rewards -0.4 std: 9.991996797437437 best avg 6.8@2430 epsilon 0.01067618061486604\n",
      "7300: avg rewards 2.4 std: 9.499473669630335 best avg 6.8@2430 epsilon 0.010669452505332534\n",
      "7310: avg rewards 2.0 std: 9.797958971132712 best avg 6.8@2430 epsilon 0.010662791341607438\n",
      "7320: avg rewards 4.4 std: 8.97997772825746 best avg 6.8@2430 epsilon 0.010656196457568833\n",
      "7330: avg rewards -1.2 std: 9.927738916792686 best avg 6.8@2430 epsilon 0.010649667193722815\n",
      "7340: avg rewards 2.0 std: 9.797958971132712 best avg 6.8@2430 epsilon 0.010643202897137563\n",
      "7350: avg rewards 2.0 std: 9.797958971132712 best avg 6.8@2430 epsilon 0.010636802921378027\n",
      "7360: avg rewards 3.6 std: 9.329523031752482 best avg 6.8@2430 epsilon 0.0106304666264413\n",
      "7370: avg rewards 2.8 std: 9.600000000000001 best avg 6.8@2430 epsilon 0.010624193378692607\n",
      "7380: avg rewards 0.4 std: 9.991996797437437 best avg 6.8@2430 epsilon 0.010617982550801949\n",
      "7390: avg rewards 4.0 std: 8.94427190999916 best avg 6.8@2430 epsilon 0.010611833521681355\n",
      "7400: avg rewards 4.4 std: 8.97997772825746 best avg 6.8@2430 epsilon 0.010605745676422794\n",
      "7410: avg rewards 2.0 std: 9.797958971132712 best avg 6.8@2430 epsilon 0.010599718406236665\n",
      "7420: avg rewards 0.4 std: 9.991996797437437 best avg 6.8@2430 epsilon 0.010593751108390927\n",
      "7430: avg rewards -0.4 std: 9.991996797437437 best avg 6.8@2430 epsilon 0.01058784318615082\n",
      "7440: avg rewards 2.4 std: 9.499473669630335 best avg 6.8@2430 epsilon 0.010581994048719201\n",
      "7450: avg rewards 2.0 std: 9.797958971132712 best avg 6.8@2430 epsilon 0.01057620311117745\n",
      "7460: avg rewards 2.8 std: 9.600000000000001 best avg 6.8@2430 epsilon 0.010570469794426988\n",
      "7470: avg rewards 4.8 std: 8.541662601625049 best avg 6.8@2430 epsilon 0.010564793525131361\n",
      "7480: avg rewards 3.6 std: 9.329523031752482 best avg 6.8@2430 epsilon 0.01055917373565891\n",
      "7490: avg rewards 0.4 std: 9.991996797437437 best avg 6.8@2430 epsilon 0.010553609864026006\n",
      "7500: avg rewards 3.6 std: 9.329523031752482 best avg 6.8@2430 epsilon 0.010548101353840846\n",
      "7510: avg rewards 1.2 std: 9.927738916792686 best avg 6.8@2430 epsilon 0.010542647654247825\n",
      "7520: avg rewards 3.2 std: 9.260669522232178 best avg 6.8@2430 epsilon 0.010537248219872434\n",
      "7530: avg rewards -0.4 std: 9.991996797437437 best avg 6.8@2430 epsilon 0.01053190251076674\n",
      "7540: avg rewards 0.4 std: 9.991996797437437 best avg 6.8@2430 epsilon 0.010526609992355376\n",
      "7550: avg rewards 0.4 std: 9.991996797437437 best avg 6.8@2430 epsilon 0.010521370135382091\n",
      "7560: avg rewards 2.0 std: 9.797958971132712 best avg 6.8@2430 epsilon 0.01051618241585682\n",
      "7570: avg rewards 0.4 std: 9.991996797437437 best avg 6.8@2430 epsilon 0.010511046315003289\n",
      "7580: avg rewards -2.0 std: 9.797958971132712 best avg 6.8@2430 epsilon 0.01050596131920713\n",
      "7590: avg rewards 4.0 std: 8.94427190999916 best avg 6.8@2430 epsilon 0.010500926919964529\n",
      "7600: avg rewards 2.4 std: 9.499473669630335 best avg 6.8@2430 epsilon 0.010495942613831365\n",
      "7610: avg rewards 1.2 std: 9.927738916792686 best avg 6.8@2430 epsilon 0.010491007902372871\n",
      "7620: avg rewards 4.0 std: 8.94427190999916 best avg 6.8@2430 epsilon 0.010486122292113789\n",
      "7630: avg rewards 4.4 std: 8.97997772825746 best avg 6.8@2430 epsilon 0.010481285294489022\n",
      "7640: avg rewards -0.4 std: 9.991996797437437 best avg 6.8@2430 epsilon 0.010476496425794775\n",
      "7650: avg rewards 0.4 std: 9.991996797437437 best avg 6.8@2430 epsilon 0.01047175520714019\n",
      "7660: avg rewards 4.0 std: 8.94427190999916 best avg 6.8@2430 epsilon 0.010467061164399449\n",
      "7670: avg rewards 3.6 std: 9.329523031752482 best avg 6.8@2430 epsilon 0.010462413828164367\n",
      "7680: avg rewards 3.6 std: 9.329523031752482 best avg 6.8@2430 epsilon 0.010457812733697449\n",
      "7690: avg rewards 0.4 std: 9.991996797437437 best avg 6.8@2430 epsilon 0.01045325742088541\n",
      "7700: avg rewards 4.4 std: 8.97997772825746 best avg 6.8@2430 epsilon 0.010448747434193177\n",
      "7710: avg rewards 2.8 std: 9.600000000000001 best avg 6.8@2430 epsilon 0.010444282322618322\n",
      "7720: avg rewards 0.4 std: 9.991996797437437 best avg 6.8@2430 epsilon 0.010439861639645963\n",
      "7730: avg rewards 6.0 std: 8.0 best avg 6.8@2430 epsilon 0.010435484943204123\n",
      "7740: avg rewards 2.8 std: 9.173875952943773 best avg 6.8@2430 epsilon 0.010431151795619507\n",
      "7750: avg rewards 3.6 std: 9.329523031752482 best avg 6.8@2430 epsilon 0.010426861763573748\n",
      "7760: avg rewards 0.8 std: 9.765244492586962 best avg 6.8@2430 epsilon 0.010422614418060066\n",
      "7770: avg rewards 4.8 std: 8.541662601625049 best avg 6.8@2430 epsilon 0.01041840933434037\n",
      "7780: avg rewards 6.0 std: 8.0 best avg 6.8@2430 epsilon 0.010414246091902784\n",
      "7790: avg rewards 3.6 std: 9.329523031752482 best avg 6.8@2430 epsilon 0.010410124274419594\n",
      "7800: avg rewards 4.0 std: 8.94427190999916 best avg 6.8@2430 epsilon 0.010406043469705617\n",
      "7810: avg rewards 2.0 std: 9.797958971132712 best avg 6.8@2430 epsilon 0.010402003269676982\n",
      "7820: avg rewards 4.4 std: 8.97997772825746 best avg 6.8@2430 epsilon 0.010398003270310317\n",
      "7830: avg rewards 1.6 std: 9.666436778875658 best avg 6.8@2430 epsilon 0.010394043071602355\n",
      "7840: avg rewards 2.8 std: 9.600000000000001 best avg 6.8@2430 epsilon 0.010390122277529923\n",
      "7850: avg rewards 3.6 std: 9.329523031752482 best avg 6.8@2430 epsilon 0.010386240496010347\n",
      "7860: avg rewards 1.2 std: 9.927738916792686 best avg 6.8@2430 epsilon 0.01038239733886224\n",
      "7870: avg rewards 6.8 std: 7.332121111929345 best avg 6.8@2430 epsilon 0.010378592421766685\n",
      "7880: avg rewards 2.8 std: 9.600000000000001 best avg 6.8@2430 epsilon 0.010374825364228802\n",
      "7890: avg rewards 4.4 std: 8.97997772825746 best avg 6.8@2430 epsilon 0.010371095789539696\n",
      "7900: avg rewards 2.8 std: 9.600000000000001 best avg 6.8@2430 epsilon 0.010367403324738792\n",
      "7910: avg rewards 4.4 std: 8.979977728257458 best avg 6.8@2430 epsilon 0.010363747600576534\n",
      "7920: avg rewards 3.6 std: 9.329523031752482 best avg 6.8@2430 epsilon 0.010360128251477457\n",
      "7930: avg rewards 3.6 std: 9.329523031752482 best avg 6.8@2430 epsilon 0.010356544915503633\n",
      "7940: avg rewards 0.0 std: 9.797958971132712 best avg 6.8@2430 epsilon 0.010352997234318484\n",
      "7950: avg rewards 4.0 std: 8.94427190999916 best avg 6.8@2430 epsilon 0.010349484853150931\n",
      "7960: avg rewards 2.8 std: 9.600000000000001 best avg 6.8@2430 epsilon 0.010346007420759931\n",
      "7970: avg rewards -0.4 std: 9.991996797437437 best avg 6.8@2430 epsilon 0.010342564589399349\n",
      "7980: avg rewards 1.6 std: 9.666436778875658 best avg 6.8@2430 epsilon 0.010339156014783177\n",
      "7990: avg rewards 3.6 std: 9.329523031752482 best avg 6.8@2430 epsilon 0.010335781356051114\n",
      "8000: avg rewards 6.0 std: 8.0 best avg 6.8@2430 epsilon 0.010332440275734477\n",
      "8010: avg rewards 4.0 std: 8.94427190999916 best avg 6.8@2430 epsilon 0.010329132439722446\n",
      "8020: avg rewards -0.4 std: 9.991996797437437 best avg 6.8@2430 epsilon 0.010325857517228665\n",
      "8030: avg rewards 6.8 std: 7.332121111929345 best avg 6.8@2430 epsilon 0.010322615180758157\n",
      "8040: avg rewards 5.2 std: 8.541662601625049 best avg 6.8@2430 epsilon 0.010319405106074571\n",
      "8050: avg rewards 1.6 std: 9.666436778875658 best avg 6.8@2430 epsilon 0.010316226972167764\n",
      "8060: avg rewards 4.0 std: 8.94427190999916 best avg 6.8@2430 epsilon 0.010313080461221698\n",
      "8070: avg rewards 0.4 std: 9.991996797437437 best avg 6.8@2430 epsilon 0.010309965258582654\n",
      "8080: avg rewards 3.6 std: 9.329523031752482 best avg 6.8@2430 epsilon 0.010306881052727776\n",
      "8090: avg rewards 2.4 std: 9.499473669630335 best avg 6.8@2430 epsilon 0.010303827535233904\n",
      "8100: avg rewards -1.2 std: 9.927738916792686 best avg 6.8@2430 epsilon 0.010300804400746747\n",
      "8110: avg rewards 2.0 std: 9.797958971132712 best avg 6.8@2430 epsilon 0.010297811346950334\n",
      "8120: avg rewards 2.8 std: 9.600000000000001 best avg 6.8@2430 epsilon 0.010294848074536794\n",
      "8130: avg rewards 4.0 std: 8.94427190999916 best avg 6.8@2430 epsilon 0.010291914287176416\n",
      "8140: avg rewards 1.2 std: 9.927738916792686 best avg 6.8@2430 epsilon 0.010289009691488018\n",
      "8150: avg rewards 2.0 std: 9.797958971132712 best avg 6.8@2430 epsilon 0.01028613399700961\n",
      "8160: avg rewards 1.6 std: 9.666436778875658 best avg 6.8@2430 epsilon 0.010283286916169348\n",
      "8170: avg rewards 2.8 std: 9.600000000000001 best avg 6.8@2430 epsilon 0.010280468164256778\n",
      "8180: avg rewards -1.2 std: 9.927738916792686 best avg 6.8@2430 epsilon 0.010277677459394358\n",
      "8190: avg rewards 0.8 std: 9.765244492586962 best avg 6.8@2430 epsilon 0.010274914522509275\n",
      "8200: avg rewards 1.2 std: 9.927738916792686 best avg 6.8@2430 epsilon 0.01027217907730554\n",
      "8210: avg rewards 1.6 std: 9.666436778875658 best avg 6.8@2430 epsilon 0.010269470850236351\n",
      "8220: avg rewards 2.0 std: 9.797958971132712 best avg 6.8@2430 epsilon 0.010266789570476748\n",
      "8230: avg rewards 6.0 std: 8.0 best avg 6.8@2430 epsilon 0.010264134969896515\n",
      "8240: avg rewards 2.8 std: 9.600000000000001 best avg 6.8@2430 epsilon 0.010261506783033386\n",
      "8250: avg rewards 0.8 std: 9.765244492586962 best avg 6.8@2430 epsilon 0.010258904747066484\n",
      "8260: avg rewards 0.4 std: 9.991996797437437 best avg 6.8@2430 epsilon 0.010256328601790043\n",
      "8270: avg rewards 4.4 std: 8.97997772825746 best avg 6.8@2430 epsilon 0.01025377808958739\n",
      "8280: avg rewards 0.4 std: 9.58331884056875 best avg 6.8@2430 epsilon 0.010251252955405176\n",
      "8290: avg rewards 2.0 std: 9.797958971132712 best avg 6.8@2430 epsilon 0.010248752946727882\n",
      "8300: avg rewards 6.8 std: 7.332121111929345 best avg 6.8@2430 epsilon 0.010246277813552555\n",
      "8310: avg rewards 2.4 std: 9.499473669630335 best avg 6.8@2430 epsilon 0.010243827308363816\n",
      "8320: avg rewards 4.4 std: 8.97997772825746 best avg 6.8@2430 epsilon 0.010241401186109103\n",
      "8330: avg rewards 3.6 std: 9.329523031752482 best avg 6.8@2430 epsilon 0.01023899920417417\n",
      "8340: avg rewards 1.2 std: 9.927738916792686 best avg 6.8@2430 epsilon 0.010236621122358819\n",
      "8350: avg rewards -0.4 std: 9.991996797437437 best avg 6.8@2430 epsilon 0.010234266702852891\n",
      "8360: avg rewards -2.8 std: 9.600000000000001 best avg 6.8@2430 epsilon 0.01023193571021247\n",
      "8370: avg rewards 0.4 std: 9.991996797437437 best avg 6.8@2430 epsilon 0.010229627911336352\n",
      "8380: avg rewards 4.4 std: 8.97997772825746 best avg 6.8@2430 epsilon 0.010227343075442723\n",
      "8390: avg rewards 2.0 std: 9.797958971132712 best avg 6.8@2430 epsilon 0.010225080974046093\n",
      "8400: avg rewards 1.2 std: 9.927738916792686 best avg 6.8@2430 epsilon 0.010222841380934435\n",
      "8410: avg rewards 2.8 std: 9.600000000000001 best avg 6.8@2430 epsilon 0.010220624072146573\n",
      "8420: avg rewards -0.4 std: 9.991996797437437 best avg 6.8@2430 epsilon 0.010218428825949779\n",
      "8430: avg rewards 1.2 std: 9.927738916792686 best avg 6.8@2430 epsilon 0.010216255422817604\n",
      "8440: avg rewards 1.2 std: 9.927738916792686 best avg 6.8@2430 epsilon 0.010214103645407925\n",
      "8450: avg rewards -0.4 std: 9.991996797437437 best avg 6.8@2430 epsilon 0.010211973278541207\n",
      "8460: avg rewards 3.6 std: 9.329523031752482 best avg 6.8@2430 epsilon 0.010209864109178988\n",
      "8470: avg rewards 3.2 std: 9.260669522232178 best avg 6.8@2430 epsilon 0.010207775926402575\n",
      "8480: avg rewards 2.8 std: 9.600000000000001 best avg 6.8@2430 epsilon 0.010205708521391948\n",
      "8490: avg rewards 2.0 std: 9.797958971132712 best avg 6.8@2430 epsilon 0.010203661687404886\n",
      "8500: avg rewards -1.2 std: 9.927738916792686 best avg 6.8@2430 epsilon 0.010201635219756281\n",
      "8510: avg rewards 3.6 std: 9.329523031752482 best avg 6.8@2430 epsilon 0.010199628915797683\n",
      "8520: avg rewards 3.6 std: 9.329523031752482 best avg 6.8@2430 epsilon 0.010197642574897024\n",
      "8530: avg rewards 4.0 std: 8.94427190999916 best avg 6.8@2430 epsilon 0.010195675998418556\n",
      "8540: avg rewards 2.8 std: 9.600000000000001 best avg 6.8@2430 epsilon 0.010193728989702994\n",
      "8550: avg rewards -2.8 std: 9.600000000000001 best avg 6.8@2430 epsilon 0.010191801354047843\n",
      "8560: avg rewards 2.0 std: 9.797958971132712 best avg 6.8@2430 epsilon 0.010189892898687932\n",
      "8570: avg rewards 2.0 std: 9.797958971132712 best avg 6.8@2430 epsilon 0.010188003432776135\n",
      "8580: avg rewards 2.8 std: 9.600000000000001 best avg 6.8@2430 epsilon 0.010186132767364285\n",
      "8590: avg rewards 3.6 std: 9.329523031752482 best avg 6.8@2430 epsilon 0.010184280715384283\n",
      "8600: avg rewards 2.4 std: 9.499473669630335 best avg 6.8@2430 epsilon 0.010182447091629387\n",
      "8610: avg rewards 4.4 std: 8.97997772825746 best avg 6.8@2430 epsilon 0.010180631712735694\n",
      "8620: avg rewards 3.2 std: 9.260669522232178 best avg 6.8@2430 epsilon 0.010178834397163801\n",
      "8630: avg rewards 3.2 std: 9.260669522232178 best avg 6.8@2430 epsilon 0.010177054965180654\n",
      "8640: avg rewards 2.4 std: 9.499473669630335 best avg 6.8@2430 epsilon 0.010175293238841572\n",
      "8650: avg rewards 3.2 std: 9.260669522232178 best avg 6.8@2430 epsilon 0.010173549041972452\n",
      "8660: avg rewards 2.0 std: 9.797958971132712 best avg 6.8@2430 epsilon 0.010171822200152152\n",
      "8670: avg rewards 1.2 std: 9.927738916792686 best avg 6.8@2430 epsilon 0.010170112540695055\n",
      "8680: avg rewards 2.8 std: 9.600000000000001 best avg 6.8@2430 epsilon 0.010168419892633788\n",
      "8690: avg rewards -2.0 std: 9.38083151964686 best avg 6.8@2430 epsilon 0.010166744086702135\n",
      "8700: avg rewards 2.0 std: 9.797958971132712 best avg 6.8@2430 epsilon 0.010165084955318105\n",
      "8710: avg rewards 0.4 std: 9.991996797437437 best avg 6.8@2430 epsilon 0.010163442332567179\n",
      "8720: avg rewards -4.4 std: 8.522910301065007 best avg 6.8@2430 epsilon 0.010161816054185712\n",
      "8730: avg rewards 0.0 std: 9.797958971132712 best avg 6.8@2430 epsilon 0.010160205957544511\n",
      "8740: avg rewards 0.8 std: 9.765244492586962 best avg 6.8@2430 epsilon 0.010158611881632569\n",
      "8750: avg rewards 2.8 std: 9.600000000000001 best avg 6.8@2430 epsilon 0.010157033667040967\n",
      "8760: avg rewards 1.2 std: 9.516301802696255 best avg 6.8@2430 epsilon 0.010155471155946932\n",
      "8770: avg rewards 4.4 std: 8.97997772825746 best avg 6.8@2430 epsilon 0.010153924192098051\n",
      "8780: avg rewards 2.4 std: 9.499473669630335 best avg 6.8@2430 epsilon 0.01015239262079665\n",
      "8790: avg rewards 2.8 std: 9.600000000000001 best avg 6.8@2430 epsilon 0.010150876288884324\n",
      "8800: avg rewards 1.6 std: 9.666436778875658 best avg 6.8@2430 epsilon 0.010149375044726615\n",
      "8810: avg rewards 2.0 std: 9.797958971132712 best avg 6.8@2430 epsilon 0.010147888738197861\n",
      "8820: avg rewards 5.2 std: 8.541662601625049 best avg 6.8@2430 epsilon 0.010146417220666165\n",
      "8830: avg rewards 2.8 std: 9.600000000000001 best avg 6.8@2430 epsilon 0.010144960344978552\n",
      "8840: avg rewards 6.4 std: 7.418894796396563 best avg 6.8@2430 epsilon 0.010143517965446238\n",
      "8850: avg rewards 2.4 std: 9.499473669630335 best avg 6.8@2430 epsilon 0.010142089937830067\n",
      "8860: avg rewards 1.2 std: 9.927738916792686 best avg 6.8@2430 epsilon 0.010140676119326088\n",
      "8870: avg rewards 0.8 std: 9.765244492586962 best avg 6.8@2430 epsilon 0.010139276368551272\n",
      "8880: avg rewards 4.4 std: 8.97997772825746 best avg 6.8@2430 epsilon 0.010137890545529374\n",
      "8890: avg rewards 6.0 std: 8.0 best avg 6.8@2430 epsilon 0.01013651851167694\n",
      "8900: avg rewards 2.0 std: 9.797958971132712 best avg 6.8@2430 epsilon 0.010135160129789437\n",
      "8910: avg rewards 2.0 std: 9.797958971132712 best avg 6.8@2430 epsilon 0.010133815264027549\n",
      "8920: avg rewards 2.8 std: 9.600000000000001 best avg 6.8@2430 epsilon 0.010132483779903575\n",
      "8930: avg rewards 1.6 std: 9.666436778875658 best avg 6.8@2430 epsilon 0.010131165544267996\n",
      "8940: avg rewards 2.0 std: 9.797958971132712 best avg 6.8@2430 epsilon 0.010129860425296148\n",
      "8950: avg rewards 0.4 std: 9.991996797437437 best avg 6.8@2430 epsilon 0.010128568292475049\n",
      "8960: avg rewards 0.8 std: 9.765244492586962 best avg 6.8@2430 epsilon 0.010127289016590336\n",
      "8970: avg rewards -0.4 std: 9.991996797437437 best avg 6.8@2430 epsilon 0.010126022469713357\n",
      "8980: avg rewards 4.4 std: 8.979977728257458 best avg 6.8@2430 epsilon 0.01012476852518837\n",
      "8990: avg rewards 0.8 std: 9.765244492586962 best avg 6.8@2430 epsilon 0.010123527057619873\n",
      "9000: avg rewards 3.6 std: 9.329523031752482 best avg 6.8@2430 epsilon 0.010122297942860079\n",
      "9010: avg rewards 2.0 std: 9.797958971132712 best avg 6.8@2430 epsilon 0.010121081057996487\n",
      "9020: avg rewards 2.0 std: 9.797958971132712 best avg 6.8@2430 epsilon 0.010119876281339596\n",
      "9030: avg rewards -1.2 std: 9.927738916792686 best avg 6.8@2430 epsilon 0.010118683492410735\n",
      "9040: avg rewards 4.4 std: 8.97997772825746 best avg 6.8@2430 epsilon 0.01011750257193002\n",
      "9050: avg rewards 1.2 std: 9.927738916792686 best avg 6.8@2430 epsilon 0.010116333401804414\n",
      "9060: avg rewards 2.0 std: 9.797958971132712 best avg 6.8@2430 epsilon 0.010115175865115936\n",
      "9070: avg rewards 6.4 std: 7.418894796396563 best avg 6.8@2430 epsilon 0.01011402984610995\n",
      "9080: avg rewards 4.4 std: 8.979977728257458 best avg 6.8@2430 epsilon 0.010112895230183598\n",
      "9090: avg rewards -1.2 std: 9.927738916792686 best avg 6.8@2430 epsilon 0.010111771903874345\n",
      "9100: avg rewards -1.2 std: 9.927738916792686 best avg 6.8@2430 epsilon 0.010110659754848624\n",
      "9110: avg rewards 4.4 std: 8.522910301065007 best avg 6.8@2430 epsilon 0.010109558671890603\n",
      "9120: avg rewards 2.0 std: 9.797958971132712 best avg 6.8@2430 epsilon 0.010108468544891072\n",
      "9130: avg rewards 0.4 std: 9.156418513807678 best avg 6.8@2430 epsilon 0.01010738926483642\n",
      "9140: avg rewards 2.0 std: 9.797958971132712 best avg 6.8@2430 epsilon 0.010106320723797742\n",
      "9150: avg rewards 1.2 std: 9.927738916792686 best avg 6.8@2430 epsilon 0.010105262814920047\n",
      "9160: avg rewards 1.2 std: 9.927738916792686 best avg 6.8@2430 epsilon 0.010104215432411561\n",
      "9170: avg rewards 2.8 std: 9.600000000000001 best avg 6.8@2430 epsilon 0.010103178471533164\n",
      "9180: avg rewards 0.8 std: 9.765244492586962 best avg 6.8@2430 epsilon 0.010102151828587902\n",
      "9190: avg rewards -1.2 std: 9.927738916792686 best avg 6.8@2430 epsilon 0.010101135400910627\n",
      "9200: avg rewards 3.6 std: 9.329523031752482 best avg 6.8@2430 epsilon 0.010100129086857722\n",
      "9210: avg rewards -2.0 std: 9.797958971132712 best avg 6.8@2430 epsilon 0.010099132785796943\n",
      "9220: avg rewards -0.8 std: 9.765244492586962 best avg 6.8@2430 epsilon 0.010098146398097354\n",
      "9230: avg rewards 4.4 std: 8.97997772825746 best avg 6.8@2430 epsilon 0.010097169825119367\n",
      "9240: avg rewards 2.0 std: 9.797958971132712 best avg 6.8@2430 epsilon 0.010096202969204864\n",
      "9250: avg rewards 3.2 std: 9.260669522232178 best avg 6.8@2430 epsilon 0.010095245733667452\n",
      "9260: avg rewards -1.2 std: 9.927738916792686 best avg 6.8@2430 epsilon 0.010094298022782779\n",
      "9270: avg rewards 0.4 std: 9.991996797437437 best avg 6.8@2430 epsilon 0.010093359741778964\n",
      "9280: avg rewards 2.0 std: 9.797958971132712 best avg 6.8@2430 epsilon 0.01009243079682713\n",
      "9290: avg rewards 3.6 std: 9.329523031752482 best avg 6.8@2430 epsilon 0.010091511095032002\n",
      "9300: avg rewards -0.4 std: 9.991996797437437 best avg 6.8@2430 epsilon 0.010090600544422639\n",
      "9310: avg rewards 1.2 std: 9.927738916792686 best avg 6.8@2430 epsilon 0.010089699053943217\n",
      "9320: avg rewards 1.2 std: 9.927738916792686 best avg 6.8@2430 epsilon 0.01008880653344394\n",
      "9330: avg rewards 2.0 std: 9.797958971132712 best avg 6.8@2430 epsilon 0.010087922893672012\n",
      "9340: avg rewards 4.8 std: 8.541662601625049 best avg 6.8@2430 epsilon 0.010087048046262722\n",
      "9350: avg rewards 4.4 std: 8.522910301065007 best avg 6.8@2430 epsilon 0.010086181903730599\n",
      "9360: avg rewards 4.0 std: 8.94427190999916 best avg 6.8@2430 epsilon 0.010085324379460666\n",
      "9370: avg rewards 3.6 std: 9.329523031752482 best avg 6.8@2430 epsilon 0.010084475387699783\n",
      "9380: avg rewards 2.8 std: 9.600000000000001 best avg 6.8@2430 epsilon 0.010083634843548066\n",
      "9390: avg rewards 3.2 std: 9.260669522232178 best avg 6.8@2430 epsilon 0.010082802662950401\n",
      "9400: avg rewards 2.8 std: 9.600000000000001 best avg 6.8@2430 epsilon 0.010081978762688033\n",
      "9410: avg rewards 5.2 std: 8.541662601625049 best avg 6.8@2430 epsilon 0.01008116306037025\n",
      "9420: avg rewards 2.8 std: 9.600000000000001 best avg 6.8@2430 epsilon 0.010080355474426138\n",
      "9430: avg rewards 2.8 std: 9.600000000000001 best avg 6.8@2430 epsilon 0.010079555924096434\n",
      "9440: avg rewards 1.2 std: 9.927738916792686 best avg 6.8@2430 epsilon 0.010078764329425437\n",
      "9450: avg rewards 3.2 std: 9.26066952223218 best avg 6.8@2430 epsilon 0.010077980611253017\n",
      "9460: avg rewards 6.0 std: 8.0 best avg 6.8@2430 epsilon 0.01007720469120671\n",
      "9470: avg rewards 0.4 std: 9.991996797437437 best avg 6.8@2430 epsilon 0.010076436491693859\n",
      "9480: avg rewards 1.2 std: 9.516301802696256 best avg 6.8@2430 epsilon 0.010075675935893874\n",
      "9490: avg rewards 0.4 std: 9.991996797437437 best avg 6.8@2430 epsilon 0.010074922947750543\n",
      "9500: avg rewards 4.4 std: 8.97997772825746 best avg 6.8@2430 epsilon 0.010074177451964423\n",
      "9510: avg rewards 2.8 std: 9.600000000000001 best avg 6.8@2430 epsilon 0.010073439373985313\n",
      "9520: avg rewards 1.6 std: 9.666436778875658 best avg 6.8@2430 epsilon 0.010072708640004802\n",
      "9530: avg rewards -0.4 std: 9.991996797437437 best avg 6.8@2430 epsilon 0.010071985176948883\n",
      "9540: avg rewards 3.6 std: 9.329523031752482 best avg 6.8@2430 epsilon 0.010071268912470645\n",
      "9550: avg rewards 2.8 std: 9.600000000000001 best avg 6.8@2430 epsilon 0.010070559774943047\n",
      "9560: avg rewards 4.4 std: 8.97997772825746 best avg 6.8@2430 epsilon 0.010069857693451742\n",
      "9570: avg rewards 2.8 std: 9.600000000000001 best avg 6.8@2430 epsilon 0.010069162597787997\n",
      "9580: avg rewards 0.8 std: 9.765244492586962 best avg 6.8@2430 epsilon 0.010068474418441668\n",
      "9590: avg rewards 2.8 std: 9.600000000000001 best avg 6.8@2430 epsilon 0.010067793086594244\n",
      "9600: avg rewards 3.6 std: 9.329523031752482 best avg 6.8@2430 epsilon 0.010067118534111973\n",
      "9610: avg rewards 4.4 std: 8.97997772825746 best avg 6.8@2430 epsilon 0.010066450693539048\n",
      "9620: avg rewards 3.6 std: 9.329523031752482 best avg 6.8@2430 epsilon 0.010065789498090852\n",
      "9630: avg rewards 1.2 std: 9.927738916792686 best avg 6.8@2430 epsilon 0.010065134881647288\n",
      "9640: avg rewards 4.4 std: 8.97997772825746 best avg 6.8@2430 epsilon 0.01006448677874617\n",
      "9650: avg rewards 5.2 std: 8.541662601625049 best avg 6.8@2430 epsilon 0.010063845124576665\n",
      "9660: avg rewards 3.6 std: 9.329523031752482 best avg 6.8@2430 epsilon 0.010063209854972822\n",
      "9670: avg rewards 2.0 std: 9.797958971132712 best avg 6.8@2430 epsilon 0.01006258090640715\n",
      "9680: avg rewards 0.4 std: 9.991996797437437 best avg 6.8@2430 epsilon 0.010061958215984271\n",
      "9690: avg rewards 3.6 std: 9.329523031752482 best avg 6.8@2430 epsilon 0.010061341721434624\n",
      "9700: avg rewards -0.4 std: 9.991996797437437 best avg 6.8@2430 epsilon 0.010060731361108237\n",
      "9710: avg rewards 0.0 std: 9.797958971132712 best avg 6.8@2430 epsilon 0.010060127073968571\n",
      "9720: avg rewards 2.8 std: 9.173875952943774 best avg 6.8@2430 epsilon 0.010059528799586407\n",
      "9730: avg rewards 3.6 std: 9.329523031752482 best avg 6.8@2430 epsilon 0.01005893647813381\n",
      "9740: avg rewards 5.6 std: 8.039900496896712 best avg 6.8@2430 epsilon 0.01005835005037814\n",
      "9750: avg rewards -1.2 std: 9.927738916792686 best avg 6.8@2430 epsilon 0.010057769457676134\n",
      "9760: avg rewards 5.2 std: 8.541662601625049 best avg 6.8@2430 epsilon 0.010057194641968036\n",
      "9770: avg rewards 4.4 std: 8.97997772825746 best avg 6.8@2430 epsilon 0.010056625545771797\n",
      "9780: avg rewards 1.2 std: 9.927738916792686 best avg 6.8@2430 epsilon 0.010056062112177324\n",
      "9790: avg rewards 2.8 std: 9.600000000000001 best avg 6.8@2430 epsilon 0.010055504284840786\n",
      "9800: avg rewards 4.4 std: 8.97997772825746 best avg 6.8@2430 epsilon 0.010054952007978986\n",
      "9810: avg rewards 1.2 std: 9.927738916792684 best avg 6.8@2430 epsilon 0.010054405226363779\n",
      "9820: avg rewards 0.4 std: 9.991996797437437 best avg 6.8@2430 epsilon 0.010053863885316545\n",
      "9830: avg rewards 2.8 std: 9.173875952943773 best avg 6.8@2430 epsilon 0.01005332793070273\n",
      "9840: avg rewards 3.6 std: 9.329523031752482 best avg 6.8@2430 epsilon 0.010052797308926425\n",
      "9850: avg rewards 0.8 std: 9.765244492586962 best avg 6.8@2430 epsilon 0.01005227196692501\n",
      "9860: avg rewards 3.6 std: 9.329523031752482 best avg 6.8@2430 epsilon 0.010051751852163848\n",
      "9870: avg rewards 2.4 std: 9.499473669630335 best avg 6.8@2430 epsilon 0.01005123691263103\n",
      "9880: avg rewards -0.4 std: 9.991996797437437 best avg 6.8@2430 epsilon 0.010050727096832171\n",
      "9890: avg rewards -2.0 std: 9.797958971132712 best avg 6.8@2430 epsilon 0.01005022235378527\n",
      "9900: avg rewards 4.4 std: 8.97997772825746 best avg 6.8@2430 epsilon 0.010049722633015599\n",
      "9910: avg rewards 2.0 std: 9.797958971132712 best avg 6.8@2430 epsilon 0.010049227884550663\n",
      "9920: avg rewards 2.0 std: 9.797958971132712 best avg 6.8@2430 epsilon 0.010048738058915208\n",
      "9930: avg rewards 5.2 std: 8.541662601625049 best avg 6.8@2430 epsilon 0.01004825310712626\n",
      "9940: avg rewards 3.6 std: 9.329523031752482 best avg 6.8@2430 epsilon 0.010047772980688234\n",
      "9950: avg rewards 4.4 std: 8.97997772825746 best avg 6.8@2430 epsilon 0.010047297631588088\n",
      "9960: avg rewards 0.8 std: 9.765244492586962 best avg 6.8@2430 epsilon 0.010046827012290515\n",
      "9970: avg rewards 0.0 std: 9.797958971132712 best avg 6.8@2430 epsilon 0.010046361075733194\n",
      "9980: avg rewards 1.6 std: 9.666436778875658 best avg 6.8@2430 epsilon 0.010045899775322083\n",
      "9990: avg rewards 1.2 std: 9.927738916792686 best avg 6.8@2430 epsilon 0.01004544306492675\n"
     ]
    }
   ],
   "source": [
    "seed = 1337\n",
    "# Create a grid of learning rates and gammas\n",
    "learning_rates = [0.0001]\n",
    "gammas = [0.99]\n",
    "\n",
    "results = {}\n",
    "for lr in learning_rates:\n",
    "  results[lr] = {}\n",
    "  for gamma in gammas:\n",
    "    seed = seed + 1\n",
    "    reward_per_episode = train(env, gamma, lr, max_steps=MAX_STEPS, seed=seed, use_td_target=False)\n",
    "    results[lr][gamma] = reward_per_episode\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Summarize rewards per episode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr: 0.0001 gamma: 0.99 rewards: [-1.2, -0.4, -1.2, -2.0, -2.0, 2.8, -2.0, -0.4, 0.4, 2.0, -2.8, -3.6, -1.2, -0.4, -0.4, -2.0, -3.6, -3.6, -0.4, -3.6, -0.4, -6.0, -2.8, -0.4, -2.8, 0.4, -2.0, -5.2, 0.4, -5.2, -1.2, 1.2, -3.6, -3.6, -5.2, 0.4, -2.8, -3.6, -4.4, 1.2, -2.0, -2.0, -2.0, -0.4, -2.0, -6.0, -3.6, -2.8, 0.4, -4.4, -1.2, -4.4, -3.6, -3.6, -3.6, -3.6, 2.0, 1.6, -0.8, -0.4, 2.0, -2.4, -2.0, 2.0, 0.4, -1.6, -2.8, -4.4, -0.4, 0.8, 1.2, 0.4, -2.8, 0.8, -1.2, -0.8, 2.4, -0.8, 3.2, -2.8, -2.8, -1.2, 0.4, 4.4, 1.6, 1.6, -0.4, -1.2, 0.0, -4.4, -0.4, -1.2, -3.2, 0.4, -2.8, -2.0, -2.0, 0.4, -0.4, -1.2, 3.2, -1.2, 1.2, 1.2, -2.8, 1.2, 1.2, -4.4, -1.2, -2.4, -1.6, 0.4, -1.2, 2.8, 0.0, -0.4, 2.8, -1.2, -2.8, 2.8, 2.0, 3.6, -2.8, -2.8, 1.2, 0.4, 2.0, 2.4, 3.2, 1.2, 2.8, 1.2, 2.0, 0.4, -1.2, -0.4, -1.2, -1.2, -0.4, 2.0, -3.6, 2.0, 2.0, -0.4, -1.2, -3.2, -2.8, -0.4, -0.4, -2.0, 1.2, -1.2, 2.8, 2.0, 0.4, -3.6, 2.0, 0.4, 1.6, 0.4, 0.4, -2.0, -1.2, 1.6, 2.0, 1.2, -0.4, 3.6, 1.2, 0.4, -0.4, -1.2, 2.8, 2.0, 2.8, 2.0, 2.0, 3.6, -0.4, 4.8, 2.8, 1.2, 2.8, 3.2, 0.4, 1.2, -2.8, 2.8, -1.2, -2.0, -0.4, -2.0, 4.4, -1.2, 1.2, -0.4, 0.4, -1.2, 1.2, 1.2, 2.0, 2.0, 5.2, 1.2, 1.2, 2.0, -1.2, 0.4, -0.4, 0.4, -0.4, 1.2, 2.8, -2.0, -0.4, 2.8, 1.2, -0.4, 0.4, -2.8, 2.8, 4.8, 2.8, 2.0, 0.4, -0.4, 2.0, -0.4, 0.4, -2.0, 0.4, -1.2, -0.4, 0.4, -0.4, 2.0, 2.0, 0.4, -6.0, 3.6, 0.0, -0.4, -1.2, 6.8, -2.8, -1.2, -2.0, -2.0, 2.0, -0.4, 4.4, -0.4, 2.0, -2.0, -0.4, 2.8, 2.0, 0.4, -0.4, 0.4, -0.4, -0.4, 1.2, 0.4, -1.2, 2.0, 0.4, 0.0, 2.0, -4.4, -2.0, 2.0, 2.0, -3.6, 5.2, 2.8, 0.4, 0.4, 0.4, 3.2, 0.4, 2.8, -2.0, 0.4, -2.8, 1.2, 2.0, 2.0, 4.4, -2.0, 2.0, 2.8, 0.4, 1.2, -2.0, -2.0, 2.8, 1.2, -2.0, -4.4, -1.2, 1.2, -0.4, -0.4, 1.2, 2.0, 2.0, -4.4, -2.8, -0.4, -1.2, 0.0, 2.0, 2.8, -1.2, -3.6, -2.8, -1.2, 0.4, 3.6, -0.4, 0.4, -1.2, 0.4, 2.8, -2.0, 2.0, -1.2, -0.4, -0.4, -0.4, 1.2, -0.4, 0.4, 0.4, 1.2, 0.4, -2.8, 0.4, 0.4, -0.4, 0.4, 2.8, -0.4, -0.4, -2.0, -0.4, -1.2, -2.0, -1.2, -2.0, -2.8, -1.2, -2.8, -1.2, 1.2, 0.4, 2.0, -1.2, -2.8, 0.4, 1.2, -1.2, -0.4, 0.4, -3.6, 2.8, -0.4, -2.0, 1.2, -2.4, 1.2, 0.4, 1.2, 2.0, 0.4, 2.0, -1.2, 2.8, -0.4, 2.0, -2.0, 0.4, -4.4, 4.4, 0.4, 1.2, -2.0, -1.2, -0.4, 1.2, -1.2, 2.0, -1.2, -0.8, 1.2, -2.0, 5.2, -1.2, 0.4, 2.0, -2.8, 2.8, 2.0, -2.8, 1.2, 1.2, 0.4, -3.6, 1.2, 2.8, -1.6, -3.6, -1.2, -0.4, -0.4, 2.8, 0.4, -0.4, -3.6, 5.2, -1.2, 1.2, -0.4, -0.4, 0.4, 1.2, -1.2, -0.4, 0.4, -0.4, -0.4, 2.0, -0.4, 1.2, -4.4, 1.2, -2.0, 0.4, -2.8, -2.0, 2.0, -2.8, 0.8, 2.8, -0.4, -1.2, -3.6, -3.6, 0.4, 2.8, 1.6, 2.0, 0.4, -2.8, -1.2, -2.0, -1.2, -1.2, 2.4, 1.2, -2.0, 4.4, -2.0, 0.4, 6.8, 3.6, 3.6, -0.4, -0.4, 2.0, 0.8, -1.2, -0.4, -1.6, -2.0, 0.8, 2.8, 0.4, 2.8, -0.4, 1.2, -0.4, -1.2, -0.4, 2.0, 1.2, 3.6, 5.2, 0.4, -0.4, 1.2, 5.2, -0.4, 0.4, -0.8, -0.4, 2.0, -4.4, -0.4, -2.0, -3.6, -1.2, -1.2, 2.8, 1.2, -0.4, 2.8, -1.2, 0.4, 1.2, -2.4, 2.8, 1.2, 4.4, 1.2, -0.4, 3.6, -0.4, 1.2, -3.2, 1.6, -1.2, -2.0, -4.0, -1.2, 1.2, 0.4, 2.0, -0.4, 1.2, -0.4, 3.6, 0.0, 1.6, -1.2, 1.2, 0.4, 1.6, 3.6, -4.4, 2.8, 4.4, -0.8, 1.2, 2.0, -2.4, -2.8, -1.2, 2.0, -2.0, 1.2, -2.0, 3.2, 6.0, 1.2, 1.2, -0.4, 0.4, 6.0, 2.8, -1.2, -3.6, 0.4, -2.0, 0.8, -1.2, -2.0, 2.4, -3.6, -1.6, -3.6, 2.8, 1.2, 1.2, 0.4, -2.8, 4.0, 1.2, -2.4, 1.2, 2.8, 3.2, 2.8, 2.0, -1.6, 1.2, 3.2, 2.8, -2.4, 1.2, 2.8, 2.0, -0.4, -1.2, -0.4, -2.8, -2.0, 3.6, 2.0, 0.4, -1.2, -1.2, 0.0, 0.4, 1.6, -3.6, -2.8, 0.8, -2.4, -0.4, 4.4, 4.0, 2.0, -2.4, -1.2, -4.0, -1.6, 0.8, 0.0, 3.6, 0.4, -1.6, 2.4, 1.2, -1.2, -1.6, -1.6, -2.8, 2.0, 0.4, 2.8, -1.2, 1.6, -1.6, 0.4, 2.0, 2.4, 0.8, 3.6, 2.0, 3.2, -1.6, -1.2, -1.2, 2.8, 1.2, 0.0, -2.8, 2.8, 0.0, 0.8, 2.0, 6.0, 2.0, 2.4, 2.4, 5.2, -1.2, 2.4, 1.2, 3.6, 0.8, 4.0, 1.2, -0.4, 4.4, 2.0, 3.2, 1.2, 5.2, -0.4, 2.8, 3.6, 3.2, 2.4, 0.0, 1.6, -1.2, 2.0, 1.2, 4.4, 3.6, 6.0, 0.8, 2.4, 1.6, 0.4, 1.2, 2.4, 2.0, 2.8, 1.2, 1.6, -1.2, 2.0, 2.0, 3.6, 2.0, 1.6, 1.2, -0.4, -1.2, 5.2, 3.6, 3.6, 1.6, 0.4, 0.4, 0.4, 2.8, 1.2, 5.2, 6.0, 1.2, 2.0, 0.8, 1.2, 3.6, -0.8, 1.6, 3.6, 1.6, 1.2, 3.2, 2.8, 1.6, 4.8, -0.8, -0.4, 2.4, 2.0, 4.4, -1.2, 2.0, 2.0, 3.6, 2.8, 0.4, 4.0, 4.4, 2.0, 0.4, -0.4, 2.4, 2.0, 2.8, 4.8, 3.6, 0.4, 3.6, 1.2, 3.2, -0.4, 0.4, 0.4, 2.0, 0.4, -2.0, 4.0, 2.4, 1.2, 4.0, 4.4, -0.4, 0.4, 4.0, 3.6, 3.6, 0.4, 4.4, 2.8, 0.4, 6.0, 2.8, 3.6, 0.8, 4.8, 6.0, 3.6, 4.0, 2.0, 4.4, 1.6, 2.8, 3.6, 1.2, 6.8, 2.8, 4.4, 2.8, 4.4, 3.6, 3.6, 0.0, 4.0, 2.8, -0.4, 1.6, 3.6, 6.0, 4.0, -0.4, 6.8, 5.2, 1.6, 4.0, 0.4, 3.6, 2.4, -1.2, 2.0, 2.8, 4.0, 1.2, 2.0, 1.6, 2.8, -1.2, 0.8, 1.2, 1.6, 2.0, 6.0, 2.8, 0.8, 0.4, 4.4, 0.4, 2.0, 6.8, 2.4, 4.4, 3.6, 1.2, -0.4, -2.8, 0.4, 4.4, 2.0, 1.2, 2.8, -0.4, 1.2, 1.2, -0.4, 3.6, 3.2, 2.8, 2.0, -1.2, 3.6, 3.6, 4.0, 2.8, -2.8, 2.0, 2.0, 2.8, 3.6, 2.4, 4.4, 3.2, 3.2, 2.4, 3.2, 2.0, 1.2, 2.8, -2.0, 2.0, 0.4, -4.4, 0.0, 0.8, 2.8, 1.2, 4.4, 2.4, 2.8, 1.6, 2.0, 5.2, 2.8, 6.4, 2.4, 1.2, 0.8, 4.4, 6.0, 2.0, 2.0, 2.8, 1.6, 2.0, 0.4, 0.8, -0.4, 4.4, 0.8, 3.6, 2.0, 2.0, -1.2, 4.4, 1.2, 2.0, 6.4, 4.4, -1.2, -1.2, 4.4, 2.0, 0.4, 2.0, 1.2, 1.2, 2.8, 0.8, -1.2, 3.6, -2.0, -0.8, 4.4, 2.0, 3.2, -1.2, 0.4, 2.0, 3.6, -0.4, 1.2, 1.2, 2.0, 4.8, 4.4, 4.0, 3.6, 2.8, 3.2, 2.8, 5.2, 2.8, 2.8, 1.2, 3.2, 6.0, 0.4, 1.2, 0.4, 4.4, 2.8, 1.6, -0.4, 3.6, 2.8, 4.4, 2.8, 0.8, 2.8, 3.6, 4.4, 3.6, 1.2, 4.4, 5.2, 3.6, 2.0, 0.4, 3.6, -0.4, 0.0, 2.8, 3.6, 5.6, -1.2, 5.2, 4.4, 1.2, 2.8, 4.4, 1.2, 0.4, 2.8, 3.6, 0.8, 3.6, 2.4, -0.4, -2.0, 4.4, 2.0, 2.0, 5.2, 3.6, 4.4, 0.8, 0.0, 1.6, 1.2]\n"
     ]
    }
   ],
   "source": [
    "for item in results:\n",
    "  for gamma in results[item]:\n",
    "    print(f\"lr: {item} gamma: {gamma} rewards: {results[item][gamma]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot the results\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "for lr in learning_rates:\n",
    "    for gamma in gammas:\n",
    "        plt.plot(results[lr][gamma], label=f\"lr={lr}, gamma={gamma}\")\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = make_env(game_setup_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training with gamma 0.99 and learning rate 0.001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jedld/.local/lib/python3.10/site-packages/gymnasium/core.py:311: UserWarning: \u001b[33mWARN: env.seed to get variables from other wrappers is deprecated and will be removed in v1.0, to get this variable you can do `env.unwrapped.seed` for environment variables or `env.get_wrapper_attr('seed')` that will search the reminding wrappers.\u001b[0m\n",
      "  logger.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d5ab5250b90b489fb91d1d9bff4ac87b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jedld/.local/lib/python3.10/site-packages/torch/autograd/graph.py:744: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0: avg rewards -3.6 std: 9.329523031752482 best avg -10@0 temperature 5.0\n",
      "best: -3.6\n",
      "10: avg rewards -10.0 std: 0.0 best avg -3.6@0 temperature 4.950224401048741\n",
      "20: avg rewards -10.0 std: 0.0 best avg -3.6@0 temperature 4.900944324147673\n",
      "30: avg rewards -9.2 std: 3.919183588453085 best avg -3.6@0 temperature 4.852154836315428\n",
      "40: avg rewards -10.0 std: 0.0 best avg -3.6@0 temperature 4.803851053679058\n",
      "50: avg rewards -10.0 std: 0.0 best avg -3.6@0 temperature 4.756028140985157\n",
      "60: avg rewards -10.0 std: 0.0 best avg -3.6@0 temperature 4.70868131111584\n",
      "70: avg rewards -10.0 std: 0.0 best avg -3.6@0 temperature 4.661805824609562\n",
      "80: avg rewards -10.0 std: 0.0 best avg -3.6@0 temperature 4.61539698918668\n",
      "90: avg rewards -10.0 std: 0.0 best avg -3.6@0 temperature 4.569450159279758\n",
      "100: avg rewards -10.0 std: 0.0 best avg -3.6@0 temperature 4.523960735568544\n",
      "110: avg rewards -3.6 std: 9.329523031752482 best avg -3.6@0 temperature 4.478924164519563\n",
      "120: avg rewards -7.6 std: 6.499230723708769 best avg -3.6@0 temperature 4.434335937930317\n",
      "130: avg rewards -2.0 std: 9.797958971132712 best avg -3.6@0 temperature 4.390191592478003\n",
      "best: -2.0\n"
     ]
    }
   ],
   "source": [
    "seed = 1337\n",
    "# Create a grid of learning rates and gammas\n",
    "learning_rates = [0.001]\n",
    "gammas = [0.99]\n",
    "\n",
    "results = {}\n",
    "for lr in learning_rates:\n",
    "  results[lr] = {}\n",
    "  for gamma in gammas:\n",
    "    seed = seed + 1\n",
    "    reward_per_episode = train(env, gamma, lr, max_steps=MAX_STEPS, seed=seed, trajectory_policy='boltzmann', label=\"boltzmann\")\n",
    "    results[lr][gamma] = reward_per_episode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for item in results:\n",
    "  for gamma in results[item]:\n",
    "    print(f\"lr: {item} gamma: {gamma} rewards: {results[item][gamma]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the results\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "for lr in learning_rates:\n",
    "    for gamma in gammas:\n",
    "        plt.plot(results[lr][gamma], label=f\"lr={lr}, gamma={gamma}\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perform some tests on the trained agent. Show a combat log from a fight against the rules based AI. Define a policy based on the Model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "MAX_STEPS = 500\n",
    "NUM_EPISODES = 100\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "class ModelPolicy:\n",
    "    def __init__(self, weights_file = 'model_best_boltzmann.pt'):\n",
    "        self.model = QNetwork(device=device)\n",
    "        self.model.to(device)\n",
    "        if not os.path.exists(weights_file):\n",
    "            raise FileNotFoundError(f\"Model file {weights_file} not found. Please run dnd_dqn.ipynb notebook to train an agent.\")\n",
    "        self.model.load_state_dict(torch.load(weights_file))\n",
    "\n",
    "    def action(self, state, info):\n",
    "        available_moves = info[\"available_moves\"]\n",
    "        values = torch.stack([self.model(state, move) for move in available_moves])\n",
    "        for index, v in enumerate(values):\n",
    "            print(f\"{index}: {available_moves[index]} {v.item()}\")\n",
    "\n",
    "        chosen_index = torch.argmax(values).item()\n",
    "        return available_moves[chosen_index]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "env = make_env(game_setup_path)\n",
    "\n",
    "print(\"=========================================\")\n",
    "print(\"Battle between an RL agent vs a Rules based AI\")\n",
    "print(\"=========================================\")\n",
    "win_count = 0\n",
    "loss_count = 0\n",
    "for i in range(NUM_EPISODES):\n",
    "    observation, info = env.reset()\n",
    "    model = ModelPolicy()\n",
    "    action = action = model.action(observation, info)\n",
    "\n",
    "    print(f\"selected action: {action}\")\n",
    "    terminal = False\n",
    "    episode = 0\n",
    "\n",
    "    while not terminal and episode < MAX_STEPS:\n",
    "        episode += 1\n",
    "        observation, reward, terminal, truncated, info = env.step(action)\n",
    "        print(env.render())\n",
    "        if not terminal and not truncated:\n",
    "            episode_name_with_padding = str(episode).zfill(3)\n",
    "\n",
    "            # display entity healths\n",
    "            print(f\"Turn {info['current_index']}\\n\")\n",
    "            print(f\"Reward: {reward}\\n\")\n",
    "            print(f\"health hero: {observation['health_pct']}\\n\")\n",
    "            print(f\"health enemy: {observation['health_enemy']}\\n\")\n",
    "            print(env.render())\n",
    "            \n",
    "            action = model.action(observation, info)\n",
    "            print(f\"agent selected action: {action}\")\n",
    "\n",
    "        if terminal or truncated:\n",
    "            print(f\"Reward: {reward}\")\n",
    "            if reward > 0:\n",
    "                win_count += 1\n",
    "            else:\n",
    "                loss_count += 1\n",
    "            break\n",
    "        \n",
    "print(f\"Win count: {win_count} Loss count: {loss_count} Win rate: {win_count/(win_count+loss_count)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
