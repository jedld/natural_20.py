{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from natural20.session import Session\n",
    "from natural20.gym.dndenv import dndenv, action_type_to_int\n",
    "from gymnasium import register, envs, make\n",
    "from natural20.gym.llm_helpers.prompting_utils import action_to_prompt\n",
    "from natural20.gym.dndenv import embedding_loader\n",
    "from natural20.event_manager import EventManager\n",
    "from natural20.gym.dqn.policy import ModelPolicy\n",
    "from llm_interface import GPT4Interfacer, OllamaInterfacer\n",
    "import torch\n",
    "import random\n",
    "import os\n",
    "import numpy as np\n",
    "from tqdm.autonotebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "ROUND_PER_MATCH = 30\n",
    "# setup VLLM endpoints\n",
    "LLAMA3_URL = \"http://localhost:8001/v1\"\n",
    "MISTRAL_URL = \"http://localhost:8000/v1\"\n",
    "GPT4_TOKEN = \"OPENAI_GPT_TOKEN_HERE\"\n",
    "WEIGHTS_FOLDER = \"model_weights_all\"\n",
    "HORIZON_LENGTH = 512\n",
    "ENABLE_LOGS = True\n",
    "OUTPUTFOLDER = \"output\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "event_manager = EventManager()\n",
    "event_manager.standard_cli()\n",
    "session = Session(root_path=\"map_with_obstacles\", event_manager=event_manager)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Agent:\n",
    "    def action(self, observation, info):\n",
    "        return random.choice(info['available_moves'])\n",
    "\n",
    "class CustomAgent(Agent):\n",
    "    def __init__(self, llm_interface):\n",
    "        self.llm_interface = llm_interface\n",
    "\n",
    "    def action(self, observation, info):\n",
    "        return self.llm_interface.select_action_for_state(observation, info)\n",
    "    def __str__(self) -> str:\n",
    "        return \"Custom LLM Agent\"\n",
    "\n",
    "class ModelAgent(Agent):\n",
    "    def __init__(self, model_policy):\n",
    "        self.model_policy = model_policy\n",
    "\n",
    "    def action(self, observation, info):\n",
    "        return self.model_policy.action(observation, info)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setup the appropriate URLs to your vLLM instances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def prompt_for_variant(variant):\n",
    "#     if variant == \"llama3\":\n",
    "#         prompt = GPT4Interfacer(debug=False, tools=False, base_url=LLAMA3_URL, api_key=\"token1234\", variant='NousResearch/Meta-Llama-3.1-8B-Instruct')\n",
    "#     elif variant == \"gpt4\":\n",
    "#         prompt = GPT4Interfacer(debug=False, tools=True, api_key=GPT4_TOKEN, variant='gpt-4o-mini')\n",
    "#     elif variant == \"mistral\":\n",
    "#         prompt = GPT4Interfacer(debug=False, tools=False, base_url=MISTRAL_URL, api_key=\"token1234\", variant='mistralai/Mistral-7B-Instruct-v0.3')\n",
    "#     else:\n",
    "#         raise ValueError(f\"Invalid variant: {variant}\")\n",
    "\n",
    "#     return prompt\n",
    "\n",
    "def prompt_for_variant(variant):\n",
    "    if variant == \"llama3\":\n",
    "        prompt = OllamaInterfacer(model=\"llama3.2:latest\")\n",
    "    elif variant == \"gpt4\":\n",
    "        prompt = OllamaInterfacer(debug=False, tools=True, api_key=GPT4_TOKEN, variant='gpt-4o-mini')\n",
    "    elif variant == \"mistral\":\n",
    "        prompt = OllamaInterfacer(base_url=\"http://ubuntu.local:11434\", model=\"mistral:7b\")\n",
    "    elif variant == \"deepseek\":\n",
    "        prompt = OllamaInterfacer(model=\"deepseek-r1:7b\")\n",
    "    else:\n",
    "        raise ValueError(f\"Invalid variant: {variant}\")\n",
    "\n",
    "    return prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def increment_result_by_class(type, info, wins_or_loss_by_class=None):\n",
    "    for p in info[type]:\n",
    "        if p.class_descriptor() not in wins_or_loss_by_class:\n",
    "            wins_or_loss_by_class[p.class_descriptor()] = 0\n",
    "        wins_or_loss_by_class[p.class_descriptor()] += 1\n",
    "\n",
    "\n",
    "def start_game(player=\"rl_rules_trained\", adversary=\"llm_llama3\", output_file=None):\n",
    "    player_agent = None\n",
    "    if player == \"rl_rules_trained\":\n",
    "        model = ModelPolicy(session, weights_file=f\"model_best_dnd_egreedy.pt\", device=device, debug=False)\n",
    "        player_agent = ModelAgent(model)\n",
    "    elif player == \"rl_llama3_trained\":\n",
    "        model = ModelPolicy(session, weights_file=f\"{WEIGHTS_FOLDER}/model_best_llm_adversary.pt\", device=device, debug=False)\n",
    "        player_agent = ModelAgent(model)\n",
    "    elif player == \"rl_mistral_trained\":\n",
    "        model = ModelPolicy(session, weights_file=f\"{WEIGHTS_FOLDER}/model_best_llm_adversary_mistral.pt\", device=device, debug=False)\n",
    "        player_agent = ModelAgent(model)\n",
    "    elif player == \"rl_gpt4_trained\":\n",
    "        model = ModelPolicy(session, weights_file=f\"{WEIGHTS_FOLDER}/model_best_llm_adversary_gpt4.pt\", device=device, debug=False)\n",
    "        player_agent = ModelAgent(model)\n",
    "    elif player.startswith(\"llm\"):\n",
    "        prompt = prompt_for_variant(player.split(\"_\")[1])\n",
    "        player_agent = CustomAgent(prompt)\n",
    "    elif player == \"random\":\n",
    "        player_agent = Agent()\n",
    "    else:\n",
    "        raise ValueError(f\"Invalid player: {player}\")\n",
    "\n",
    "    # Setup Adversary\n",
    "    if adversary == \"rl_rules_trained\":\n",
    "        model = ModelPolicy(session, weights_file=f\"model_best_dnd_egreedy.pt\", device=device, debug=False)\n",
    "        adversary_agent = ModelAgent(model)\n",
    "    elif adversary == \"rl_llama3_trained\":\n",
    "        model = ModelPolicy(session, weights_file=f\"{WEIGHTS_FOLDER}/model_best_llm_adversary.pt\", device=device, debug=False)\n",
    "        adversary_agent = ModelAgent(model)\n",
    "    elif adversary == \"rl_mistral_trained\":\n",
    "        model = ModelPolicy(session, weights_file=f\"{WEIGHTS_FOLDER}/model_best_llm_adversary_mistral.pt\", device=device, debug=False)\n",
    "        adversary_agent = ModelAgent(model)\n",
    "    elif adversary == \"rl_gpt4_trained\":\n",
    "        model = ModelPolicy(session, weights_file=f\"{WEIGHTS_FOLDER}/model_best_llm_adversary_gpt4.pt\", device=device, debug=False)\n",
    "        adversary_agent = ModelAgent(model)\n",
    "    elif adversary.startswith(\"llm\"):\n",
    "        prompt = prompt_for_variant(adversary.split(\"_\")[1])\n",
    "        adversary_agent = CustomAgent(prompt)\n",
    "    elif adversary == \"ai\":\n",
    "        adversary_agent = None\n",
    "    elif adversary == \"random\":\n",
    "        adversary_agent = Agent()\n",
    "    else:\n",
    "        raise ValueError(f\"Invalid adversary: {adversary}\")\n",
    "\n",
    "    def reaction_callback(state, reward, done, truncated, info):\n",
    "        \"\"\"\n",
    "        Callback function to be called when the environment is waiting for a reaction from the agent.\n",
    "        Reactions in DnD are typically reactions to enemy actions, such as opportunity attacks.\n",
    "        \"\"\"\n",
    "        print(f\"{info['reactor']}: Reaction for {info['trigger']}:\")\n",
    "        action = player_agent.action(state, info)\n",
    "        return action\n",
    "\n",
    "    env = make(\"dndenv-v0\", root_path=\"map_with_obstacles\",\n",
    "           render_mode=\"ansi\",\n",
    "           custom_agent=adversary_agent,\n",
    "           show_logs=ENABLE_LOGS,\n",
    "           hero_names=[f\"player_{player}\"],\n",
    "           enemy_names=[f\"player_{adversary}\"],\n",
    "           profiles=lambda: random.choice(['high_elf_fighter','halfling_rogue','high_elf_mage','dwarf_cleric']),\n",
    "            enemies=lambda: random.choice(['high_elf_fighter','halfling_rogue','high_elf_mage','dwarf_cleric']),\n",
    "            map_file=lambda: random.choice(['maps/simple_map',\\\n",
    "                                            'maps/complex_map', \\\n",
    "                                            'maps/game_map', \\\n",
    "                                            'maps/walled_map']),\n",
    "           debug=False)\n",
    "    wins = 0\n",
    "    losses = 0\n",
    "    ties = 0\n",
    "    errors = 0\n",
    "\n",
    "    total_rounds = []\n",
    "    wins_by_class = {}\n",
    "    loss_by_class = {}\n",
    "\n",
    "    foldername = os.path.join(OUTPUTFOLDER, f\"{player}_{adversary}\")\n",
    "    os.makedirs(foldername, exist_ok=True)\n",
    "    with open(os.path.join(foldername, \"000_summary.txt\"), \"w\") as f:\n",
    "        f.write(f\"Player: {player}\\n\")\n",
    "        f.write(f\"Adversary: {adversary}\\n\")\n",
    "\n",
    "        for round in tqdm(range(ROUND_PER_MATCH), leave=False):\n",
    "            try:\n",
    "                print(f\"Round {round + 1}\")\n",
    "                outputfile = os.path.join(foldername, f\"round_{round + 1}.txt\")\n",
    "                observation, info = env.reset(reaction_callback=reaction_callback, output_file=outputfile)\n",
    "                last_info = info\n",
    "                action = player_agent.action(observation, info)\n",
    "                terminal = False\n",
    "                steps = 0\n",
    "                result = None\n",
    "                while not terminal and steps < HORIZON_LENGTH:\n",
    "                    steps += 1\n",
    "                    observation, reward, terminal, truncated, info = env.step(action)\n",
    "                    last_info = info\n",
    "                    if not terminal and not truncated:\n",
    "                        action = player_agent.action(observation, info)\n",
    "\n",
    "                    if terminal or truncated:\n",
    "                        print(f\"Reward: {reward}\")\n",
    "                        if reward == 10:\n",
    "                            result = \"1.0-0.0\"\n",
    "                            wins += 1\n",
    "                            increment_result_by_class('players', info, wins_by_class)\n",
    "                            increment_result_by_class('enemies', info, loss_by_class)\n",
    "                        elif reward == -10:\n",
    "                            result = \"0.0-1.0\"\n",
    "                            losses += 1\n",
    "                            increment_result_by_class('players', info, loss_by_class)\n",
    "                            increment_result_by_class('enemies', info, wins_by_class)\n",
    "                        else:\n",
    "                            result = \"0.5-0.5\"\n",
    "                            ties += 1\n",
    "                        break\n",
    "\n",
    "                total_rounds.append(info['round'])\n",
    "                f.write(f\"Round {round + 1}: {info['round']},{result},{result}\\n\")\n",
    "            except Exception as e:\n",
    "                f.write(f\"Round {round + 1}: Error {e}\\n\")\n",
    "                print(f\"Error: {e}\")\n",
    "                errors += 1\n",
    "                continue\n",
    "            f.flush()\n",
    "        f.write(\"\\n\")\n",
    "        f.write(f\"Wins: {wins}, Losses: {losses}, Ties: {ties}\\n\")\n",
    "        f.write(f\"Errors: {errors}\\n\")\n",
    "        f.write(f\"Total Rounds: {np.mean(total_rounds)}\\n\")\n",
    "    print(f\"Wins: {wins}, Losses: {losses}, Ties: {ties}\")\n",
    "\n",
    "\n",
    "\n",
    "    return wins, losses, ties, np.mean(total_rounds), wins_by_class, loss_by_class, errors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a match grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "match_grid = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setup pairings for the tournament"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup available players and adversaries, note that duplicate pairings are automatically removed\n",
    "\n",
    "players = [\"random\", \"llm_mistral\", \"llm_llama3\",\"rl_rules_trained\",\"llm_deepseek\"]\n",
    "adversaries = [\"random\", \"llm_mistral\", \"llm_llama3\", \"ai\", \"rl_rules_trained\",\"llm_deepseek\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_grid = {}\n",
    "match_paring = []\n",
    "\n",
    "# create a cartesian product of all players and adversaries\n",
    "for player in players:\n",
    "    for adversary in adversaries:\n",
    "        if (player, adversary) in match_grid:\n",
    "            continue\n",
    "        if (adversary, player) in match_grid:\n",
    "            continue\n",
    "        if adversary == player:\n",
    "            continue\n",
    "        match_paring.append((player, adversary))\n",
    "\n",
    "for player, adversary in tqdm(match_paring):\n",
    "    try:\n",
    "        wins, losses, ties, avg_rounds, wins_by_class, loss_by_class, errors = start_game(player=player, adversary=adversary)\n",
    "        match_grid[(player, adversary)] = (wins, losses, ties, avg_rounds)\n",
    "        match_grid[(adversary, player)] = (losses, wins, ties, avg_rounds)\n",
    "\n",
    "        class_grid[(player, adversary)] = (wins_by_class, loss_by_class)\n",
    "        class_grid[(adversary, player)] = (loss_by_class, wins_by_class)\n",
    "    except Exception as e:\n",
    "        print(f\"Error: {e} on {player} vs {adversary}\")\n",
    "        match_grid[(player, adversary)] = (0, 0, 0, 0)\n",
    "        match_grid[(adversary, player)] = (0, 0, 0, 0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate Report about the matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# setup a pandas table to plot the wins, losses, and ties for each matchup\n",
    "df = pd.DataFrame(match_grid).T\n",
    "df.columns = ['Wins', 'Losses', 'Ties', 'AVG Rounds']\n",
    "df = df.sort_values('Wins', ascending=False)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "leaderboard = df.groupby(level=0).sum().sort_values('Wins', ascending=False)\n",
    "\n",
    "with open(\"leaderboard_all.latex\", \"w\") as f:\n",
    "    header =  r\"\"\"\n",
    "\\begin{table}[h]\n",
    "\\centering\n",
    "\\begin{tabular}{|l|c|c|c|c|}\n",
    "\\hline\n",
    "\\textbf{Agent} & \\textbf{Wins} & \\textbf{Losses} & \\textbf{Ties} & \\textbf{AVG Rounds} \\\\\n",
    "\\hline\n",
    "\"\"\"\n",
    "    f.write(header + \"\\n\")\n",
    "    for index, row in leaderboard.iterrows():\n",
    "        player_str = index.replace('_', '\\_')\n",
    "        f.write(f\"{player_str} & {row['Wins']} & {row['Losses']} & {row['Ties']} & {row['AVG Rounds']:.2f} \\\\\\\\\\n\")\n",
    "    footer = r\"\"\"\n",
    "\\hline\n",
    "\\end{tabular}\n",
    "\\caption{Leaderboard for D\\&D Four Classes Tournament: LLMs vs RL Agents}\n",
    "\\label{tab:dnd-four-classes-leaderboard}\n",
    "\\end{table}\n",
    "\"\"\"\n",
    "    f.write(footer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a leaderboard on the most wins\n",
    "\n",
    "leaderboard = df.groupby(level=0).sum().sort_values('Wins', ascending=False)\n",
    "leaderboard.to_csv(\"leaderboard_all.csv\")\n",
    "\n",
    "\n",
    "\n",
    "leaderboard"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dump results to CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"match_results_all.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# read the match_result_all.csv\n",
    "df = pd.read_csv(\"match_results_all.csv\")\n",
    "df = df.set_index(['player', 'adversary'])\n",
    "\n",
    "# append a column if a player has beaten its adversary\n",
    "\n",
    "df['player_won'] = df['Wins'] > df['Losses']\n",
    "df['adversary_won'] = df['Wins'] < df['Losses']\n",
    "df['tie'] = df['Wins'] == df['Losses']\n",
    "\n",
    "# create a pivot table to show the wins, losses, and ties for each player\n",
    "pivot = df.pivot_table(index='player', values=['player_won','adversary_won'], aggfunc='sum')\n",
    "# sort by wins and then by the least losses\n",
    "pivot = pivot.sort_values('player_won', ascending=False)\n",
    "pivot\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# create a table of how many times an agent has \"won\" against another agent\n",
    "win_table = {}\n",
    "lost_against = {}\n",
    "for (player, adversary) in match_grid.keys():\n",
    "    wins, losses, _, _ = match_grid[(player, adversary)]\n",
    "    win_table[player] = win_table.get(player, 0)\n",
    "    if wins > losses:\n",
    "        win_table[player] += 1\n",
    "    else:\n",
    "        losses = lost_against.get(player, [])\n",
    "        losses.append(adversary)\n",
    "        lost_against[player] =  losses\n",
    "\n",
    "lost_against\n",
    "win_table\n",
    "\n",
    "# create a table ranking the agents by how many times they have won\n",
    "df = pd.DataFrame(win_table.items(), columns=[\"Agent\", \"Wins\"])\n",
    "df = df.sort_values('Wins', ascending=False)\n",
    "df.to_csv(\"agent_ranking_all.csv\")\n",
    "df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dump CSV with class matchups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show the class grid\n",
    "\n",
    "print(\"Class Grid\")\n",
    "print(class_grid)\n",
    "# Class Grid: {('random', 'llm_mistral'): ({'wizard-2': 19, 'fighter-2': 9, 'rogue-2': 10}, {'fighter-2': 32, 'rogue-2': 6, 'wizard-2': 8}), ('llm_mistral', 'random'): ({'fighter-2': 32, 'rogue-2': 6, 'wizard-2': 8}, {'wizard-2': 19, 'fighter-2': 9, 'rogue-2': 10}), ('random', 'llm_llama3'): ({'wizard-2': 17, 'fighter-2': 3, 'rogue-2': 26}, {'rogue-2': 10, 'fighter-2': 19, 'wizard-2': 15}), ('llm_llama3', 'random'): ({'rogue-2': 10, 'fighter-2': 19, 'wizard-2': 15}, {'wizard-2': 17, 'fighter-2': 3, 'rogue-2': 26}), ('random', 'llm_gpt4'): ({'rogue-2': 14, 'wizard-2': 22, 'fighter-2': 4}, {'wizard-2': 20, 'fighter-2': 11, 'rogue-2': 15}), ('llm_gpt4', 'random'): ({'wizard-2': 20, 'fighter-2': 11, 'rogue-2': 15}, {'rogue-2': 14, 'wizard-2': 22, 'fighter-2': 4}), ('random', 'ai'): ({'fighter-2': 14, 'rogue-2': 22, 'wizard-2': 5}, {'rogue-2': 11, 'wizard-2': 32, 'fighter-2': 6}), ('ai', 'random'): ({'rogue-2': 11, 'wizard-2': 32, 'fighter-2': 6}, {'fighter-2': 14, 'rogue-2': 22, 'wizard-2': 5}), ('random', 'rl_rules_trained'): ({'rogue-2': 18, 'fighter-2': 5, 'wizard-2': 13}, {'wizard-2': 18, 'rogue-2': 15, 'fighter-2': 15}), ('rl_rules_trained', 'random'): ({'wizard-2': 18, 'rogue-2': 15, 'fighter-2': 15}, {'rogue-2': 18, 'fighter-2': 5, 'wizard-2': 13}), ('random', 'rl_llama3_trained'): ({'fighter-2': 8, 'rogue-2': 21, 'wizard-2': 7}, {'rogue-2': 10, 'wizard-2': 20, 'fighter-2': 21}), ('rl_llama3_trained', 'random'): ({'rogue-2': 10, 'wizard-2': 20, 'fighter-2': 21}, {'fighter-2': 8, 'rogue-2': 21, 'wizard-2': 7}), ('random', 'rl_gpt4_trained'): ({'fighter-2': 9, 'wizard-2': 6, 'rogue-2': 15}, {'fighter-2': 21, 'wizard-2': 20, 'rogue-2': 7}), ('rl_gpt4_trained', 'random'): ({'fighter-2': 21, 'wizard-2': 20, 'rogue-2': 7}, {'fighter-2': 9, 'wizard-2': 6, 'rogue-2': 15}), ('random', 'rl_mistral_trained'): ({'rogue-2': 15, 'wizard-2': 11, 'fighter-2': 6}, {'fighter-2': 18, 'rogue-2': 10, 'wizard-2': 27}), ('rl_mistral_trained', 'random'): ({'fighter-2': 18, 'rogue-2': 10, 'wizard-2': 27}, {'rogue-2': 15, 'wizard-2': 11, 'fighter-2': 6}), ('llm_mistral', 'llm_llama3'): ({'rogue-2': 19, 'wizard-2': 21, 'fighter-2': 13}, {'rogue-2': 17, 'fighter-2': 13, 'wizard-2': 7}), ('llm_llama3', 'llm_mistral'): ({'rogue-2': 17, 'fighter-2': 13, 'wizard-2': 7}, {'rogue-2': 19, 'wizard-2': 21, 'fighter-2': 13}), ('llm_mistral', 'llm_gpt4'): ({'rogue-2': 20, 'wizard-2': 22, 'fighter-2': 8}, {'rogue-2': 12, 'fighter-2': 21, 'wizard-2': 7}), ('llm_gpt4', 'llm_mistral'): ({'rogue-2': 12, 'fighter-2': 21, 'wizard-2': 7}, {'rogue-2': 20, 'wizard-2': 22, 'fighter-2': 8}), ('llm_mistral', 'ai'): ({'rogue-2': 21, 'wizard-2': 6, 'fighter-2': 15}, {'wizard-2': 28, 'rogue-2': 7, 'fighter-2': 12}), ('ai', 'llm_mistral'): ({'wizard-2': 28, 'rogue-2': 7, 'fighter-2': 12}, {'rogue-2': 21, 'wizard-2': 6, 'fighter-2': 15}), ('llm_mistral', 'rl_rules_trained'): ({'wizard-2': 14, 'fighter-2': 18, 'rogue-2': 13}, {'fighter-2': 17, 'rogue-2': 8, 'wizard-2': 8}), ('rl_rules_trained', 'llm_mistral'): ({'fighter-2': 17, 'rogue-2': 8, 'wizard-2': 8}, {'wizard-2': 14, 'fighter-2': 18, 'rogue-2': 13}), ('llm_mistral', 'rl_llama3_trained'): ({'rogue-2': 15, 'fighter-2': 14, 'wizard-2': 12}, {'rogue-2': 13, 'fighter-2': 21, 'wizard-2': 12}), ('rl_llama3_trained', 'llm_mistral'): ({'rogue-2': 13, 'fighter-2': 21, 'wizard-2': 12}, {'rogue-2': 15, 'fighter-2': 14, 'wizard-2': 12}), ('llm_mistral', 'rl_gpt4_trained'): ({'rogue-2': 12, 'fighter-2': 8, 'wizard-2': 18}, {'wizard-2': 16, 'fighter-2': 18, 'rogue-2': 12}), ('rl_gpt4_trained', 'llm_mistral'): ({'wizard-2': 16, 'fighter-2': 18, 'rogue-2': 12}, {'rogue-2': 12, 'fighter-2': 8, 'wizard-2': 18}), ('llm_mistral', 'rl_mistral_trained'): ({'wizard-2': 22, 'fighter-2': 8, 'rogue-2': 15}, {'rogue-2': 8, 'wizard-2': 14, 'fighter-2': 17}), ('rl_mistral_trained', 'llm_mistral'): ({'rogue-2': 8, 'wizard-2': 14, 'fighter-2': 17}, {'wizard-2': 22, 'fighter-2': 8, 'rogue-2': 15}), ('llm_llama3', 'llm_gpt4'): ({'wizard-2': 14, 'rogue-2': 21, 'fighter-2': 6}, {'wizard-2': 7, 'rogue-2': 13, 'fighter-2': 26}), ('llm_gpt4', 'llm_llama3'): ({'wizard-2': 7, 'rogue-2': 13, 'fighter-2': 26}, {'wizard-2': 14, 'rogue-2': 21, 'fighter-2': 6}), ('llm_llama3', 'ai'): ({'rogue-2': 17, 'fighter-2': 20, 'wizard-2': 5}, {'wizard-2': 25, 'rogue-2': 16, 'fighter-2': 6}), ('ai', 'llm_llama3'): ({'wizard-2': 25, 'rogue-2': 16, 'fighter-2': 6}, {'rogue-2': 17, 'fighter-2': 20, 'wizard-2': 5}), ('llm_llama3', 'rl_rules_trained'): ({'wizard-2': 13, 'fighter-2': 8, 'rogue-2': 20}, {'rogue-2': 8, 'fighter-2': 25, 'wizard-2': 16}), ('rl_rules_trained', 'llm_llama3'): ({'rogue-2': 8, 'fighter-2': 25, 'wizard-2': 16}, {'wizard-2': 13, 'fighter-2': 8, 'rogue-2': 20}), ('llm_llama3', 'rl_llama3_trained'): ({'rogue-2': 19, 'fighter-2': 10, 'wizard-2': 12}, {'fighter-2': 32, 'wizard-2': 15, 'rogue-2': 2}), ('rl_llama3_trained', 'llm_llama3'): ({'fighter-2': 32, 'wizard-2': 15, 'rogue-2': 2}, {'rogue-2': 19, 'fighter-2': 10, 'wizard-2': 12}), ('llm_llama3', 'rl_gpt4_trained'): ({'fighter-2': 11, 'rogue-2': 18, 'wizard-2': 13}, {'fighter-2': 23, 'rogue-2': 8, 'wizard-2': 17}), ('rl_gpt4_trained', 'llm_llama3'): ({'fighter-2': 23, 'rogue-2': 8, 'wizard-2': 17}, {'fighter-2': 11, 'rogue-2': 18, 'wizard-2': 13}), ('llm_llama3', 'rl_mistral_trained'): ({'fighter-2': 5, 'rogue-2': 21, 'wizard-2': 11}, {'rogue-2': 14, 'fighter-2': 30, 'wizard-2': 6}), ('rl_mistral_trained', 'llm_llama3'): ({'rogue-2': 14, 'fighter-2': 30, 'wizard-2': 6}, {'fighter-2': 5, 'rogue-2': 21, 'wizard-2': 11}), ('llm_gpt4', 'ai'): ({'fighter-2': 33, 'rogue-2': 6, 'wizard-2': 5}, {'wizard-2': 27, 'fighter-2': 8, 'rogue-2': 10}), ('ai', 'llm_gpt4'): ({'wizard-2': 27, 'fighter-2': 8, 'rogue-2': 10}, {'fighter-2': 33, 'rogue-2': 6, 'wizard-2': 5}), ('llm_gpt4', 'rl_rules_trained'): ({'rogue-2': 18, 'wizard-2': 24, 'fighter-2': 6}, {'rogue-2': 16, 'fighter-2': 17, 'wizard-2': 9}), ('rl_rules_trained', 'llm_gpt4'): ({'rogue-2': 16, 'fighter-2': 17, 'wizard-2': 9}, {'rogue-2': 18, 'wizard-2': 24, 'fighter-2': 6}), ('llm_gpt4', 'rl_llama3_trained'): ({'rogue-2': 21, 'fighter-2': 4, 'wizard-2': 13}, {'wizard-2': 11, 'fighter-2': 19, 'rogue-2': 19}), ('rl_llama3_trained', 'llm_gpt4'): ({'wizard-2': 11, 'fighter-2': 19, 'rogue-2': 19}, {'rogue-2': 21, 'fighter-2': 4, 'wizard-2': 13}), ('llm_gpt4', 'rl_gpt4_trained'): ({'fighter-2': 13, 'wizard-2': 10, 'rogue-2': 12}, {'fighter-2': 22, 'wizard-2': 13, 'rogue-2': 14}), ('rl_gpt4_trained', 'llm_gpt4'): ({'fighter-2': 22, 'wizard-2': 13, 'rogue-2': 14}, {'fighter-2': 13, 'wizard-2': 10, 'rogue-2': 12}), ('llm_gpt4', 'rl_mistral_trained'): ({'rogue-2': 15, 'wizard-2': 14, 'fighter-2': 6}, {'rogue-2': 17, 'wizard-2': 18, 'fighter-2': 17}), ('rl_mistral_trained', 'llm_gpt4'): ({'rogue-2': 17, 'wizard-2': 18, 'fighter-2': 17}, {'rogue-2': 15, 'wizard-2': 14, 'fighter-2': 6}), ('rl_rules_trained', 'ai'): ({'fighter-2': 27, 'rogue-2': 9, 'wizard-2': 13}, {'wizard-2': 21, 'rogue-2': 8, 'fighter-2': 9}), ('ai', 'rl_rules_trained'): ({'wizard-2': 21, 'rogue-2': 8, 'fighter-2': 9}, {'fighter-2': 27, 'rogue-2': 9, 'wizard-2': 13}), ('rl_rules_trained', 'rl_llama3_trained'): ({'wizard-2': 13, 'fighter-2': 8, 'rogue-2': 12}, {'rogue-2': 10, 'wizard-2': 14, 'fighter-2': 12}), ('rl_llama3_trained', 'rl_rules_trained'): ({'rogue-2': 10, 'wizard-2': 14, 'fighter-2': 12}, {'wizard-2': 13, 'fighter-2': 8, 'rogue-2': 12}), ('rl_rules_trained', 'rl_gpt4_trained'): ({'fighter-2': 6, 'wizard-2': 19, 'rogue-2': 8}, {'rogue-2': 11, 'wizard-2': 14, 'fighter-2': 20}), ('rl_gpt4_trained', 'rl_rules_trained'): ({'rogue-2': 11, 'wizard-2': 14, 'fighter-2': 20}, {'fighter-2': 6, 'wizard-2': 19, 'rogue-2': 8}), ('rl_rules_trained', 'rl_mistral_trained'): ({'rogue-2': 10, 'wizard-2': 14, 'fighter-2': 10}, {'wizard-2': 19, 'fighter-2': 13, 'rogue-2': 6}), ('rl_mistral_trained', 'rl_rules_trained'): ({'wizard-2': 19, 'fighter-2': 13, 'rogue-2': 6}, {'rogue-2': 10, 'wizard-2': 14, 'fighter-2': 10}), ('rl_llama3_trained', 'ai'): ({'rogue-2': 8, 'fighter-2': 24, 'wizard-2': 14}, {'wizard-2': 22, 'rogue-2': 14, 'fighter-2': 8}), ('ai', 'rl_llama3_trained'): ({'wizard-2': 22, 'rogue-2': 14, 'fighter-2': 8}, {'rogue-2': 8, 'fighter-2': 24, 'wizard-2': 14}), ('rl_llama3_trained', 'rl_gpt4_trained'): ({'rogue-2': 17, 'wizard-2': 14, 'fighter-2': 10}, {'wizard-2': 19, 'rogue-2': 10, 'fighter-2': 17}), ('rl_gpt4_trained', 'rl_llama3_trained'): ({'wizard-2': 19, 'rogue-2': 10, 'fighter-2': 17}, {'rogue-2': 17, 'wizard-2': 14, 'fighter-2': 10}), ('rl_llama3_trained', 'rl_mistral_trained'): ({'wizard-2': 24, 'rogue-2': 13, 'fighter-2': 6}, {'rogue-2': 9, 'fighter-2': 14, 'wizard-2': 24}), ('rl_mistral_trained', 'rl_llama3_trained'): ({'rogue-2': 9, 'fighter-2': 14, 'wizard-2': 24}, {'wizard-2': 24, 'rogue-2': 13, 'fighter-2': 6}), ('rl_gpt4_trained', 'ai'): ({'fighter-2': 30, 'rogue-2': 12, 'wizard-2': 7}, {'rogue-2': 14, 'wizard-2': 21, 'fighter-2': 6}), ('ai', 'rl_gpt4_trained'): ({'rogue-2': 14, 'wizard-2': 21, 'fighter-2': 6}, {'fighter-2': 30, 'rogue-2': 12, 'wizard-2': 7}), ('rl_gpt4_trained', 'rl_mistral_trained'): ({'rogue-2': 18, 'wizard-2': 14, 'fighter-2': 10}, {'rogue-2': 13, 'wizard-2': 13, 'fighter-2': 18}), ('rl_mistral_trained', 'rl_gpt4_trained'): ({'rogue-2': 13, 'wizard-2': 13, 'fighter-2': 18}, {'rogue-2': 18, 'wizard-2': 14, 'fighter-2': 10}), ('rl_mistral_trained', 'ai'): ({'fighter-2': 28, 'rogue-2': 15, 'wizard-2': 5}, {'fighter-2': 5, 'wizard-2': 18, 'rogue-2': 19}), ('ai', 'rl_mistral_trained'): ({'fighter-2': 5, 'wizard-2': 18, 'rogue-2': 19}, {'fighter-2': 28, 'rogue-2': 15, 'wizard-2': 5})}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert to latex for publishing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "adversaries.sort()\n",
    "\n",
    "with open(\"match_grid_all.latex\", \"w\") as f:\n",
    "    header =  r\"\"\"\n",
    "\\begin{table}[h]\n",
    "\\centering\n",
    "\\resizebox{\\textwidth}{!}{%\n",
    "\\begin{tabular}{|l|c|c|c|c|c|c|c|c|c|}\n",
    "\\hline\"\"\"\n",
    "    f.write(header + \"\\n\")\n",
    "    f.write(\"\\\\textbf{Agent}\")\n",
    "    for player in adversaries:\n",
    "        player_str = player.replace('_', '\\_')\n",
    "        f.write(\" & \\\\textbf{\" + f\"{player_str}\" + \"}\")\n",
    "    f.write(\" \\\\\\\\\\n\")\n",
    "    f.write(\"\\\\hline\\n\")\n",
    "    for player in adversaries:\n",
    "        player_str = player.replace('_', '\\_')\n",
    "        f.write(f\"{player_str}\")\n",
    "        for adversary in adversaries:\n",
    "            if (player, adversary) in match_grid:\n",
    "                wins, losses, ties, avg_rounds = match_grid[(player, adversary)]\n",
    "                f.write(f\" & {wins}/{losses}/{ties} \")\n",
    "            else:\n",
    "                f.write(\" & - \")\n",
    "        f.write(\" \\\\\\\\\\n\")\n",
    "    footer = r\"\"\"\n",
    "\\hline\n",
    "\\end{tabular}%\n",
    "}\n",
    "\\caption{D\\&D Four Classes Tournament: Win/Loss/Tie Matrix}\n",
    "\\label{tab:dnd-four-classes-matrix}\n",
    "\\end{table}\"\"\"\n",
    "    f.write(footer)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai322",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
