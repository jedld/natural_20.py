{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from natural20.map import Map, Terrain\n",
    "from natural20.battle import Battle\n",
    "from natural20.player_character import PlayerCharacter\n",
    "from natural20.map_renderer import MapRenderer\n",
    "from natural20.die_roll import DieRoll\n",
    "from natural20.generic_controller import GenericController\n",
    "from natural20.session import Session\n",
    "from natural20.actions.move_action import MoveAction\n",
    "from natural20.action import Action\n",
    "from natural20.gym.dndenv import dndenv, action_type_to_int\n",
    "from gymnasium import register, envs, make\n",
    "from llm_interface import GPT4Interfacer, LLama3Interface\n",
    "from natural20.gym.dndenv_controller import DndenvController\n",
    "from model import QNetwork\n",
    "from natural20.gym.llm_helpers.prompting_utils import action_to_prompt\n",
    "from natural20.gym.dndenv import embedding_loader\n",
    "from natural20.event_manager import EventManager\n",
    "from natural20.gym.dqn.policy import ModelPolicy\n",
    "from llm_interface import GPT4Interfacer\n",
    "import os\n",
    "import time\n",
    "import torch\n",
    "import random\n",
    "import numpy as np\n",
    "from tqdm.autonotebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "ROUND_PER_MATCH = 30\n",
    "# setup vLLM endpoints\n",
    "LLAMA3_URL = \"http://localhost:8001/v1\"\n",
    "MISTRAL_URL = \"http://localhost:8000/v1\"\n",
    "GPT4_TOKEN = \"OPENAI_GPT_TOKEN_HERE\"\n",
    "WEIGHTS_FOLDER = \"model_weights_all\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "event_manager = EventManager()\n",
    "event_manager.standard_cli()\n",
    "session = Session(root_path=\"map_with_obstacles\", event_manager=event_manager)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Agent:\n",
    "    def action(self, observation, info):\n",
    "        return random.choice(info['available_moves'])\n",
    "\n",
    "class CustomAgent(Agent):\n",
    "    def __init__(self, llm_interface):\n",
    "        self.llm_interface = llm_interface\n",
    "\n",
    "    def action(self, observation, info):\n",
    "        return self.llm_interface.select_action_for_state(observation, info)\n",
    "    def __str__(self) -> str:\n",
    "        return \"Custom LLM Agent\"\n",
    "\n",
    "class ModelAgent(Agent):\n",
    "    def __init__(self, model_policy):\n",
    "        self.model_policy = model_policy\n",
    "\n",
    "    def action(self, observation, info):\n",
    "        return self.model_policy.action(observation, info)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setup the appropriate URLs to your vLLM instances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prompt_for_variant(variant):\n",
    "    if variant == \"llama3\":\n",
    "        prompt = GPT4Interfacer(debug=False, tools=False, base_url=LLAMA3_URL, api_key=\"token1234\", variant='NousResearch/Meta-Llama-3.1-8B-Instruct')\n",
    "    elif variant == \"gpt4\":\n",
    "        prompt = GPT4Interfacer(debug=False, tools=True, api_key=GPT4_TOKEN, variant='gpt-4o-mini')\n",
    "    elif variant == \"mistral\":\n",
    "        prompt = GPT4Interfacer(debug=False, tools=False, base_url=MISTRAL_URL, api_key=\"token1234\", variant='mistralai/Mistral-7B-Instruct-v0.3')\n",
    "    else:\n",
    "        raise ValueError(f\"Invalid variant: {variant}\")\n",
    "\n",
    "    return prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def start_game(player=\"rl_rules_trained\", adversary=\"llm_llama3\"):\n",
    "    player_agent = None\n",
    "    if player == \"rl_rules_trained\":\n",
    "        model = ModelPolicy(session, weights_file=f\"{WEIGHTS_FOLDER}/model_best_dnd_egreedy.pt\", device=device, debug=False)\n",
    "        player_agent = ModelAgent(model)\n",
    "    elif player == \"rl_llama3_trained\":\n",
    "        model = ModelPolicy(session, weights_file=f\"{WEIGHTS_FOLDER}/model_best_llm_adversary.pt\", device=device, debug=False)\n",
    "        player_agent = ModelAgent(model)\n",
    "    elif player == \"rl_mistral_trained\":\n",
    "        model = ModelPolicy(session, weights_file=f\"{WEIGHTS_FOLDER}/model_best_llm_adversary_mistral.pt\", device=device, debug=False)\n",
    "        player_agent = ModelAgent(model)\n",
    "    elif player == \"rl_gpt4_trained\":\n",
    "        model = ModelPolicy(session, weights_file=f\"{WEIGHTS_FOLDER}/model_best_llm_adversary_gpt4.pt\", device=device, debug=False)\n",
    "        player_agent = ModelAgent(model)        \n",
    "    elif player.startswith(\"llm\"):\n",
    "        prompt = prompt_for_variant(player.split(\"_\")[1])\n",
    "        player_agent = CustomAgent(prompt)\n",
    "    elif player == \"random\":\n",
    "        player_agent = Agent()\n",
    "    else:\n",
    "        raise ValueError(f\"Invalid player: {player}\")\n",
    "\n",
    "    # Setup Adversary\n",
    "    if adversary == \"rl_rules_trained\":\n",
    "        model = ModelPolicy(session, weights_file=f\"{WEIGHTS_FOLDER}/model_best_dnd_egreedy.pt\", device=device, debug=False)\n",
    "        adversary_agent = ModelAgent(model)\n",
    "    elif adversary == \"rl_llama3_trained\":\n",
    "        model = ModelPolicy(session, weights_file=f\"{WEIGHTS_FOLDER}/model_best_llm_adversary.pt\", device=device, debug=False)\n",
    "        adversary_agent = ModelAgent(model)\n",
    "    elif adversary == \"rl_mistral_trained\":\n",
    "        model = ModelPolicy(session, weights_file=f\"{WEIGHTS_FOLDER}/model_best_llm_adversary_mistral.pt\", device=device, debug=False)\n",
    "        adversary_agent = ModelAgent(model)\n",
    "    elif adversary == \"rl_gpt4_trained\":\n",
    "        model = ModelPolicy(session, weights_file=f\"{WEIGHTS_FOLDER}/model_best_llm_adversary_gpt4.pt\", device=device, debug=False)\n",
    "        adversary_agent = ModelAgent(model)\n",
    "    elif adversary.startswith(\"llm\"):\n",
    "        prompt = prompt_for_variant(adversary.split(\"_\")[1])\n",
    "        adversary_agent = CustomAgent(prompt)\n",
    "    elif adversary == \"ai\":\n",
    "        adversary_agent = None\n",
    "    elif adversary == \"random\":\n",
    "        adversary_agent = Agent()\n",
    "    else:\n",
    "        raise ValueError(f\"Invalid adversary: {adversary}\")\n",
    "\n",
    "    def reaction_callback(state, reward, done, truncated, info):\n",
    "        \"\"\"\n",
    "        Callback function to be called when the environment is waiting for a reaction from the agent.\n",
    "        Reactions in DnD are typically reactions to enemy actions, such as opportunity attacks.\n",
    "        \"\"\"\n",
    "        print(f\"{info['reactor']}: Reaction for {info['trigger']}:\")\n",
    "        action = player_agent.action(state, info)\n",
    "        return action\n",
    "\n",
    "    env = make(\"dndenv-v0\", root_path=\"map_with_obstacles\",\n",
    "           render_mode=\"ansi\",\n",
    "           custom_agent=adversary_agent,\n",
    "           profiles=lambda: random.choice(['high_elf_fighter']),\n",
    "                enemies=lambda: random.choice(['high_elf_fighter']),\n",
    "                map_file=lambda: random.choice(['maps/simple_map',\\\n",
    "                                                'maps/complex_map', \\\n",
    "                                                'maps/game_map', \\\n",
    "                                                'maps/walled_map']),\n",
    "           debug=False,\n",
    "           show_logs=False)\n",
    "    wins = 0\n",
    "    losses = 0\n",
    "    ties = 0\n",
    "    total_rounds = []\n",
    "    for round in tqdm(range(ROUND_PER_MATCH), leave=False):\n",
    "        print(f\"Round {round + 1}\")\n",
    "\n",
    "        observation, info = env.reset(reaction_callback=reaction_callback)\n",
    "        action = player_agent.action(observation, info)\n",
    "        terminal = False\n",
    "        steps = 0\n",
    "\n",
    "        while not terminal and steps < 512:\n",
    "            steps += 1\n",
    "            observation, reward, terminal, truncated, info = env.step(action)\n",
    "\n",
    "            if not terminal and not truncated:\n",
    "                action = player_agent.action(observation, info)\n",
    "\n",
    "            if terminal or truncated:\n",
    "                print(f\"Reward: {reward}\")\n",
    "                if reward == 10:\n",
    "                    wins += 1\n",
    "                elif reward == -10:\n",
    "                    losses += 1\n",
    "                else:\n",
    "                    ties += 1\n",
    "                break\n",
    "        total_rounds.append(info['round'])\n",
    "\n",
    "    print(f\"Wins: {wins}, Losses: {losses}, Ties: {ties}\")\n",
    "    return wins, losses, ties, np.mean(total_rounds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a match grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "match_grid = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setup pairings for the tournament"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup available players and adversaries, note that duplicate pairings are automatically removed\n",
    "\n",
    "players = [\"random\", \"llm_mistral\", \"llm_llama3\", \"llm_gpt4\", \"rl_rules_trained\", \"rl_llama3_trained\", \"rl_gpt4_trained\", \"rl_mistral_trained\"]\n",
    "adversaries = [\"random\", \"llm_mistral\", \"llm_llama3\", \"llm_gpt4\", \"ai\", \"rl_rules_trained\", \"rl_llama3_trained\", \"rl_gpt4_trained\", \"rl_mistral_trained\"]\n",
    "\n",
    "# remove from matchgrid first\n",
    "\n",
    "# for player in players:\n",
    "#     for adversary in adversaries:\n",
    "#         if (player,adversary) in match_grid:\n",
    "#             del match_grid[(player, adversary)]\n",
    "#         if (adversary, player) in match_grid:\n",
    "#             del match_grid[(adversary, player)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0912dcc26d8643cfa2deb534cea9f7e3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ed9eaa47fbb048f394bba4614a1e576b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/30 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Round 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jedld/.local/lib/python3.10/site-packages/gymnasium/utils/passive_env_checker.py:159: UserWarning: \u001b[33mWARN: The obs returned by the `reset()` method is not within the observation space.\u001b[0m\n",
      "  logger.warn(f\"{pre} is not within the observation space.\")\n",
      "/home/jedld/.local/lib/python3.10/site-packages/gymnasium/utils/passive_env_checker.py:159: UserWarning: \u001b[33mWARN: The obs returned by the `step()` method is not within the observation space.\u001b[0m\n",
      "  logger.warn(f\"{pre} is not within the observation space.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reward: 10\n",
      "Round 2\n",
      "Reward: 10\n",
      "Round 3\n",
      "Reward: -10\n",
      "Round 4\n",
      "gomerin: Reaction for opportunity_attack:\n",
      "Reward: -10\n",
      "Round 5\n",
      "Reward: 10\n",
      "Round 6\n",
      "Reward: -10\n",
      "Round 7\n",
      "Reward: -10\n",
      "Round 8\n",
      "Reward: 10\n",
      "Round 9\n",
      "Reward: 10\n",
      "Round 10\n",
      "Reward: -10\n",
      "Round 11\n",
      "Reward: -10\n",
      "Round 12\n",
      "Reward: 10\n",
      "Round 13\n",
      "Reward: 10\n",
      "Round 14\n",
      "Reward: 10\n",
      "Round 15\n",
      "Reward: 10\n",
      "Round 16\n",
      "Reward: 0\n",
      "Round 17\n",
      "Reward: -10\n",
      "Round 18\n",
      "Reward: 10\n",
      "Round 19\n",
      "Reward: 10\n",
      "Round 20\n",
      "Reward: -10\n",
      "Round 21\n",
      "Reward: 10\n",
      "Round 22\n",
      "Reward: 10\n",
      "Round 23\n",
      "Reward: 10\n",
      "Round 24\n",
      "Reward: -10\n",
      "Round 25\n",
      "Reward: 0\n",
      "Round 26\n",
      "Reward: -10\n",
      "Round 27\n",
      "Reward: 0\n",
      "Round 28\n",
      "Reward: -10\n",
      "Round 29\n",
      "Reward: 10\n",
      "Round 30\n",
      "gomerin: Reaction for opportunity_attack:\n",
      "Reward: 10\n",
      "Wins: 16, Losses: 11, Ties: 3\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2c4f8dccb7514c9b881ac63d4034d373",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/30 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Round 1\n",
      "Reward: 10\n",
      "Round 2\n",
      "Reward: 10\n",
      "Round 3\n",
      "Reward: 10\n",
      "Round 4\n",
      "gomerin: Reaction for opportunity_attack:\n",
      "gomerin: Reaction for opportunity_attack:\n",
      "Reward: 10\n",
      "Round 5\n",
      "Reward: -10\n",
      "Round 6\n",
      "Reward: 10\n",
      "Round 7\n",
      "Reward: 10\n",
      "Round 8\n",
      "gomerin: Reaction for opportunity_attack:\n",
      "Reward: 10\n",
      "Round 9\n",
      "Reward: -10\n",
      "Round 10\n",
      "Reward: 10\n",
      "Round 11\n",
      "Reward: -10\n",
      "Round 12\n",
      "Reward: 10\n",
      "Round 13\n",
      "Reward: 10\n",
      "Round 14\n",
      "Reward: 10\n",
      "Round 15\n",
      "Reward: 10\n",
      "Round 16\n",
      "Reward: -10\n",
      "Round 17\n",
      "Reward: 10\n",
      "Round 18\n",
      "Reward: -10\n",
      "Round 19\n",
      "Reward: 10\n",
      "Round 20\n",
      "Reward: 10\n",
      "Round 21\n",
      "Reward: -10\n",
      "Round 22\n",
      "Reward: 10\n",
      "Round 23\n",
      "Reward: 10\n",
      "Round 24\n",
      "Reward: -10\n",
      "Round 25\n",
      "Reward: 10\n",
      "Round 26\n",
      "Reward: -10\n",
      "Round 27\n",
      "Reward: -10\n",
      "Round 28\n",
      "Reward: -10\n",
      "Round 29\n",
      "Reward: -10\n",
      "Round 30\n",
      "gomerin: Reaction for opportunity_attack:\n",
      "Reward: 10\n",
      "Wins: 19, Losses: 11, Ties: 0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4ca38931724f4659b05137ec20d7eb37",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/30 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Round 1\n",
      "Reward: -10\n",
      "Round 2\n",
      "Reward: 10\n",
      "Round 3\n",
      "Reward: 10\n",
      "Round 4\n",
      "Reward: 10\n",
      "Round 5\n",
      "Reward: 10\n",
      "Round 6\n",
      "Reward: 10\n",
      "Round 7\n",
      "Reward: 10\n",
      "Round 8\n",
      "Reward: -10\n",
      "Round 9\n",
      "Reward: 10\n",
      "Round 10\n",
      "Reward: 10\n",
      "Round 11\n",
      "Reward: -10\n",
      "Round 12\n",
      "Reward: -10\n",
      "Round 13\n",
      "Reward: 10\n",
      "Round 14\n",
      "Reward: -10\n",
      "Round 15\n",
      "Reward: -10\n",
      "Round 16\n",
      "Reward: -10\n",
      "Round 17\n",
      "Reward: -10\n",
      "Round 18\n",
      "Reward: 10\n",
      "Round 19\n",
      "Reward: -10\n",
      "Round 20\n",
      "Reward: 10\n",
      "Round 21\n",
      "Reward: 10\n",
      "Round 22\n",
      "Reward: -10\n",
      "Round 23\n",
      "Reward: -10\n",
      "Round 24\n",
      "Reward: -10\n",
      "Round 25\n",
      "Reward: -10\n",
      "Round 26\n",
      "Reward: -10\n",
      "Round 27\n",
      "Reward: 10\n",
      "Round 28\n",
      "Reward: 10\n",
      "Round 29\n",
      "Reward: -10\n",
      "Round 30\n",
      "Reward: -10\n",
      "Wins: 14, Losses: 16, Ties: 0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "match_paring = []\n",
    "\n",
    "# create a cartesian product of all players and adversaries\n",
    "for player in players:\n",
    "    for adversary in adversaries:\n",
    "        if (player, adversary) in match_grid:\n",
    "            continue\n",
    "        if (adversary, player) in match_grid:\n",
    "            continue\n",
    "        if adversary == player:\n",
    "            continue\n",
    "        match_paring.append((player, adversary))\n",
    "\n",
    "for player, adversary in tqdm(match_paring):\n",
    "    try:\n",
    "        wins, losses, ties, avg_rounds = start_game(player=player, adversary=adversary)\n",
    "        match_grid[(player, adversary)] = (wins, losses, ties, avg_rounds)\n",
    "        match_grid[(adversary, player)] = (losses, wins, ties, avg_rounds)\n",
    "    except Exception as e:\n",
    "        print(f\"Error: {e} on {player} vs {adversary}\")\n",
    "        match_grid[(player, adversary)] = (0, 0, 0, 0)\n",
    "        match_grid[(adversary, player)] = (0, 0, 0, 0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate Report about the matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>Wins</th>\n",
       "      <th>Losses</th>\n",
       "      <th>Ties</th>\n",
       "      <th>AVG Rounds</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>llm_mistral</th>\n",
       "      <th>random</th>\n",
       "      <td>29.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ai</th>\n",
       "      <th>random</th>\n",
       "      <td>29.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.800000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rl_gpt4_trained</th>\n",
       "      <th>random</th>\n",
       "      <td>29.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13.433333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rl_llama3_trained</th>\n",
       "      <th>random</th>\n",
       "      <td>29.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.233333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>llm_gpt4</th>\n",
       "      <th>random</th>\n",
       "      <td>28.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">random</th>\n",
       "      <th>llm_gpt4</th>\n",
       "      <td>2.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ai</th>\n",
       "      <td>1.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.800000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rl_llama3_trained</th>\n",
       "      <td>1.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.233333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rl_gpt4_trained</th>\n",
       "      <td>1.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13.433333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>llm_mistral</th>\n",
       "      <td>1.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>72 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     Wins  Losses  Ties  AVG Rounds\n",
       "llm_mistral       random             29.0     1.0   0.0   11.000000\n",
       "ai                random             29.0     1.0   0.0    3.800000\n",
       "rl_gpt4_trained   random             29.0     1.0   0.0   13.433333\n",
       "rl_llama3_trained random             29.0     1.0   0.0   12.233333\n",
       "llm_gpt4          random             28.0     2.0   0.0   10.500000\n",
       "...                                   ...     ...   ...         ...\n",
       "random            llm_gpt4            2.0    28.0   0.0   10.500000\n",
       "                  ai                  1.0    29.0   0.0    3.800000\n",
       "                  rl_llama3_trained   1.0    29.0   0.0   12.233333\n",
       "                  rl_gpt4_trained     1.0    29.0   0.0   13.433333\n",
       "                  llm_mistral         1.0    29.0   0.0   11.000000\n",
       "\n",
       "[72 rows x 4 columns]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# setup a pandas table to plot the wins, losses, and ties for each matchup\n",
    "df = pd.DataFrame(match_grid).T\n",
    "df.columns = ['Wins', 'Losses', 'Ties', 'AVG Rounds']\n",
    "df = df.sort_values('Wins', ascending=False)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "leaderboard = df.groupby(level=0).sum().sort_values('Wins', ascending=False)\n",
    "\n",
    "with open(\"leaderboard_fighters.latex\", \"w\") as f:\n",
    "    header =  r\"\"\"\n",
    "\\begin{table}[h]\n",
    "\\centering\n",
    "\\begin{tabular}{|l|c|c|c|c|}\n",
    "\\hline\n",
    "\\textbf{Agent} & \\textbf{Wins} & \\textbf{Losses} & \\textbf{Ties} & \\textbf{AVG Rounds} \\\\\n",
    "\\hline\n",
    "\"\"\"\n",
    "    f.write(header + \"\\n\")\n",
    "    for index, row in leaderboard.iterrows():\n",
    "        player_str = index.replace('_', '\\_')\n",
    "        f.write(f\"{player_str} & {row['Wins']} & {row['Losses']} & {row['Ties']} & {row['AVG Rounds']:.2f} \\\\\\\\\\n\")\n",
    "    footer = r\"\"\"\n",
    "\\hline\n",
    "\\end{tabular}\n",
    "\\caption{Leaderboard for the Fighter Class Tournament: LLMs vs RL Agents}\n",
    "\\label{tab:fighter-class-leaderboard}\n",
    "\\end{table}\n",
    "\"\"\"\n",
    "    f.write(footer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Agent</th>\n",
       "      <th>Wins</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>llm_mistral</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>llm_gpt4</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>rl_gpt4_trained</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>rl_mistral_trained</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ai</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>llm_llama3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>rl_rules_trained</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>rl_llama3_trained</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>random</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Agent  Wins\n",
       "1         llm_mistral     7\n",
       "3            llm_gpt4     6\n",
       "7     rl_gpt4_trained     6\n",
       "8  rl_mistral_trained     5\n",
       "4                  ai     4\n",
       "2          llm_llama3     3\n",
       "5    rl_rules_trained     3\n",
       "6   rl_llama3_trained     2\n",
       "0              random     0"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create a table of how many times an agent has \"won\" against another agent\n",
    "win_table = {}\n",
    "lost_against = {}\n",
    "for (player, adversary) in match_grid.keys():\n",
    "    wins, losses, _, _ = match_grid[(player, adversary)]\n",
    "    win_table[player] = win_table.get(player, 0)\n",
    "    if wins > losses:\n",
    "        win_table[player] += 1\n",
    "    else:\n",
    "        losses = lost_against.get(player, [])\n",
    "        losses.append(adversary)\n",
    "        lost_against[player] =  losses\n",
    "\n",
    "lost_against\n",
    "win_table\n",
    "\n",
    "# create a table ranking the agents by how many times they have won\n",
    "df = pd.DataFrame(win_table.items(), columns=[\"Agent\", \"Wins\"])\n",
    "df = df.sort_values('Wins', ascending=False)\n",
    "df.to_csv(\"agent_ranking_fighters.csv\")\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dump results to CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"match_results_fighter.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1417608/1093576282.py:3: FutureWarning: The default value of numeric_only in DataFrameGroupBy.sum is deprecated. In a future version, numeric_only will default to False. Either specify numeric_only or select only columns which should be valid for the function.\n",
      "  leaderboard = df.groupby(level=0).sum().sort_values('Wins', ascending=False)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Wins</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Wins\n",
       "1     7\n",
       "3     6\n",
       "7     6\n",
       "8     5\n",
       "4     4\n",
       "2     3\n",
       "5     3\n",
       "6     2\n",
       "0     0"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create a leaderboard on the most wins\n",
    "\n",
    "leaderboard = df.groupby(level=0).sum().sort_values('Wins', ascending=False)\n",
    "leaderboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "leaderboard.to_csv(\"leaderboard_fighter.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "adversaries.sort()\n",
    "\n",
    "with open(\"match_grid_fighters.latex\", \"w\") as f:\n",
    "    header =  r\"\"\"\n",
    "\\begin{table}[h]\n",
    "\\centering\n",
    "\\resizebox{\\textwidth}{!}{%\n",
    "\\begin{tabular}{|l|c|c|c|c|c|c|c|c|c|}\n",
    "\\hline\"\"\"\n",
    "    f.write(header + \"\\n\")\n",
    "    f.write(\"\\\\textbf{Agent}\")\n",
    "    for player in adversaries:\n",
    "        player_str = player.replace('_', '\\_')\n",
    "        f.write(\" & \\\\textbf{\" + f\"{player_str}\" + \"}\")\n",
    "    f.write(\" \\\\\\\\\\n\")\n",
    "    f.write(\"\\\\hline\\n\")\n",
    "    for player in adversaries:\n",
    "        player_str = player.replace('_', '\\_')\n",
    "        f.write(f\"{player_str}\")\n",
    "        for adversary in adversaries:\n",
    "            if (player, adversary) in match_grid:\n",
    "                wins, losses, ties, avg_rounds = match_grid[(player, adversary)]\n",
    "                f.write(f\" & {wins}/{losses}/{ties}\")\n",
    "            else:\n",
    "                f.write(\" & - \")\n",
    "        f.write(\" \\\\\\\\\\n\")\n",
    "    footer = r\"\"\"\n",
    "\\hline\n",
    "\\end{tabular}%\n",
    "}\n",
    "\\caption{D\\&D Fighter-Class Tournament: Win/Loss/Tie Matrix}\n",
    "\\label{tab:fighter-class-matrix}\n",
    "\\end{table}\"\"\"\n",
    "    f.write(footer)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai322",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
